\chapter{Pequeñas optimizaciones al código de Python3}
\label{chap:optimus}

Debido a las limitaciones de memoria de la Jetson Orin Nano durante la ejecución del sistema (sección \ref{sec:syscal}, se ha optado por modificar el código a modo de hacerlo más eficiente en términos de reserva de memoria. Los cambios realizados son los siguientes:
\begin{itemize}
    \item Sustituir \textit{imports} de librerías "pesadas" (ejemplo: OpenCV o ultralytics, en torno a cientos de \acrshort{mb}) por otras más ligeras (ejemplo: numpy o scipy, en torno a decenas de \acrshort{mb}) con funciones alternativas, sin comprometer en exceso la precisión y latencia de las inferencias (ejemplo: sustituir cv2.copyMakeBorder por np.pad, o cv2.imread por PIL.Image).
    \item Uso de slots: la variable \textit{\textunderscore \textunderscore slots\_\_} evita la creación del diccionario dinámico de Python (\textit{\_\_dict\_\_}), que almacena las variables de una \textbf{clase}. Los \textit{\_\_slots\_\_} son más rápidos y eficientes que los diccionarios dinámicos de Python, aunque también más extrictos (no se pueden crear más atributos que los especificados en \textit{\_\_slots\_\_}). Un ejemplo de uso se muestra en el código \ref{coud:slots}.
\end{itemize}

\input{contenido/codes/slots.tex}

El modelo ArcFace utilizado pesa \textbf{79 \acrshort{mb}} en su versión optimizada para TensorRT (en el formato \acrshort{onnx}, pesa \textbf{152 \acrshort{mb}}), 10 veces más que cualquiera de los otros modelos empleados (el tamaño es en torno a 8 \acrshort{mb}). Utilizando un modelo ArcFace más pequeño podría reducir en torno a cientos de \acrshort{mb} la ejecución del sistema.