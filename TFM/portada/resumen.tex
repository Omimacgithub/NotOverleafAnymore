%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
    \thispagestyle{empty}
    El auge del Deep Learning (DL) ha impulsado numerosos avances en aplicaciones como la visión artificial. No obstante, estos modelos dependen en gran medida de los datos de entrenamiento, lo que limita su capacidad de generalización a nuevos contextos. El aprendizaje incremental aborda esta problemática al permitir el reconocimiento de datos desconocidos (\textit{Open-Set}) y su inclusión durante el tiempo de operación (\textit{Open-World}) sin necesidad de reentrenar el modelo desde cero. En aplicaciones de redes neuronales en tiempo real con enfoque en sistemas embebidos, se requiere además de un esfuerzo de optimización debido a las restricciones computacionales existentes.

    Este proyecto propone la integración de un método de aprendizaje incremental en un sistema de detección y reconocimiento de personas, diseñado para el robot móvil Summit\_XL, equipado con múltiples cámaras RGBD. Con el fin de garantizar la eficacia del enfoque propuesto, el sistema se ha extendido al procesamiento de vídeo, permitiendo una recolección de datos más eficiente durante la operación. Se analizan las capacidades del aprendizaje implementado en escenarios con conocimiento parcial de los datos (\textit{semisupervised learning}) y sin conocimiento previo (\textit{unsupervised learning}). Dicho sistema está implementado en la arquitectura ROS, que permite la interacción con el robot por medio de una red distribuida. Debido al fin de soporte de ROS 1 el 31 de mayo de 2025, se ha realizado una migración a ROS 2 para garantizar su continuidad.

    El sistema ha sido adaptado para aprovechar las capacidades de la familia de placas NVIDIA Jetson y otros dispositivos relacionados (GeForce GTX y RTX). Se evalúa el rendimiento de los modelos de redes neuronales en distintas arquitecturas de GPU y se analiza la escalabilidad del sistema completo en tiempo real en función del número de cámaras.

    Todas las pruebas se han realizado a partir de muestras (videos etiquetados) obtenidas en un entorno real de operación, con movimientos de las cámaras y entrecruzado de los individuos.

    \vspace*{25pt}
    \begin{english}
        \centerline{\bfseries \abstractname}
        The rise of Deep Learning (DL) has led to significant advances in applications such as computer vision. However, these models heavily depend on the training data, which limits their ability to generalize to new contexts. Incremental learning addresses this limitation by enabling the recognition of previously unseen data (Open-Set) and their incorporation during the operational phase (Open-World), without the need to retrain the model from scratch. In real-time neural network applications targeting embedded systems, additional optimization efforts are required due to existing computational constraints.

        This project proposes the integration of an incremental learning method into a person detection and recognition system designed for the mobile robot Summit\_XL, equipped with multiple RGBD cameras. To ensure the effectiveness of the proposed approach, the system has been extended to process video streams, enabling more efficient data collection during operation. The capabilities of the implemented learning strategy are analyzed under scenarios with partial prior knowledge of the data (\textit{semisupervised learning}) and with no prior knowledge (\textit{unsupervised learning}). The system is implemented within the ROS architecture, which enables interaction with the robot through a distributed network. Due to the end of support for ROS 1 on May 31, 2025, the system has been migrated to ROS 2 to ensure its long-term maintainability.

        The system has been adapted to exploit the capabilities of the NVIDIA Jetson family of embedded platforms, as well as related devices (GeForce GTX and RTX). The performance of the neural network models is evaluated across different GPU architectures, and the real-time scalability of the complete system is analyzed according to the number of cameras.

        All experiments have been conducted using labeled video samples acquired in a real-world operational environment, characterized by camera movements and frequent inter-person occlusions.
    \end{english}

    \vspace*{25pt}
    \input{portada/palabras-clave}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
