\chapter{Introducción}
\label{chap:introduccion}
\lettrine{E}{n} este capítulo se expone la motivación y los objetivos de este proyecto. Adicionalmente, se comenta la estructura por capítulos de esta memoria y brevemente su contenido.

\section{Motivación}
\label{sec:motivo}

El auge del Deep Learning (DL) y las \acrshort{cnn} han impulsado numerosos avances en aplicaciones como la visión artificial, procesado de nubes de puntos, etc \cite{Erik, ImageNet, MITTAL2019428}. Sin embargo, debido a sus elevados requerimientos computacionales, los modelos de \textit{Deep Learning} suelen ejecutarse en entornos en la nube \cite{MITTAL2019428}, lo que no es una solución viable en aplicaciones con ejecución en tiempo real, debido a la latencia en las respuestas. En este contexto, surge el concepto de \textbf{computación en el borde o Edge Computing}, que es un paradigma que consiste en procesar los datos desde su fuente de origen o desde un dispositivo muy cercano. De esta forma, se reduce la latencia de transmisión y se reparte el volumen de datos entre múltiples dispositivos \cite{EDCOM}. Un ejemplo sería procesar los datos de una cámara conectada directamente a un equipo, de esta forma se ahorraría todo el ancho de banda que implicaría transmitir una imagen por la red.

Por otro lado, existe el concepto de \textbf{TinyML} \cite{OLIVEIRA2024101153}, que consiste en la implementación de modelos compactos de forma eficiente en \glspl{embsystem} como microcontroladores (\textit{Low-end} TinyML, ejemplo: Arduino) u ordenadores de placa única (\textit{High-end} TinyML, ejemplo: NVIDIA Jetson), más potentes que los microcontroladores, pero menos económicos.

Aunque las \acrshort{cnn} han demostrado excelentes resultados, sin embargo, son fuertemente dependientes del conjunto de datos de entrenamiento, lo que acaba resultando en una pérdida en la precisión a la hora de manejar datos diferentes a los del entrenamiento, es decir, no generalizan bien \cite{Erik, malisiewicz2011ensemble}. El primer desafío consiste en reconocer cuando aparece una clase (identidad) que no pertenezca al conjunto de entrenamiento, es decir, detectar clases desconocidas (es lo que se conoce como \textit{Open-Set}). El segundo desafío será adaptar el sistema para reconocer esas nuevas entidades en el futuro. La perspectiva del aprendizaje logra superar esta limitación \cite{Erik}, al otorgar la capacidad de añadir nuevos datos durante el tiempo de operación (también conocido como \textit{Open-World}). El objetivo es que el sistema sea capaz de evolucionar y extenderse a nuevos contextos (entidades) sin necesidad de reentrenar las redes neuronales, lo que puede ser un proceso extremadamente costoso y que, a falta de un conjunto muy amplio y representativo de datos correctamente etiquetados, puede dar resultados pobres o al menos muy sesgados.

Durante el desarrollo del sistema base, se contempló implementar la capacidad de detectar cuando un individuo es un \textbf{desconocido} (individuo no registrado previamente en el sistema) y en ese caso agregarlo al sistema (\textit{Open-World})\cite{andrew}. Esta funcionalidad es muy útil para implementar un robot móvil guía que asista a los usuarios proporcionando un trato cercano en todo momento (ejemplo: saludarlos por su nombre). Sin embargo, con las capacidades del sistema actual no es posible implementar esta funcionalidad de manera operativa. Debido al elevado índice de sesgo que adoptan las \acrshort{cnn}, se genera una gran caída en la precisión a la hora de manejar datos diferentes a los del entrenamiento. La perspectiva del aprendizaje logra superar esta limitación \cite{Erik}, al otorgar la capacidad de añadir nuevos datos durante el tiempo de operación (también conocido como \textit{Open-World}).

TODO: El método propuesto en \cite{Erik} y que conforma la base del sistema implementado, ha sido probado en un contexto de video vigilancia bajo el \textit{\gls{dataset}} \textbf{FACE COX} \cite{cox}. También se ha utilizado el \textit{\gls{dataset}} \textbf{Youtube Faces} (YTF) \cite{ytf} que, a diferencia del anterior, se encuentra accesible de forma pública. En este proyecto se utiliza un \textit{\gls{dataset}}\dots
El método utiliza \textbf{secuencias de video} como entrada para devolver las predicciones acerca de un IoI o para determinar una identidad desconocida.

Para concluir, este proyecto surgió a partir de la idea de implementar un complejo sistema de detección y reconocimiento capaz de agregar a nuevos usuarios bajo su confirmación. Se buscaron dispositivos que fueran potentes, pero a su vez de bajo consumo y fácilmente acoplables a un robot móvil, de forma que todas las operaciones del sistema no dependan de un ordenador central que limite la movilidad del robot.

TODO: El método requiere de un conjunto reducido de datos para su inicialización (por ejemplo, los datos biométricos de 5 personas). Dado que la recopilación de imágenes faciales está fuertemente regulada por la ley de protección de datos, el uso de este enfoque resulta especialmente relevante para el presente proyecto \cite{Erik}.

\section{Trabajo relacionado}

A la hora de diseñar aceleradores hardware para aplicaciones de redes neuronales es necesario mantener el balance entre precisión, rendimiento y bajo consumo. La NVIDIA Jetson es una familia de sistemas embebidos que persigue maximizar dicho balance \cite{MITTAL2019428}. Un claro ejemplo es el uso de la Jetson TX2 en aplicaciones como el reconocimiento facial para el procesamiento de videos en resolución Full HD (1080p) \cite{qi2018iot} o la detección de personas con cámaras \acrshort{rgb} en resolución HD (720p) \cite{rahmaniar2021real}, ambos casos de uso han reportado un rendimiento satisfactorio en tiempo real.

(TODO: reformular esto) Entre las múltiples técnicas y herramientas que existen \cite{MITTAL2019428}, se ha decantado principalmente por usar TensorRT. Este ecosistema de herramientas permite la optimización de redes neuronales \cite{rahmaniar2021real}, logrando así la ejecución de múltiples aplicaciones en tiempo real. NVIDIA dispone dicho software para una gran variedad de sus \acrshort{gpu} y dispositivos Jetson, además de tutoriales para múltiples aplicaciones de \acrshort{ia} \cite{x36}.

En este proyecto se explora la inclusión de un algoritmo de aprendizaje incremental, que permita a las \acrshort{cnn} poder integrar nueva información sin necesidad de reentrenar desde 0. Los algoritmos desarrollados en este campo de estudio se reúnen bajo los conceptos de \textbf{\textit{Open-Set}} y \textbf{\textit{Open-World}} \cite{rudd2017extreme, Erik, CESAR}. Mientras que el primero se limita a clasificar nuevas muestras como muestras nunca antes vistas (o desconocidas), el segundo permite incluir dicho conocimiento al modelo, de forma que se logra adaptar a los múltiples factores cambiantes que entraña el mundo real.

A la hora de diseñar un nuevo algoritmo que incluya nuevo conocimiento, es fundamental establecer un balance entre añadir y actualizar las muestras ante los nuevos cambios producidos (\textit{concept-drift}) y evitar \textbf{borrar} el conocimiento previo (\textit{catastrophic forgetting}) \cite{Erik, CESAR}.

\section{Objetivos}

El primer objetivo de este proyecto es desarrollar un nuevo método de aprendizaje máquina para detectar desconocidos (\textit{Open-Set}) e incluir nuevos individuos (\textit{Open-World}) basado en las ideas mencionadas en la sección \ref{sec:motivo}. Estas mejoras incluyen, entre otras, construir y procesar simultáneamente las secuencias de todas las caras detectadas en todas las cámaras (aplicando técnicas de tracking), usar comités basados en clasificadores débiles (máquina de vectores de soporte o SVM) para identificar clases (usando votación mayoritaria), aplicar la distribución de Weibull para detectar clases desconocidas, inicializar el sistema de forma apropiada (bien de forma manual, bien cuando el sistema detecta varias caras en el mismo instante de tiempo), adaptar los comités (añadiendo y limitando sus SVM) para seguir los cambios de esa entidad (concept drift) y crear una nueva identidad (comité) para cada desconocido. Para facilitar su despliegue y mantenimiento se dockerizará el sistema y se migrará a ROS2.

El segundo objetivo del proyecto será optimizar todo el software para funcionar de forma eficiente en la familia de sistemas embebidos NVIDIA Jetson \cite{MITTAL2019428, rahmaniar2021real} y otros dispositivos relacionados (NVIDIA GeForce GTX y RTX). Se evaluará el rendimiento del sistema tanto de forma aislada (cada uno de sus módulos principales o con más carga computacional) como en conjunto con el sistema completo. Las pruebas se realizarán a partir de muestras (videos) de un entorno de operación real en interiores, con movimientos bruscos del robot (y de las cámaras) y entrecruzado de los individuos. También se realizarán diversas pruebas de estrés para analizar el comportamiento del sistema con distintas cargas de trabajo y también para comprobar hasta qué punto escala, por ejemplo, aumentando el número de cámaras a procesar.

TODO: comparan la AGX Xavier (+1000 leuros) con una GTX 1050 y los resultados son muy similares \cite{murthy2020investigations}

\section{Estructura de la memoria}

Esta memoria se divide en capítulos, cada uno con una explicación detallada del trabajo realizado. Se expone a continuación la estructura de esta memoria, explicando brevemente su contenido:

\begin{enumerate}
    \item \textbf{Introducción}: presente capítulo en el que se exponen los motivos de realización de este proyecto, los objetivos planteados y la estructura de la memoria resultante.
    \item \textbf{Fundamentos teóricos y tecnológicos}: capítulo en el que se presentan los conceptos clave del proyecto, así como las herramientas tanto hardware como software utilizadas.
    \item \textbf{Gestión del proyecto}: en este capítulo se presentan los requisitos, actores y casos de uso que definen el sistema propuesto, el plan de gestión de los riesgos, la metodología de desarrollo empleada y una vista detallada de la planificación del proyecto y su posterior seguimiento.
    \item \textbf{Integración y extensión del sistema base}: capítulo en el que se expone la arquitectura del sistema del proyecto, el procedimiento seguido para integrar dicho sistema en la familia de dispositivos NVIDIA Jetson y varias modificaciones del sistema necesarias para el correcto transcurso del proyecto.
    \item \textbf{Reconocimiento facial adaptativo}: capítulo en el que se detallan las características del método de aprendizaje máquina propuesto y su implementación.
    \item \textbf{Pruebas y resultados}: capítulo en el que se presenta la preparación de las pruebas y se arrojan resultados de todos los componentes implementados.
    \item \textbf{Conclusiones y trabajo futuro}: análisis de los resultados e hitos alcanzados en el proyecto y propuesta de varias líneas de investigación y desarrollo que podrían mejorar los resultados obtenidos.
\end{enumerate}