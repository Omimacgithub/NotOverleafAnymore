\chapter{Introducción}
\label{chap:introduccion}
\lettrine{E}{n} este capítulo se expone la motivación y los objetivos de este proyecto. Adicionalmente, se comenta la estructura por capítulos de esta memoria y brevemente su contenido.

\section{Motivación}
\label{sec:motivo}

En el contexto actual, la robótica inteligente se halla cada vez más integrada en la sociedad. El desarrollo de sistemas robóticos capaces de interactuar con los seres humanos constituye un aspecto esencial, en la medida en que estos sistemas deben favorecer un trato cálido y centrar la atención humana en los objetivos verdaderamente relevantes.

Con el auge del Deep Learning (DL) y de las \acrfull{cnn}, se han impulsado numerosos avances en la robótica y en aplicaciones como la visión artificial o el procesado de nubes de puntos \cite{Erik, ImageNet, MITTAL2019428}. No obstante, debido a sus elevados requerimientos computacionales, estos modelos suelen ejecutarse en entornos de computación en la nube \cite{MITTAL2019428}, lo que no resulta adecuado para aplicaciones en tiempo real debido a la latencia introducida. En este contexto, la \textbf{computación en el borde o Edge Computing} surge como una alternativa que permite procesar los datos cerca de su origen, reduciendo la latencia y distribuyendo la carga de procesamiento entre distintos dispositivos \cite{EDCOM}.

Dentro del paradigma de la computación en el borde, nace el concepto de \textbf{TinyML} \cite{OLIVEIRA2024101153}, que consiste en la implementación de modelos de redes neuronales de forma eficiente en \glspl{embsystem} como microcontroladores (\textit{Low-end} TinyML, ejemplo: Arduino) u ordenadores de placa única (\textit{High-end} TinyML, ejemplo: NVIDIA Jetson), más potentes que los microcontroladores, pero menos económicos.

Este proyecto propone la integración de un sistema de detección y reconocimiento de personas (definido en \cite{andrew}) bajo la familia de placas de bajo consumo NVIDIA Jetson. Dicho sistema se ha implementado para un robot móvil equipado con un sensor \acrshort{lidar} y múltiples cámaras \acrshort{rgbd}. Todo el procesamiento es realizado a través de un ordenador central, por lo que la adopción de la NVIDIA Jetson permitiría tener una unidad de procesamiento acoplada al robot, dotándole así de mayor movilidad e independencia.

Aunque las \acrshort{cnn} han demostrado excelentes resultados, sin embargo, son fuertemente dependientes del conjunto de datos de entrenamiento, lo que acaba resultando en una pérdida en la precisión a la hora de manejar datos diferentes a los del entrenamiento, es decir, no generalizan bien \cite{Erik, malisiewicz2011ensemble}. Para abordar este problema, surge el concepto de la \textbf{adaptación}, que permite a los modelos aprender nuevo conocimiento durante la operación del sistema. Este enfoque permite al sistema evolucionar y extenderse a nuevos contextos (en este caso personas) sin necesidad de reentrenar las redes neuronales, lo que puede ser un proceso extremadamente costoso y que, a falta de un conjunto muy amplio y representativo de datos correctamente etiquetados, puede dar resultados pobres o al menos muy sesgados.

Este proyecto propone la integración de un algoritmo (definido en \cite{Erik}) que, en primer lugar, sea capaz de reconocer clases (individuos) que no pertenezcan al conjunto de entrenamiento, es decir, detectar clases desconocidas (es lo que se conoce como \textit{Open-Set}). En segundo lugar, el algoritmo permitirá al sistema adaptarse para reconocer nuevas entidades en el futuro, agregando la información de estas en forma de conocimiento (también conocido como \textit{Open-World}).

\section{Objetivos}

El primer objetivo de este proyecto es desarrollar un nuevo método de aprendizaje máquina para detectar desconocidos (\textit{Open-Set}) e incluir nuevos individuos (\textit{Open-World}) basado en las ideas mencionadas en la sección \ref{sec:motivo}. Concretamente, el sistema debe ser capaz de realizar lo siguiente:
\begin{itemize}
    \item Construir y procesar simultáneamente las secuencias de todas las caras detectadas en todas las cámaras, aplicando técnicas para el seguimiento y reidentificación de personas.
    \item Usar comités basados en clasificadores débiles (máquina de vectores de soporte o SVM) para identificar clases (usando votación mayoritaria).
    \item Adaptar los comités (añadiendo y limitando sus SVM) para seguir los cambios de esa entidad (\textit{\textbf{concept-drift}}) y crear una nueva identidad (comité) para cada desconocido.
    \item Aplicar la distribución de Weibull para detectar clases desconocidas.
    \item Inicializar el sistema de forma apropiada, bien de forma manual (las caras que pasan a formar parte del sistema se seleccionan minuciosamente), bien cuando el sistema detecta varias caras en el mismo instante de tiempo.
\end{itemize}

El segundo objetivo del proyecto será optimizar todo el software para funcionar de forma eficiente en la familia de sistemas embebidos NVIDIA Jetson y otros dispositivos relacionados (NVIDIA GeForce GTX y RTX). Se evaluará el rendimiento del sistema tanto de forma aislada (cada uno de sus módulos principales o con más carga computacional) como en conjunto con el sistema completo. Las pruebas se realizarán a partir de muestras (videos) de un entorno de operación real en interiores, con movimientos bruscos del robot (y de las cámaras) y entrecruzado de los individuos. También se realizarán diversas pruebas de estrés para analizar el comportamiento del sistema con distintas cargas de trabajo y también para comprobar hasta qué punto escala, por ejemplo, aumentando el número de cámaras a procesar.

Para facilitar su despliegue y mantenimiento, el sistema se empaquetará en contenedores de Docker y se migrará a \acrshort{ros} 2.

\section{Trabajo relacionado}

\subsection{Aprendizaje incremental con adaptación a los cambios}
\label{sec:incrlearning}

En el contexto de este proyecto (detección y reconocimiento de personas en tiempo real), no es posible preparar un \gls{dataset} de entrenamiento compuesto por una gran multitud de etiquetas, debido a la naturaleza cambiante de los datos en el mundo visual \cite{Erik}, tampoco sería posible debido a la ley de protección de datos, que restringe la capacidad de recolección de estos datos. Por lo que es necesario adoptar un método que permita a los modelos de redes neuronales aprender, partiendo de un conjunto de datos muy escaso.

En este proyecto se explora la implementación de un algoritmo de aprendizaje incremental, que permite a los modelos poder integrar nueva información sin necesidad de reentrenar desde 0. Los algoritmos desarrollados en este campo de estudio se reúnen bajo los conceptos de \textbf{\textit{Open-Set}} y \textbf{\textit{Open-World}} \cite{rudd2017extreme, Erik, CESAR}. Mientras que el primero se limita a distinguir las clases conocidas de las desconocidas, el segundo permite incluir conocimiento al modelo a partir de las entradas, de forma que se logra adaptar a los múltiples factores cambiantes que entraña el mundo real.

El aprendizaje incremental se ha enfocado en dos vías, cada una con sus propios desafíos. Por un lado, se realizan predicciones, sin ningún aprendizaje previo, a partir de un \gls{batch} de datos, que se itera una y otra vez (\textit{batch learning}) \cite{Erik, rodeo, rodeo1}. Esta actualización resulta lenta de ejecutar para cada entrada e inoperativa para aplicaciones de sistemas embebidos en tiempo real \cite{rodeo}. Por el otro lado, se agrega el conocimiento de forma gradual a partir de pequeñas muestras de datos (\textit{streaming learning}), que permite un aprendizaje rápido y adaptable a los cambios en tiempo real \cite{Erik, rodeo, streaming2}.

A la hora de diseñar un nuevo algoritmo que incluya nuevo conocimiento, es fundamental establecer un balance entre añadir y actualizar las muestras ante los nuevos cambios producidos (\textit{concept-drift}) y evitar \textbf{borrar} el conocimiento previo (\textit{catastrophic forgetting}) \cite{Erik, CESAR, rodeo, streaming2, rodeo1}.

El uso de \textbf{comités}, que no son más que un conjunto de clasificadores, ha demostrado ser eficaz para tratar el problema del \textit{catastrophic forgetting} \cite{Erik, ensembles0, ensembles3}. Los comités permiten agregar conocimiento acerca de una entidad entrenando un nuevo clasificador o eliminar dicho conocimiento descartando el clasificador correspondiente. De esta forma, se obtiene una representación de un individuo a partir de un conjunto de clasificadores ligeros, sin necesidad de reentrenar un clasificador complejo desde cero \cite{malisiewicz2011ensemble}.

A la hora de implementar el reconocimiento \textit{Open-Set}, destaca el uso del \acrfull{evt} \cite{Erik,CESAR,rudd2017extreme,scorenorm}. El \acrshort{evt} es una teoría estadística, que devuelve la probabilidad de que un evento represente un \textbf{extremo} respecto a una distribución de máximos o mínimos.

Los métodos propuestos en \cite{rudd2017extreme, Erik, CESAR} han sido probados en los \glspl{dataset} \textbf{FACE COX} \cite{cox}, \textbf{Youtube Faces} (YTF) \cite{ytf} e \textbf{ImageNet} \cite{ImageNet}, cuya adquisición de muestras se realiza en entornos controlados (buena iluminación, en las que suele aparecer un único objeto). Para probar el algoritmo desarrollado en este proyecto, se emplea un \gls{dataset} creado en \cite{andrew}. Dicho \gls{dataset} contiene frames borrosos, con múltiples individuos en escena entrecruzándose, caras ocluidas, etc, que son condiciones comunes en un entorno realista.

El procesamiento de video permite aprovechar la coherencia espacio-temporal, sobre todo en el contexto de las personas, cuyos movimientos son lentos y predecibles. Por otra parte, los métodos de seguimiento pueden ayudar a obtener muestras difíciles de reconocer para el aprendizaje de los modelos. Otro aspecto importante a la hora del seguimiento es la \textbf{reidentificación}, es decir, como localizar al individuo una vez se ha perdido su rastro (ejemplo: ha sido ocluido por otro individuo o por un objeto).

Para implementar el seguimiento y la \textbf{reidentificación} de objetos, se suele emplear el método húngaro combinado con el filtro de kalman \cite{Hungarian,MangoYOLO}. El \textbf{filtro de Kalman} predice la próxima posición del individuo a partir de la probabilidad Gausiana, de tal forma que puede mantenerse el rastro cuando la persona desaparece por unos frames. A pesar de ser una técnica efectiva, el filtro necesita de un mínimo de frames para converger cuando una nueva persona aparece \cite{MangoYOLO}, lo que no es beneficioso para secuencias de frames cortas.

\subsection{Aplicaciones de redes neuronales en sistemas embebidos}

La ejecución de modelos de inteligencia artificial en sistemas embebidos (o TinyML) sigue suponiendo un gran reto a día de hoy \cite{OLIVEIRA2024101153}.

\cite{tflitework} ha logrado la ejecución en tiempo real de dos deep conventional neural networks (DCNNs) en la Raspberry Pi 4 usando TensorFlow Lite, relegando en técnicas como la \gls{quant} de rango dinámico (los valores se cuantizan a enteros de 8 bits en tiempo de ejecución) y \gls{quant} en \acrshort{fp}16.

A la hora de diseñar aceleradores hardware para aplicaciones de redes neuronales es necesario mantener el balance entre precisión, rendimiento y bajo consumo. La NVIDIA Jetson es una familia de sistemas embebidos que persigue maximizar dicho balance \cite{MITTAL2019428, rahmaniar2021real}. Un claro ejemplo es el uso de la Jetson TX2 en aplicaciones como el reconocimiento facial para el procesamiento de videos en resolución Full HD (1080p) \cite{qi2018iot} o la detección de personas con cámaras \acrshort{rgb} en resolución HD (720p) \cite{rahmaniar2021real}, ambos casos de uso han reportado un rendimiento satisfactorio en tiempo real.

TensorRT es una pieza clave para la optimización de modelos en aceleradoras de NVIDIA, habilitando así la ejecución de aplicaciones de inteligencia artificial en tiempo real \cite{MITTAL2019428, rahmaniar2021real}.

\cite{mdpi}.


\section{Estructura de la memoria}

Esta memoria se divide en capítulos, cada uno con una explicación detallada del trabajo realizado. Se expone a continuación la estructura de esta memoria, explicando brevemente su contenido:

\begin{enumerate}
    \item \textbf{Introducción}: presente capítulo en el que se exponen los motivos de realización de este proyecto, los objetivos planteados, el trabajo relacionado y la estructura de la memoria resultante.
    \item \textbf{Fundamentos teóricos}: capítulo en el que se presentan los conceptos que se referenciarán a lo largo de la memoria.
    \item \textbf{Fundamentos tecnológicos}: capítulo que presenta los dispositivos sujetos de pruebas de este proyecto, así como las arquitecturas de las \acrshort{gpu}s que incorporan. También se exponen las herramientas hardware y software utilizadas.
    \item \textbf{Gestión del proyecto}: en este capítulo se presentan los requisitos, actores y casos de uso que definen el sistema propuesto, el plan de gestión de los riesgos, la metodología de desarrollo empleada y una vista detallada de la planificación del proyecto y su posterior seguimiento.
    \item \textbf{Arquitectura del sistema propuesto}: capítulo en el que se expone la arquitectura general del sistema, la nueva arquitectura propuesta para este proyecto y la explicación en detalle de cada uno de los módulos planteados.
    \item \textbf{Implementación del sistema}: capítulo en el que se detallan algunos aspectos de la implementación.
    \item \textbf{Análisis de rendimiento}: capítulo en el que se presentan los modelos de redes neuronales utilizados y las pruebas a realizar. Se analizan en detalle y se discuten los resultados en todos los dispositivos del proyecto.
    \item \textbf{Pruebas y resultados}: análisis de los resultados e hitos alcanzados en el proyecto y propuesta de varias líneas de investigación y desarrollo que podrían mejorar los resultados obtenidos.
    \item \textbf{Conclusiones y trabajo futuro}: capítulo en el que se arrojan las conclusiones acerca de los resultados e hitos alcanzados, así como de los errores cometidos. También se proponen varias líneas de investigación y desarrollo para extender el trabajo del presente proyecto.
\end{enumerate}