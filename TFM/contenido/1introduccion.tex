\chapter{Introducción}
\label{chap:introduccion}
\lettrine{E}{n} este capítulo se expone la motivación y los objetivos de este proyecto. Adicionalmente, se comenta la estructura por capítulos de esta memoria y brevemente su contenido.

\section{Motivación}
\label{sec:motivo}

En el contexto actual, la robótica inteligente se halla cada vez más integrada en la sociedad. El desarrollo de sistemas robóticos capaces de interactuar con los seres humanos constituye un aspecto esencial, en la medida en que estos sistemas deben favorecer un trato cálido y centrar la atención humana en los objetivos verdaderamente relevantes.

Con el auge del Deep Learning (DL) y de las \acrfull{cnn}, se han impulsado numerosos avances en la robótica y en aplicaciones como la visión artificial o el procesado de nubes de puntos \cite{Erik, ImageNet, MITTAL2019428}. No obstante, debido a sus elevados requerimientos computacionales, estos modelos suelen ejecutarse en entornos de computación en la nube \cite{MITTAL2019428}, lo que no resulta adecuado para aplicaciones en tiempo real debido a la latencia introducida. En este contexto, la \textbf{computación en el borde o Edge Computing} surge como una alternativa que permite procesar los datos cerca de su origen, reduciendo la latencia y distribuyendo la carga de procesamiento entre distintos dispositivos \cite{EDCOM}.

Dentro del paradigma de la computación en el borde, nace el concepto de \textbf{TinyML} \cite{OLIVEIRA2024101153}, que consiste en la implementación de modelos de redes neuronales de forma eficiente en \glspl{embsystem} como microcontroladores (\textit{Low-end} TinyML, ejemplo: Arduino) u ordenadores de placa única (\textit{High-end} TinyML, ejemplo: NVIDIA Jetson), más potentes que los microcontroladores, pero menos económicos.

Este proyecto propone la integración de un sistema de detección y reconocimiento de personas (definido en \cite{andrew}) bajo la familia de placas de bajo consumo NVIDIA Jetson. Dicho sistema se ha implementado para un robot móvil equipado con un sensor \acrshort{lidar} y múltiples cámaras \acrshort{rgbd}. Todo el procesamiento es realizado a través de un ordenador central, por lo que la adopción de la NVIDIA Jetson permitiría tener una unidad de procesamiento acoplada al robot, dotándole así de mayor movilidad e independencia.

Aunque las \acrshort{cnn} han demostrado excelentes resultados, sin embargo, son fuertemente dependientes del conjunto de datos de entrenamiento, lo que acaba resultando en una pérdida en la precisión a la hora de manejar datos diferentes a los del entrenamiento, es decir, no generalizan bien \cite{Erik, malisiewicz2011ensemble}. Para abordar este problema, surge el concepto de la \textbf{adaptación}, que permite a los modelos aprender nuevo conocimiento durante la operación del sistema. Este enfoque permite al sistema evolucionar y extenderse a nuevos contextos (en este caso personas) sin necesidad de reentrenar las redes neuronales, lo que puede ser un proceso extremadamente costoso y que, a falta de un conjunto muy amplio y representativo de datos correctamente etiquetados, puede dar resultados pobres o al menos muy sesgados.

Este proyecto propone la integración de un algoritmo (definido en \cite{Erik}) que, en primer lugar, sea capaz de reconocer clases (individuos) que no pertenezcan al conjunto de entrenamiento, es decir, detectar clases desconocidas (es lo que se conoce como \textit{Open-Set}). En segundo lugar, el algoritmo permitirá al sistema adaptarse para reconocer nuevas entidades en el futuro, agregando la información de estas en forma de conocimiento (también conocido como \textit{Open-World}).

\section{Objetivos}

El primer objetivo de este proyecto es desarrollar un nuevo método de aprendizaje máquina para detectar desconocidos (\textit{Open-Set}) e incluir nuevos individuos (\textit{Open-World}) basado en las ideas mencionadas en la sección \ref{sec:motivo}. Concretamente, el sistema debe ser capaz de realizar lo siguiente:
\begin{itemize}
    \item Construir y procesar simultáneamente las secuencias de todas las caras detectadas en todas las cámaras, aplicando técnicas para el seguimiento y reidentificación de personas.
    \item Usar comités basados en clasificadores débiles (máquina de vectores de soporte o SVM) para identificar clases (usando votación mayoritaria).
    \item Adaptar los comités (añadiendo y limitando sus SVM) para seguir los cambios de esa entidad (\textit{\textbf{concept-drift}}) y crear una nueva identidad (comité) para cada desconocido.
    \item Aplicar la distribución de Weibull para detectar clases desconocidas.
    \item Inicializar el sistema de forma apropiada, bien de forma manual (las caras que pasan a formar parte del sistema se seleccionan minuciosamente), bien cuando el sistema detecta varias caras en el mismo instante de tiempo.
\end{itemize}

El segundo objetivo del proyecto será optimizar todo el software para funcionar de forma eficiente en la familia de sistemas embebidos NVIDIA Jetson y otros dispositivos relacionados (NVIDIA GeForce GTX y RTX). Se evaluará el rendimiento del sistema tanto de forma aislada (cada uno de sus módulos principales o con más carga computacional) como en conjunto con el sistema completo. Las pruebas se realizarán a partir de muestras (videos) de un entorno de operación real en interiores, con movimientos bruscos del robot (y de las cámaras) y entrecruzado de los individuos. También se realizarán diversas pruebas de estrés para analizar el comportamiento del sistema con distintas cargas de trabajo y también para comprobar hasta qué punto escala, por ejemplo, aumentando el número de cámaras a procesar.

Para facilitar su despliegue y mantenimiento, el sistema se empaquetará en contenedores de Docker y se migrará a \acrshort{ros} 2.

\section{Trabajo relacionado}

Este trabajo persigue la ejecución eficiente de un sistema compuesto por múltiples redes neuronales convolucionales (\acrshort{cnn}s), que amplían su conocimiento a partir de la información del entorno (aprendizaje incremental). Para lograr dichos objetivos, se han tenido que explorar los campos de investigación que se exponen a continuación.

\subsection{Aprendizaje incremental}
\label{sec:incrlearning}

Debido a la naturaleza cambiante de los datos en el mundo visual, preparar un \gls{dataset} que englobe todas las posibles variaciones \textbf{no sería práctico} \cite{Erik}. Adicionalmente, debido al contexto de este proyecto (detección y reconocimiento de personas en tiempo real), tampoco sería posible recoger grandes cantidades de datos debido a la ley de protección de datos, que restringe la capacidad de recolección de los mismos. Por estos motivos, se vuelve necesario adoptar un método que permita a los modelos de redes neuronales \textbf{adaptarse a los cambios} del entorno partiendo de un conjunto de muestras \textbf{muy escaso}. La perspectiva del \textbf{aprendizaje incremental} permite a los modelos incluir dichas variaciones a lo largo del tiempo \cite{rodeo}.

%Muchos sistemas que implementan el aprendizaje incremental lo hacen por medio de \glspl{batch} (\textit{batch learning}), es decir, tienen que esperar a obtener grandes conjuntos de datos antes de ejecutar la adaptación \cite{Erik, rodeo, rodeo1}. Esta actualización resulta lenta de ejecutar para cada entrada e inoperativa para aplicaciones de sistemas embebidos en tiempo real \cite{rodeo}. Por el otro lado, el sistema que se quiere implementar en este proyecto, aborda el paradigma del \textit{streaming learning} \cite{Erik} se agrega el conocimiento de forma gradual a partir de pequeñas muestras de datos (\textit{streaming learning}), que permite un aprendizaje rápido y adaptable a los cambios en tiempo real \cite{Erik, rodeo, streaming2}.

En este proyecto, se explora la implementación del algoritmo de aprendizaje incremental propuesto en \cite{Erik}, que permite al modelo poder integrar nuevo conocimiento sin necesidad de reentrenarlo desde cero. Los algoritmos desarrollados en este campo de estudio se reúnen bajo los conceptos de \textbf{\textit{Open-Set}} y \textbf{\textit{Open-World}} \cite{rudd2017extreme, Erik, CESAR}. Mientras que el primero se enfoca en distinguir nuevas clases (desconocidas) respecto a las ya conocidas del entrenamiento, el segundo permite incluir nuevo conocimiento al modelo a partir de las entradas, de forma que se logra adaptar a los múltiples factores cambiantes que entraña el mundo visual.

Los métodos de aprendizaje incremental propuestos en \cite{rudd2017extreme, Erik, CESAR} han sido probados en los \glspl{dataset} \textbf{FACE COX} \cite{cox}, \textbf{Youtube Faces} (YTF) \cite{ytf} e \textbf{ImageNet} \cite{ImageNet}, cuya adquisición de muestras se realiza en entornos controlados (buena iluminación, en las que suele aparecer un único objeto), lo que no representa una aplicación en un contexto real. Para probar la eficacia del algoritmo en condiciones reales, se emplea un \gls{dataset} creado en \cite{andrew}, que contiene frames borrosos, con múltiples individuos en escena entrecruzándose, caras ocluidas, entre otros factores comunes en un entorno real.

A la hora de implementar el reconocimiento \textit{Open-Set}, destaca el uso del \acrfull{evt} \cite{Erik,CESAR,rudd2017extreme,scorenorm,jain2014multi}. El \acrshort{evt} es una teoría estadística, que devuelve la probabilidad de que un evento represente un \textbf{extremo} respecto a una distribución de máximos o mínimos.

Es fundamental para todo algoritmo que incluya algún tipo de conocimiento establecer un balance entre añadir y actualizar las muestras ante los nuevos cambios producidos (\textit{concept-drift}) y evitar \textbf{borrar} el conocimiento previo (\textit{catastrophic forgetting}) \cite{Erik, CESAR, rodeo, streaming2, rodeo1}.

El uso de \textbf{comités}, que no son más que un conjunto de clasificadores, ha demostrado ser eficaz para tratar el problema del \textit{catastrophic forgetting} \cite{Erik, ensembles0, ensembles3}. Los comités permiten agregar conocimiento acerca de una clase entrenando un nuevo clasificador o eliminar dicho conocimiento descartando el clasificador correspondiente. De esta forma, se obtiene una representación de la clase a partir de un conjunto de clasificadores ligeros, sin necesidad de reentrenar un clasificador complejo desde cero \cite{malisiewicz2011ensemble}.

\subsection{Seguimiento de objetos en secuencias de frames}

El seguimiento de objetos permite aprovechar la coherencia espacio-temporal, sobre todo en el contexto de las personas, cuyos movimientos son lentos y predecibles. Los métodos de seguimiento pueden ayudar a obtener muestras difíciles de reconocer para el aprendizaje de los modelos \cite{Erik}. Otro aspecto importante es la \textbf{reidentificación}, es decir, como localizar al individuo una vez se ha perdido su rastro (ejemplo: ha sido ocluido por otro individuo o por un objeto).

Para implementar el seguimiento y la reidentificación de objetos, se suele emplear el \textbf{método húngaro} combinado con el \textbf{filtro de Kalman} \cite{Hungarian,MangoYOLO}. El \textbf{filtro de Kalman} predice la próxima posición del individuo a partir de la probabilidad Gausiana, de tal forma que puede mantenerse el rastro cuando la persona desaparece por unos frames. A pesar de ser una técnica efectiva, el filtro necesita de un mínimo de frames para converger cuando una nueva persona aparece \cite{MangoYOLO}, lo que no es beneficioso para secuencias de frames cortas.

\subsection{Aplicaciones de redes neuronales en sistemas embebidos}

A la hora de diseñar aceleradores de hardware para aplicaciones de redes neuronales es necesario mantener el balance entre precisión, rendimiento y bajo consumo. La NVIDIA Jetson es una familia de sistemas embebidos que destaca por el elevado rendimiento que ofrece por vatio gracias a sus núcleos de \acrshort{gpu} de bajo consumo. Otra virtud de la Jetson es la posibilidad de programar en CUDA y en librerías como cuDNN, mientras que otros dispositivos, como la Raspberry Pi, requieren el uso de OpenCL, ya que no disponen de las librerías específicas para su arquitectura \cite{MITTAL2019428, rahmaniar2021real}.

En \cite{rahmaniar2021real} se utiliza la Jetson TX2 y la Jetson Nano para la detección de personas a partir de los videos de cámaras \acrshort{rgb} en resolución HD (1280x720). Los diferentes videos de prueba muestran a personas moviéndose a diferentes velocidades, coincidiendo simultáneamente en la visión de la cámara y en varias habitaciones con diferente luminosidad. Las pruebas arrojan unos remarcables \textbf{17.32 y 26.03 \acrshort{fps}} en la Jeton Nano y TX2 respectivamente en el modelo SSD MobileNet V2, lo que las hace aptas para su ejecución en tiempo real.

% NO HACE RECONOCIMIENTO FACIAL -> También en \cite{qi2018iot} se ha empleado la Jetson TX2 para el reconocimiento facial en videos con resolución Full HD (1080p).

%\cite{tflitework} ha logrado la ejecución en tiempo real de dos deep conventional neural networks (DCNNs) en la Raspberry Pi 4 usando TensorFlow Lite, relegando en técnicas como la \gls{quant} de rango dinámico (los valores se cuantizan a enteros de 8 bits en tiempo de ejecución) y \gls{quant} en \acrshort{fp}16.

Referente a los últimos modelos que existen de la familia Jetson y que se usarán en este proyecto, en \cite{rey2025performance} se ha logrado obtener una velocidad de \textbf{37, 40 y 44 \acrshort{fps}} en la inferencia del modelo \textbf{YOLOv8n} aplicando la cuantización \acrshort{fp}32, 16 e INT8 (entero de 8 bits) respectivamente en la \textbf{Jetson Orin Nano}. YOLOv8n fue uno de los modelos escogidos en el diseño del sistema que se pretende optimizar, siendo este el principal cuello de botella, con una velocidad de tan solo \textbf{5.6 \acrshort{fps}} en una \acrshort{cpu} Intel i5 \cite{andrew}. Los \acrshort{fps} de YOLOv8n logrados en la Jetson Orin Nano demuestran la potencia de procesamiento de su \acrshort{gpu} al mismo tiempo que su reducido consumo, que no alcanza los 9 W \cite{rey2025performance}.

TensorRT es una pieza clave para la optimización de modelos en aceleradoras de NVIDIA, habilitando así la ejecución de aplicaciones de inteligencia artificial en tiempo real \cite{MITTAL2019428, rahmaniar2021real}. Su uso por medio de modelos en formato \acrshort{onnx} ha demostrado un speed up del doble en la latencia en  redes de clasificación de imágenes como MobileNet y SqueezeNet respecto a otros \glspl{rt} en \acrshort{gpu} como PyTorch, también destaca por su uso eficiente y escalable de la memoria de la \acrshort{gpu} \cite{trtworkflows}. Otra virtud de TensorRT es su capacidad de realizar inferencias en diferentes precisiones, desde \acrshort{fp}32 hasta INT8 (entero de 8 bits), hasta el reciente \acrshort{fp}4 en la arquitectura de \acrshort{gpu} Blackwell \cite{fp4}. En \cite{xu2018deep} se compara el rendimiento de la inferencia en \acrshort{fp}32 e INT8 del modelo ResNet50, cuyos resultados arrojan un speed up del 3.7 en INT8 respecto a \acrshort{fp}32 (siendo el máximo teórico de 4), con una pérdida mínima (0.02\% - 0.18\%) en la precisión del modelo.

\section{Estructura de la memoria}

Esta memoria se divide en capítulos, cada uno con una explicación detallada del trabajo realizado. Se expone a continuación la estructura de esta memoria, explicando brevemente su contenido:

\begin{enumerate}
    \item \textbf{Introducción}: presente capítulo en el que se exponen los motivos de realización de este proyecto, los objetivos planteados, el trabajo relacionado y la estructura de la memoria resultante.
    \item \textbf{Fundamentos teóricos}: capítulo en el que se presentan los conceptos que se referenciarán a lo largo de la memoria.
    \item \textbf{Fundamentos tecnológicos}: capítulo que presenta los dispositivos sujetos de pruebas de este proyecto, así como las arquitecturas de las \acrshort{gpu}s que incorporan. También se exponen las herramientas hardware y software utilizadas.
          %\item \textbf{Gestión del proyecto}: en este capítulo se presentan los requisitos, actores y casos de uso que definen el sistema propuesto, el plan de gestión de los riesgos, la metodología de desarrollo empleada y una vista detallada de la planificación del proyecto y su posterior seguimiento.
    \item \textbf{Arquitectura del sistema propuesto}: capítulo en el que se expone la arquitectura general del sistema, la nueva arquitectura propuesta para este proyecto y la explicación en detalle de cada uno de los módulos planteados.
    \item \textbf{Implementación del sistema}: capítulo en el que se detallan algunos aspectos de la implementación.
    \item \textbf{Análisis de rendimiento}: capítulo en el que se presentan los modelos de redes neuronales utilizados y las pruebas a realizar. Se analizan en detalle y se discuten los resultados en todos los dispositivos del proyecto.
    \item \textbf{Pruebas de escalabilidad del sistema}: capítulo en el que se mide la capacidad del sistema de escalar en varios de los dispositivos del proyecto.
    \item \textbf{Pruebas y resultados del reconocimiento adaptativo}: en este capítulo se analiza el rendimiento de la nueva capacidad de adaptación a partir de múltiples pruebas.
    \item \textbf{Conclusiones y trabajo futuro}: capítulo en el que se arrojan las conclusiones acerca de los resultados e hitos alcanzados, así como de los errores cometidos. También se proponen varias líneas de investigación y desarrollo para extender el trabajo del presente proyecto.
\end{enumerate}