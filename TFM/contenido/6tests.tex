\chapter{Pruebas y resultados}
\lettrine{E}{n} este capítulo se presentan los resultados de rendimiento del método con el modelo y junto con el sistema final, variando el número de cámaras. También se explica el proceso de creación de los datasets utilizados para las pruebas.

\section{Diseño de las pruebas}
\section{Resultados Open-World}
TODO: En la fase de inicialización de los modelos (o fase de entrenamiento), el sistema guarda la información estadística que representa a cierto modelo. Durante el funcionamiento del sistema, puede ocurrir que los datos que recibe de un individuo registrado varíen respecto a la información de entrenamiento, lo que se conoce como \textbf{concept drift}. Se debe de corregir el concept drift para evitar una pérdida en la precisión de reconocimiento.

TODO: actualización del modelo, añadir nuevas entidades puede corromper la información de las entidades iniciales (catastrophic forgetting).

TODO: él método tiene una precondición, \textbf{se necesitan de al menos 5 IoI para crear la distribución de Weibull}.

TODO: los criterios que conforman el módulo de limitación tienen en cuenta el signo de la puntuación de forma exclusiva, lo que puede no funcionar siempre, sobretodo si se dispone de pocos frames que definan al individuo.

TODO: las secuencias de pocos frames (ej: 2) son muy propensas a resultados erroneos, especialmente si introducen mucho ruido, como frames borrosos, con mucha oclusión, variación en la iluminación, entre otros muchos factores. Debido a que este sistema maneja secuencias solapadas (ej: frames 0 a 10, frames 5 a 15) se puede deducir que es muy probable que la identidad a reconocer en la secuencia actual sea la misma identidad que en la secuencia anterior. Dependiendo de diversos factores, como el número de frames de la secuencia, se puede otorgar un mayor peso al reconocimiento anterior.

Para concluir, cuando el sistema no es capaz de reconocer a un individuo con alta confianza y, en cambio, lo denota como desconocido, el mecanismo se vuelve \textbf{contraproducente}. Si una entidad ya conocida se reconoce como desconocida, se crea un nuevo comité de la misma persona, lo que incrementa la duda en el reconocimiento, ya que la distribución de weibull contendrá puntos que representen al propio individuo, indicando que el score de coincidencia no es un caso extremo cuando si debería serlo. La solución más rápida y efectiva es subir el valor de threshold de la probabilidad devuelta por la función de Weibull, aún así, es inevitable que se generen nuevos comités para un mismo individuo, contaminando el sistema rápidamente. 

\section{Fuentes de los datos (nuestro dataset combinado con YTF)}

\section{Pruebas del sistema final}

\section{Solapamiento de secuencias: buffering}

Supongase un tamaño de secuencia 25 y un offset de 15, la secuencia de frames sería la siguiente:

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

                                   15 16 17 18 ... 39

Se pueden almacenar parte de los frames utilizados en un buffer para la siguiente secuencia.

\section{Número de IoI}
El número de IoI (o de entidades positivas) afecta directamente al reconocimiento mediante Weibull, ya que cuantas más entidades, más puntos definen la distribución, por lo tanto mejor definida está la función. TODO: me da igual o mejores resultados con 6 entidades que con 10.

\section{Número de negativos}
En la tabla (TODO) se muestra el \textit{F1 score} para 10 y 50 muestras que conforman el conjunto de negativos de entrenamiento (ratios 1:1 y 1:5 si el tamaño del template es 10). Claramente los resultados mejoran al escoger 50 negativos, esto se debe a que en 10 frames cabe un conjunto reducido de entidades a diferencia de 50 frames, sobretodo si se realiza una selección aleatoria como ocurre en este caso.

\section{Umbral de Weibull (TW)}
Si el valor del umbral de Weibull es bajo, la precisión se mantiene en valores altos, sacrificando el recall, mientras que un valor alto en dicho umbral se traduce en un elevado recall a costa de la precisión. Como ya se ha explicado, el umbral de Weibull representa la probabilidad máxima a la que el mejor score pertenece a la distribución de scores no coincidentes, cuanto más bajo sea el valor, más extrema debe ser la coincidencia para ser reconocida (la precisión aumenta), por lo que la función es más selectiva en el reconocimiento (devuelve un mayor número de desconocidos, reduciendo así el recall). Un valor alto representa justo lo contrario. TODO: parece que un TW alto es mejor siempre, pero tengo que poner los resultados de una prueba con un desconocido de verdad, así muestro el verdadero problema de elevarlo.

\section{Percentiles}
Al fusionar los scores de todas las SVM en todos los frames, se obtiene un único score acordado por la mayoría mediante la mediana, siendo esta equivalente al percentil 50. Al variar el percentil, el número de SVM participantes también varía. Un percentil de 100 implica obtener el mayor score, que se corresponde con la peor coincidencia (por ende, el valor de recall es paupérrimo, puesto que se necesita del consenso de todas las SVM del comité para devolver un match). Por otro lado, un percentil de 0 implica recuperar el score más bajo de entre todas las SVM en todos los frames. En este caso también podría darse un bajo recall ya que si por ejemplo se añade una SVM de otra entidad, dicha SVM devolvería un score negativo, por lo que Weibull etiquetaría el reconocimiento como desconocido al haber más de un comité activado (que devuelve un score bajo).

Uno de los objetivos del sistema es obtener la mayor diversidad intra-comité y la mayor especificidad inter-comité. Un \textbf{percentil alto} encajaría si las SVM son \textbf{específicas} entre si (la mayoría de las SVM devuelven match). En cambio, un \textbf{bajo percentil} funcionaría con unas SVM \textbf{más diversas} (se espera que la minoría de las SVM den un resultado coincidente).

\section{Tamaño del comité}
En relación con el anterior punto, el número de SVM influye en la decisión de que percentil tomar. Si se utilizan 3 SVM por comité y la mediana, al menos 2 SVM deben de devolver un score bajo para dar un resultado coincidente. Por otro lado, si se utilizan 10 SVM y un percentil de 30, sólo 3 de las 10 SVM necesitan estar de acuerdo para devolver un match.

En los resultados se muestra como un comité de 3 SVM y TW=0.05 destaca respecto a un comité de 1 SVM y TW=0.5. Los resultados utilizando 10 SVM por comité no llegan a mejorar notablemente el valor de 3 SVM, esto es de gran relevancia, puesto que se reduce el número de iteraciones de cada reconocimiento de 10*n a 3*n, siendo n el número de comités que existen y asumiendo que todos los comités han llegado al límite de SVM. Con estos resultados se ha demostrado que implementar varias SVM por comité mejora el recall manteniendo la precisión. 1 sóla SVM por comité es efectiva si dicha SVM es representativa del individuo, en caso contrario puede devolver respuestas coincidentes acerca de una entidad distinta del comité, generando ruido que perjudica a las predicciones de Weibull. Un mayor número de SVM combinado con la mediana devuelve un resultado conforme dicta una mayoría que omite los scores de SVM intrusas (de entidades distintas) y permite expulsarlas mediante los criterios ya comentados en la sección \ref{seq:limmod}. 

\section{Tamaño de la plantilla}
El tamaño de plantilla es igual al tamaño del conjunto de positivos para una entidad, cuantas más muestras conformen dicho conjunto, mejores predicciones realizará la SVM asociada. En la tabla (TODO) se puede ver que el mejor resultado ha sido con un tamaño de plantilla de 10 frames. Los resultados con 5 frames son ligeramente peores (79.7 frente a 76.5), lo que demuestra la robustez del sistema ante dicho número escaso de muestras para un individuo.

\section{Tamaño de secuencia}
En la tabla (TODO) se muestran 3 valores diferentes de este parámetro. Como es de esperar, los mejores resultados coinciden con el mayor tamaño (25), puesto que se dispone de una mayor cantidad de información que apoye al reconocimiento. Los resultados con una secuencia de 15 frames caen levemente, un menor tamaño de secuencia hace que el sistema funcione a una mayor frecuencia (devuelva más reconocimientos en el mismo tiempo), concretamente a cada 1,5 segundos con dicho tamaño de secuencia asumiendo que las cámaras funcionan a 10 Hz (capturan una imagen cada 100 ms).

\section{Solapamiento}
El solapamiento entre secuencias puede causar que las SVM sean más específicas, ya que se da lugar a un mayor número de SVM parecidas entre sí (con un solapamiento de 5 y un tamaño de secuencia de 25, se comparten 20 frames entre secuencias y por ende entre las SVM). Con un número reducido o nulo de frames compartidos, el comité tiende a generalizar mejor, lo que es un factor crítico para la precisión y el recall.

Según los resultados arrojados (TODO), ninguno de los solapamientos utilizados indica una variación significativa en los resultados.

\section{Inicialización del sistema}
La selección de los frames que conforman un nuevo comité es un factor crítico para el correcto funcionamiento del sistema. En la tabla (TODO) se comparan 2 técnicas de inicialización, una semi-supervisada (los frames se escogen manualmente y el comité se actualiza de forma autónoma) y la otra no supervisada (se escogen los frames en el momento que aparecen varias personas en escena para diferenciarlas). 

\section{Criterio de selección de frames para nuevas SVM}
También es muy importante la selección de las muestras que conforman las SVM, en la tabla (TODO) se muestran 2 criterios para la selección, uno consiste en seleccionar los frames con los scores más cercanos al cero, mientras que el otro es una selección aleatoria. El primer criterio demuestra un aumento en el F1 score, dado que los frames cercanos al cero son los más complicados de reconocer, de esta forma la SVM amplía sus fronteras respecto a lo que ya reconoce. A la hora de crear una SVM de un nuevo comité en el modo open-world, no queda otra alternativa que realizar una selección aleatoria.

\section{Criterio de favorabilidad}

En la tabla (TODO) se muestra el efecto de dicho criterio a la hora de eliminar las SVM respecto a un criterio de eliminación aleatorio. Este ...

\section{Creación de nuevos comités}
En el modo Open-World, el sistema crea un nuevo comité cuando se reconoce a una nueva entidad en el sistema. Sin embargo, debido a las predicciones incorrectas del método, puede ocurrir que se creen nuevos comités para un individuo ya registrado. Estos nuevos comités pueden desplazar a los comités originales adueñándose de su identidad.

El número de comités redundantes creados varía conforme al umbral de Weibull. Cuanto menor sea el valor, más comités redundantes se crearán debido a que la incertidumbre del método aumenta.

\section{Open-set runtime}


\section{Open-world selected}


\subsection{Caso concreto:}
global  99  73  14      57.6   87.6     69.5

num ensembles: 15
svm of each ensemble: [('jose', 1), ('carlos', 1), ('martin', 1), ('omi', 1), ('rayas', 1), ('andres', 1), ('botella', 1), ('azul', 1), ('javi', 1), ('gris', 1), ('user10', 1), ('user11', 1), ('user12', 1), ('user13', 1), ('user14', 1)]

\section{Open-world runtime}
