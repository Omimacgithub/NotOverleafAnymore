\chapter{Sistema de reconocimiento y seguimiento de personas}
\label{chap:sys}

\lettrine{E}{n} este capítulo se exponen los resultados de rendimiento del sistema propuesto para varias arquitecturas. Se ha partido de una implementación final del sistema pensada para la arquitectura x86, este capítulo explica las optimizaciones aplicadas para su ejecución en arquitecturas ARM64.

\section{Arquitectura del sistema}
\label{sec:sysarch}

El sistema de este proyecto posee la capacidad de fusionar diferentes fuentes de datos para otorgar un único resultado de reconocimiento para cada persona detectada. Los nodos que componen la arquitectura se detallan a continuación y se muestran en la figura \ref{fig:ANDRES}:

\begin{itemize}
    \item Nodo cámara: recibe como fuente los datos de una cámara \textbf{RGBD} y se encarga de detectar, reconocer y obtener la posición 3D de las personas que aparecen en la imagen.
    \item Nodo LiDAR: recibe los datos de un sensor LiDAR (nube de puntos 3D) y se encarga de detectar y obtener la posición 3D de las personas del mapa (no se ha implementado el reconocimiento).
    \item Nodo integrador de sensores: fusiona los datos de los 2 nodos anteriores. La función de este nodo es el seguimiento de las personas reconocidas, más allá de lo que la cobertura de las cámaras ofrece (para un Kinect de la Xbox 360 son 57º).
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/SYSARCH.png}
    \caption{Arquitectura general del sistema (figura extraída de \cite{andrew})}
    \label{fig:ANDRES}
\end{figure} 

\section{Modificaciones propuestas}

\subsection{Ventanas de frames}
\label{subseq:secuenciation}

El sistema expuesto trabaja a nivel de frame, lo que otorga sencillez y una elevada frecuencia, pero al mismo tiempo un alto coste computacional y una no muy alta confianza (el reconocimiento depende enteramente del frame capturado). En este proyecto se ha optado por trabajar con \textbf{secuencias de frames}, de manera que se exprimen las capacidades de la GPU para trabajar por lotes (conjuntos de frames) y se otorgan mejores reconocimientos (basados en múltiples frames). El funcionamiento de esta técnica se muestra en la figura (TODO), se escoge un tamaño de secuencia (15 o 25 en las pruebas realizadas) y se extraen los frames. En cada frame, puede haber entre 0 y n entidades, como no se conoce la identidad de cada individuo en este punto, es necesario realizar un \textbf{rastreo} (tracking) de las entidades en cada uno de los frames. El tracking implementado calcula una matriz de costes entre las detecciones de un frame y el frame posterior, cada coste representa un valor de solape entre bounding boxes, cuanto menor mayor es el solape, finalmente, se realiza una asignación óptima entre detecciones mediante el método húngaro (como se plantea en \cite{Hungarian}).

\subsubsection{Re identificación de entidades}
Es posible que durante la detección de individuos, las bounding boxes de una misma persona en frames consecutivos no se solapen, debido a la velocidad de movimiento del individuo por ejemplo. En este caso, existe el riesgo de que el método húngaro asocie incorrectamente la identificación a otra persona a la que le ocurre esta misma situación. Otro problema es el no seguimiento de la persona cuando esta se encuentra totalmente ocluida (ejemplo: se cruza un individuo justo delante) y vuelve a aparecer.

A partir del método de tracking propuesto no es posible recuperar el rastro de las entidades que desaparecieron de forma intermitente. Para resolver este problema se ha optado por calcular la distancia euclidiana entre la última bounding box del individuo en cuestión y la bounding box de una nueva detección, si la distancia entre ellas es menor a un umbral, se reasigna la detección al individuo.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/Seq.jpg}
    \caption{Funcionamiento de la secuenciación, como salida se obtiene una lista de frames agrupados por entidad}
    \label{fig:Seq}
\end{figure}

\subsection{Escalabilidad y tolerancia a fallos de las cámaras}
TODO: con el sistema inicial, sólo se podían ejecutar 2 cámaras y tenían que funcionar las 2 a la vez. Por estas razones, se ha reemplazado la solución del \textit{ApproximateTimeSynchronizer} implementada en \cite{andrew} por la clase \textit{MessageFiltersCache}.

\subsection{Migración a ROS 2}
\label{subsec:ROS2}

Con el motivo del fin de soporte de ROS 1 \cite{ROSEOL}, se ha optado por migrar el sistema para ser ejecutado en ROS 2 con el fin de mantener su continuidad. Se han migrado los nodos cámara e integrador, la migración del nodo LiDAR requeriría actualizar el código a una versión soportada para Ubuntu 22.04 de la librería pcl, entre otros detalles que llevarían a rediseñar casi todo el código. TODO: Se probaron diferentes alternativas como RoboStack

\section{Optimización de inferencias con TensorRT}

TODO: Se han recortado bucles for y se ha exprimido la librería de numpy, se han reducido unos milisegundos.

El objetivo de este capítulo es descubrir la capacidad de los dispositivos Jetson de poder asumir la carga de trabajo del sistema de forma que pueda escalarse. El rendimiento esperado en tiempo real para el sistema son los \textbf{10 Hz} (o 10 FPS), por lo tanto, todos los nodos deben de funcionar a 10 Hz. Las NVIDIA Jetson sólo tienen que ocuparse de ejecutar los \textbf{nodos cámara a 10 Hz} y que otro equipo ejecute el nodo LiDAR e integrador del sistema.

Que los nodos cámara trabajen a 10 Hz implica que a cada \textbf{100 ms se recibe un nuevo frame} (10 * 100 = 1000 ms = 1 segundo), la figura \ref{fig:cam} muestra el procesado realizado por dicho nodo en cada frame, que debe de finalizar \textbf{antes de que transcurran 100 ms}. En cada iteración del procesado, se ejecutan \textbf{4 redes neuronales (CNN)}. 2 de ellas, YOLOv8n y YuNet, para la detección de cuerpos y de caras respectivamente. Las otras 2, OSNet\_x1 y ArcFace, para el reconocimiento de cuerpos y caras respectivamente. A pesar de lo que la figura \ref{fig:cam} muestra, las redes de detección YOLOv8n y YuNet \textbf{no se ejecutan en paralelo}, lo mismo sucede con las redes ArcFace y OSNet\_x1. Se ha considerado ejecutar en paralelo estas redes. Sin embargo, las limitaciones de memoria principal de la Jetson restringen tomar esta aproximación.

TODO: En equipos x86 esta meta ya se ha cumplido. Sin embargo, para la arquitectura de la Jetson (ARM64) ha sido necesario aplicar varios cambios.

\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{imagenes/CAM.png}
    \caption{Componentes del nodo cámara}
    \label{fig:cam}
\end{figure}


\subsection{Realización de pruebas}
Las pruebas del sistema se han focalizado en evaluar las redes neuronales utilizadas en los nodos cámara y el rendimiento del sistema completo. Para este fin, se cuentan con \textbf{datasets} generados a partir de los datos grabados de una prueba de 2 minutos dentro del laboratorio de robótica del CITIC con 6 personas.

Para las pruebas de los modelos de detección, se reproduce el video para que el modelo realize las detecciones en cada frame. Las predicciones obtenidas por el modelo se comparan contra el dataset para evaluar si son correctas. En la tabla (TODO) se muestra para cada modelo de detección (YOLOv8n y YuNet) la métrica F1 (definida en \ref{sec:metriks}).

Para las pruebas de los modelos de reconocimiento, se guardan como imágenes los recortes de los cuerpos y de las caras de cada individuo en cada frame del video grabado por la cámara. Para cada recorte, se ejecuta el modelo y se compara su predicción con la recogida en el dataset. En la tabla (TODO), se utiliza para los modelos de reconocimiento (ArcFace y OSNet\_x1) la métrica de \textbf{precisión} (proporción de reconocimientos correctos) \cite{andrew}.

\subsection{Resultados en dispositivos Jetson}
El sistema cuenta con un motor de inferencia de redes neuronales orientado a procesadores y gráficas \textbf{Intel}, llamado \textbf{OpenVINO} \cite{OpenVINO}. OpenVINO otorga herramientas para convertir archivos ONNX (formato reconocido para exportar redes neuronales) a ficheros XML, que son versiones \textbf{optimizadas} de las redes neuronales y que se utilizan para realizar las inferencias. Todas las redes salvo YuNet (que utiliza el motor de OpenCV en CPU) se han exportado a un equivalente optimizado en OpenVINO. 

Los primeros resultados arrojados en la tabla (TODO) muestran que las placas Jetson \textbf{no son capaces de cumplir el objetivo de 10 Hz} usando OpenVINO. Sólo la ejecución de YOLOv8n consume los 100 ms en la Jetson Xavier NX. En cuanto a la Jetson Orin Nano, la suma de la ejecución de las 4 redes supera también los 100 ms.

TensorRT es un framework para inferencia de alto rendimiento creado por NVIDIA, pensado para la ejecución de redes neuronales en sistemas embebidos de NVIDIA como es la Jetson \cite{MITTAL2019428, rahmaniar2021real}. 

TensorRT se ha empleado para optimizar modelos ONNX al formato propio de la herramienta (denominado engine) y así poder realizar inferencias a partir de su API. Un ejemplo de código de inferencia en TensorRT es el que se muestra en TODO.

Todas las redes neuronales fueron exportadas a un engine de TensorRT salvo YuNet, que utiliza \textbf{OpenCV con CUDA}. Para disponer de soporte CUDA, es necesario compilar OpenCV \textbf{desde el fuente} \cite{OpenCVCUDA}.

%\input{contenido/coud}

NVIDIA consta que con TensorRT, el Speed up de las inferencias aumenta \textbf{36 veces}. En este caso se ha logrado reducir hasta \textbf{5 veces} el tiempo de inferencia en el caso de YOLOv8n en la Jetson Xavier NX. Si sumamos todos los tiempos de inferencia usando el motor de TensorRT, da un total de \textbf{63.6 milisegundos} para la Jetson Xavier NX y \textbf{49.1 milisegundos} para la Jetson Orin Nano.

\input{contenido/tabequips}

\subsection{Resultados en equipos x86}

Afortunadamente, todas las librerías del proyecto cuenta con soporte para ambas arquitecturas x86 y ARM64, por lo que fué prácticamente inmediato el despliegue entre dispositivos mediante Docker (exceptuando pequeños cambios en el código por el cambio de versión de TensorRT y omitir ciertas optimizaciones (ejemplo: flag msse de las CPUs x86)).

Una ventaja de TensorRT es la \textbf{fácil portabilidad del código}, se puede ejecutar un mismo script de inferencia en cualquier equipo que posea una GPU de NVIDIA, siempre que sea posible instalar la misma versión de TensorRT (en caso contrario, es necesario realizar un cambio en el código, aunque este es leve).

En la tabla (TODO) se muestran los resultados obtenidos en 2 equipos x86, comparándolos con la Jetson Orin Nano, el sistema embebido con el que se ha obtenido el mejor rendimiento. En equipos x86, la latencia experimentada  es hasta \textbf{5.3 veces menor} (YOLOv8n) para los modelos ejecutados en CPU y hasta \textbf{4.9 veces menor} (YuNet) para los modelos ejecutados en GPU que la obtenida por la Jetson Orin Nano. Debido a que OpenVINO está pensado para hardware de Intel, las optimizaciones en la Jetson no suponen ninguna mejora, al contrario que en los equipos x86 con una CPU \textbf{Intel i7}. Por otro lado, es sorprendente que también existan diferencias significativas respecto a la Jetson \textbf{cuando se realizan las inferencias en GPU}. La diferencia más notoria es con YuNet en el PC del laboratorio, que poseé una \textbf{GeForce GTX 1650}, que está \textbf{una generación por detrás} de la GPU de la Jetson Orin (las arquitecturas son Turing y Ampere respectivamente) \cite{archs}. Esto implica que, para la carga de trabajo de este proyecto, \textbf{la GPU no es el factor predominante} (TODO: con estos datos puedo sacar esta conclusión?).
