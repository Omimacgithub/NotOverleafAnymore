\chapter{Implementación del sistema}
\label{chap:impl}

\lettrine{E}{n} este capítulo se ahonda en los detalles de implementación de los componentes del sistema extendido. También se comentan los cambios relevantes realizados al sistema base y a los modelos para su ejecución en \acrshort{gpu}.

Para los módulos que conforman el reconocimiento adaptativo, se ha tomado como base el siguiente repositorio \cite{src}.

\input{contenido/codes/trtskel.tex}

\section{Códigos de inferencia para el \gls{rt} de TensorRT}
En la figura \ref{fig:finalsys} se muestran los 4 modelos utilizados en el nodo cámara y que se detallarán en la sección \ref{sec:models}, todos cuentan con su implementación optimizada para OpenVINO creada en \cite{andrew}, excepto para el modelo de detección de caras (YuNet), que se ejecuta en el \gls{rt} de OpenCV. En este proyecto se han implementado nuevas versiones de las inferencias adaptadas para su uso en \acrshort{gpu} por medio de TensorRT y PyCUDA. PyCUDA ofrece una API que facilita gran parte de la interacción con CUDA, aun así, se necesita gestionar en el código temas como la creación de contextos y reserva de la memoria.

TensorRT trabaja con su propio formato de los modelos, por lo que es necesario realizar una conversión de los mismos a dicho formato mediante las herramientas expuestas en el apéndice \ref{chap:procedure}. En el proceso de conversión se aplica un proceso de selección de optimizaciones según la arquitectura de la \acrshort{gpu}, que prueba distintas tácticas para la distribución del trabajo y diferentes precisiones para quedarse con la combinación más rápida, sin comprometer la precisión del modelo.

El código \ref{coud:trtskel} muestra el esqueleto de dichas inferencias, cada vez que se crea una instancia del modelo en Python, se reservan los siguientes recursos:
\begin{itemize}
    \item \textbf{Contexto de CUDA}: en este caso se recibe como parámetro, ya que es necesario crear dicho contexto en el mismo código donde se ejecuta el bucle infinito de \acrshort{ros} (ejemplo: nodo cámara), de modo que pueda manejarse correctamente.
    \item \textbf{Contexto del modelo}: dicho contexto se crea a partir del modelo deserializado de TensorRT.
    \item \textbf{CUDA Stream}: canal que utilizará la \acrshort{gpu} para ejecutar todas las inferencias.
    \item \textbf{Device input}: memoria del \gls{tensor} de entrada reservado en la \acrshort{gpu}. Se especifica el tamaño en bytes del \gls{tensor} que representa los datos de entrada.
    \item \textbf{Device output}: memoria del \gls{tensor} de salida reservado en la \acrshort{gpu}. Se especifica el tamaño en bytes del \gls{tensor} que representa los datos de salida.
    \item \textbf{Bindings}: lista de direcciones de memoria de los \glspl{tensor} a utilizar durante la inferencia.
\end{itemize}

Dichos recursos se reservan \textbf{una sola vez}, que corresponde con el momento de creación de la instancia de la clase Python que representa al modelo.

La función \textit{infer} del código \ref{coud:trtskel} se ejecuta por cada vez que se recibe una entrada a procesar, la entrada puede ser un solo frame o una secuencia de estos.

Se ejecuta la función PREPROCESING con la entrada, que representa el pipeline de preprocesado específico para cada modelo. Los datos preprocesados se copian a la memoria de la \acrshort{gpu} (o \textit{device}) a través de un \textit{memcpy} y se realiza la inferencia en el \textit{stream} de CUDA reservado. Antes de realizar la inferencia, se especifica el tamaño concreto de los datos de entrada (función \textit{set\_input\_shape}), ya que en un procesamiento en modo \gls{batch}, el conjunto de imágenes puede diferir. Finalmente, los resultados se copian de vuelta a la memoria de la \acrshort{cpu} (o \textit{host}) y se ejecuta el pipeline de postprocesado del resultado definido en la función POSTPROCESING.

Las operaciones de copia de datos y la inferencia se ejecutan de forma \textbf{asíncrona}, por lo que es necesario introducir una barrera de sincronización una vez todas las operaciones se emitan, de forma que nuevos \glspl{thread} no sobrescriben la memoria de la \acrshort{gpu} mientras esta realiza inferencias.

%\section{Creación de las SVM}
%\label{sec:training}
\section{Procesamiento de video}
La implementación sigue el flujo expuesto en la sección \ref{sec:tracker}.

El cálculo del \acrshort{iou} es sencillo y no entraña apenas complejidad computacional. Previo al \acrshort{iou}, se obtiene el área a partir de las coordenadas de las \glspl{bbox} y se calcula la intersección y la unión. La distancia euclidiana se calcula como se expone en la sección \ref{subsec:reiden} y tampoco entraña mayor dificultad.

Para realizar una asignación óptima del método húngaro, se utilizó la función \textit{linear\_sum\_assignment} otorgada por el módulo \textit{optimize} de la librería SciPy \cite{lsa}. Dicha librería implementa el algoritmo Jonker-Volgenan, que es una variante del método húngaro con complejidad computacional $O(n^{3})$ \cite{lsa, o3}. Atendiendo a la elevada complejidad computacional, este algoritmo se volvería impracticable con matrices de cientos de filas y columnas (ejemplo: detección de 100 personas de una cámara en un frame y su anterior) \cite{325}. Sin embargo, como en los videos de prueba una cámara llega a detectar como máximo 4 personas a la vez, la ejecución del algoritmo no supone apenas algún coste.

\section{Módulo de valoración}

Como se expuso en la sección \ref{sec:val}, el módulo de valoración devuelve un conjunto de puntuaciones que representan a la secuencia para todos los comités.

La implementación sigue el funcionamiento descrito en la sección \ref{sec:val}. Para calcular los percentiles y la mediana en las funciones FDF y SDF se utilizan las funciones \textit{percentile} y \textit{median} respectivamente de la librería NumPy.

\section{Módulo de reconocimiento}

Como se mencionó en la sección \ref{sec:reckon}, el módulo de reconocimiento determina si la entidad detectada se corresponde a un individuo previamente reclutado o a una entidad \textbf{desconocida}.

\input{contenido/codes/weib.tex}

El código \ref{coud:weib} muestra la implementación de dicha funcionalidad. Se parte de la función RDF (Recognition Decision Function), que recibe el conjunto de puntuaciones ordenado y devuelve la decisión de reconocimiento.

Del conjunto de puntuaciones ordenadas, se excluye la mejor puntuación de todos los comités (es decir, la puntuación más baja) y se compone la distribución de puntuaciones no coincidentes. Se calcula para cada punto la distancia respecto a la mediana (variable v), de forma que los puntos de la distribución se distancian del mejor comité. Se obtienen los parámetros \textit{shape} y \textit{scale} a partir de la distribución, que modelan la función de Weibull. Finalmente, se calcula la probabilidad de pertenencia del mejor comité a la distribución (función weib) y se toma la decisión en base a un umbral (Tw). Si la probabilidad es inferior al umbral, se reconoce el caso como un extremo y se asigna la identidad correspondiente al sujeto (\textit{drift}), en caso contrario se devuelve como desconocido (\textit{unknown}).

Para obtener los parámetros que componen la distribución de Weibull, se utiliza la función \textit{fit} de la clase \textit{weibull\_fit} del módulo \textit{stats} de la librería SciPy.

\section{Módulo de actualización}

La implementación del módulo sigue el flujo descrito en la sección \ref{sec:reckon}. En el caso de una clase conocida, la nueva \acrshort{svm} se guarda en el comité junto a la selección de positivos, que sirven para entrenar nuevas \acrshort{svm}, en el caso contrario se crea una nueva entrada en la base de datos con la nueva etiqueta del individuo (\textbf{person\_id}), el comité con su \acrshort{svm} inicial (\textbf{ensemble}) y la selección de positivos (\textbf{descriptors}) y la lista de valores de coherencia (\textbf{coherence}) inicializada a 0. En la selección de los positivos se aplica la función de valor absoluto a la lista de puntuaciones de las muestras, que posteriormente se ordena de menor a mayor y se recuperan los primeros valores, que son los más cercanos al 0.

La creación de las \acrshort{svm} se realiza a partir de la función \textit{def\_svm}, que se verá en la sección \ref{sec:init}.

\section{Módulo de limitación}
En el \textbf{módulo de actualización}, si el comité excede el máximo de \acrshort{svm} establecido, este módulo se activa para hallar la \acrshort{svm} que menos contribuye, por tanto la que debe de abandonar el comité.

Se invoca a la función que calcula el criterio de favorabilidad, que otorga un valor para cada \acrshort{svm} a partir de la suma de los criterios de diversidad y coherencia. Se almacenan los resultados en un array de NumPy y se ordenan los valores devueltos mediante la función \textit{argsort} de NumPy, por lo que la \acrshort{svm} a eliminar se corresponde con la primera entrada del vector (es decir, el que tenga el valor de favorabilidad más bajo).

Los valores de coherencia se calculan sobre el valor acumulado de cada \acrshort{svm} cada vez que se invoca a este módulo. Por simpleza, se ha optado por reiniciar este valor en todo el comité a 0 cada vez que se reemplaza una \acrshort{svm}, de forma que se mantenga una comparación justa entre todas las \acrshort{svm}.

\section{Personas registradas}
\label{sec:init}

En esta sección se comentan las implementaciones de los componentes encargados de crear, mantener y compartir la base de datos de las personas registradas del sistema.

\subsection{Creación y entrenamiento de las \acrshort{svm}}

\input{contenido/codes/training.tex}

El código \ref{coud:training} corresponde al proceso seguido a la hora de crear y entrenar nuevas \acrshort{svm}. Si el individuo es un desconocido, entonces todas las muestras de la base de datos sirven como datos \textbf{negativos}, de lo contrario, es necesario \textbf{excluir las muestras del propio sujeto} del conjunto negativo, si no se estaría perdiendo el poder discriminativo de las \acrshort{svm}.

Tras obtener las muestras negativas, se extrae un subconjunto aleatorio de estas (función \textit{random\_pick}), que normalmente será una cantidad fija prefijada antes de lanzar el sistema.

A la hora de entrenar las \acrshort{svm}, se asigna la etiqueta 1 (variable \textit{plabels}) para las muestras positivas (variable \textit{d1}) y -1 (variable \textit{labels}) para las negativas (variable \textit{samplesNegative}). OpenCV asigna los signos a las clases según el orden de los signos y las etiquetas que se presentan en el entrenamiento. En el caso de presentar primero las muestras negativas con -1 y las positivas con +1, entonces la \acrshort{svm} devuelve como máximo -1 cuando una muestra pertenece a la clase positiva, siendo -1 la distancia al hiperplano desde la clase positiva, en caso contrario se devolverá como máximo un +1 para las clases negativas. Se ha aplicado este comportamiento para que la fusión de puntuaciones mediante la mediana \textbf{funcione} (ya que ordena los valores de menor a mayor), pero la \acrshort{svm} podría entrenarse para causar el efecto contrario, solo es necesario cambiar el orden de aparición de las etiquetas y los signos en el entrenamiento.

\subsection{Método de inicialización no supervisado}

Como ya se explicó en la sección \ref{sec:initarch}, se parte únicamente de la información de las cámaras en el momento de ejecución del sistema, en el caso de las pruebas realizadas se utilizan los frames de los videos grabados.

Para la implementación del algoritmo de la figura \ref{fig:init} se ha podido aprovechar el módulo de procesamiento de video para la fase de recolección de \glspl{bbox}. El resto de detalles de implementación no entrañan nada destacable.

\subsection{Registro compartido}

Se han implementado los 2 métodos descritos en la sección \ref{sec:shared}, que se comentan a continuación.

\begin{itemize}
    \item \textbf{Base de datos centralizada}: para la base de datos se escogió \textbf{Redis}, que funciona puramente en memoria principal. La base de datos se despliega en un contenedor de Docker separado del sistema, el propio equipo en el que se despliega la base de datos se comunica con el sistema mediante un \textbf{socket de Unix}, el resto de clientes remotos acceden por dirección IP (Internet Protocol) (TODO: la implementación no está acabada).

          El nodo integración de sensores se encarga de revisar si se han reconocido a nuevos usuarios en el sistema, si es el caso, este manda una petición de escritura a la base de datos Redis, (TODO: Redis tiene unos hooks que permiten propagar los cambios en la información en forma de broadcast, de forma que llegan a los nodos cámara, pero esto no lo implementé).
    \item \textbf{Red de \acrshort{ros}}: debido a que la base de datos introduce latencia al sistema, especialmente si las escrituras son recurrentes, se ha adoptado otra alternativa que aprovecha la red de \acrshort{ros}. Los nodos cámara se suscriben a un tópico, en el que el nodo integración de sensores publica los nuevos cambios y entidades en el sistema. De esta forma, todos los nodos cámara mantienen su copia actualizada. Esta aproximación permite ahorrarse las latencias en las peticiones de lectura/escritura de una base de datos.

\end{itemize}

\section{Escalabilidad y tolerancia a fallos de las cámaras}

\input{contenido/codes/cash.tex}

Cuando se fusionan los resultados procesados por los distintos sensores (nodo integración de sensores en la figura \ref{fig:finalsys}), se requiere que todos ellos se encuentren \textbf{sincronizados} dentro de un intervalo temporal (ejemplo: 100 milisegundos), de forma que las predicciones no se realizan a partir de información desactualizada.

En \cite{andrew} se utiliza una clase del paquete \textit{message\_filters} de \acrshort{ros} llamado \textit{ApproximateTimeSynchronizer}, que utiliza un algoritmo adaptativo para emparejar mensajes a partir de su \gls{timestamp} \cite{ApproximateTime}. El problema de \textit{ApproximateTimeSynchronizer} es que espera recibir datos \textbf{de todas las fuentes en todo momento}, de modo que si uno de los sensores falla, el sistema \textbf{se congela} debido a que se dejan de recibir mensajes de dicha fuente.

Se ha decidido sustituir dicha clase por \textit{MessageFiltersCache} de la misma librería \cite{MFC}. En esta nueva implementación, cada nodo posee una caché en la que se almacenan sus mensajes, que pueden recuperarse especificando un timestamp.

El código \ref{coud:cash} implementa una función (\textit{process}) que recoge los datos de las cachés a una frecuencia fija (ejemplo: 10 Hz), de modo que se recuperan los últimos mensajes de los sensores que emitieron dentro del intervalo, sin esperar por sensores que hayan sufrido latencias o fallos.

Se otorga una ventana de 500 ms para mensajes que llegan con cierto retardo antes de su descarte. Si un nodo no procesa y envía su mensaje antes de acabar el intervalo (ejemplo: 100ms), \textbf{se sigue aplicando el último mensaje recibido de este}, siempre y cuando no se exceda la ventana de tiempo ya comentada.

\section{Migración a ROS 2}
\label{subsec:ROS2}

Con el motivo del fin de soporte de ROS 1 \cite{ROSEOL}, se ha optado por migrar el sistema para ser ejecutado en ROS 2 con el fin de mantener su continuidad.

El proceso de migración se ha llevado a cabo por medio de la guía oficial de \acrshort{ros} \cite{ros2tuto}. Muchos de los problemas encontrados en este proceso están relacionados con los nuevos archivos de configuración.

Se han migrado los nodos cámara e integrador. El proceso incluye cambiar las firmas de las funciones, sus parámetros y cambiar de paquetes. En esencia, la mayoría de paquetes de \acrshort{ros} 2 preservan las mismas funcionalidades e incluso mantienen las mismas interfaces de las funciones de \acrshort{ros} 1, lo que ha facilitado la correcta migración.

La migración del nodo \acrshort{lidar} no ha sido posible, debido a que el código depende de versiones de librerías no soportadas a partir de la versión 22.04 de Ubuntu y de muchos componentes de \acrshort{ros} 1, eliminados en \acrshort{ros} 2. Sería necesario rediseñar todo el código o optar por un paquete de \acrshort{ros} 2 con las mismas funcionalidades que el paquete \textit{hdl\_people\_tracking}, utilizado en \cite{andrew} para detectar personas en nubes de puntos \acrshort{3d}.

En ROS 2 se ha introducido la posibilidad de escribir scripts de lanzamiento en Python. El archivo de lanzamiento del sistema se ha convertido del formato \acrshort{xml} a un script de Python para aprovechar la flexibilidad que el propio lenguaje ofrece y utilizar las nuevas funcionalidades. %Ref a esto: https://docs.ros.org/en/foxy/How-To-Guides/Launch-file-different-formats.html#launch-file-examples