\chapter{Implementación del sistema}
\label{chap:impl}

\lettrine{E}{n} este capítulo se ahonda en los detalles de implementación de ciertos componentes que se han considerado relevantes de comentar.

TODO: explicar en algún momento que implementamos el reconocimiento adaptativo como módulo por separado del sistema, y que realmente a excepción de la escalabilidad y el ROS 2, el sistema sigue igual.

\section{Códigos de inferencia para el \textit{backend} de TensorRT}
En la figura \ref{fig:finalsys} se muestran los 4 modelos utilizados en el nodo cámara y que se detallarán en la sección \ref{sec:models}. Dichos modelos cuentan con su implementación optimizada para OpenVINO creada en \cite{andrew}, excepto para el modelo de detección de caras, que se ejecuta en el \textit{backend} de OpenCV. En este proyecto se han implementado nuevas versiones adaptadas para su uso en \acrshort{gpu} por medio de TensorRT y PyCUDA.

El código \ref{coud:trtskel} muestra el esqueleto de dichas inferencias, cada vez que se crea una instancia del modelo en Python, se reservan los siguientes recursos:
\begin{itemize}
    \item Contexto de CUDA: en este caso se recibe como parámetro, ya que es necesario crear dicho contexto en el mismo código donde se ejecuta el bucle infinito de ROS (ejemplo: nodo cámara), de modo que pueda manejarse correctamente.
    \item Contexto del modelo: dicho contexto se crea a partir del \textit{engine} de TensorRT compilado para el modelo.
    \item CUDA Stream: canal que utilizará la \acrshort{gpu} para ejecutar todas las inferencias.
    \item Input size: memoria del \gls{tensor} que representa los datos de entrada.
    \item Output size: memoria del \gls{tensor} que representa los datos de salida.
    \item Device input: memoria del \gls{tensor} de entrada reservado en la \acrshort{gpu}.
    \item Device output: memoria del \gls{tensor} de salida reservado en la \acrshort{gpu}.
    \item Bindings: lista de direcciones de memoria de los \glspl{tensor} que reservará el contexto del modelo.
\end{itemize}

Dichos recursos se reservan \textbf{una sola vez}, que corresponde con el momento de creación de la instancia del modelo.

La función infer del código \ref{coud:trtskel} se ejecuta por cada vez que se recibe una imagen de entrada a procesar. Se reserva un array de NumPy para almacenar la salida de la inferencia y se ejecuta la función PREPROCESING con la imagen de entrada, que representa el pipeline de preprocesado específico para cada modelo. La imagen preprocesada se copia a la memoria de la \acrshort{gpu} y se realiza la inferencia en el stream de CUDA correspondiente. Finalmente, los resultados se copian de vuelta a la memoria principal y se devuelven tras ejecutar el pipeline de postprocesado definido en la función POSTPROCESING.

\input{contenido/codes/trtskel.tex}

\section{Creación de las SVM}
\label{sec:training}

El código \ref{coud:training} corresponde al proceso seguido a la hora de crear y entrenar nuevos clasificadores. De todas las muestras de individuos de la base de datos, se \textbf{excluyen las del propio sujeto} en el caso de crear una \acrshort{svm} para un comité existente. Posteriormente, se extrae un subconjunto aleatorio de estas (función random\_pick), que representará al conjunto de muestras negativas del entrenamiento. Finalmente, se crea la \acrshort{svm} y se entrena con el conjunto de positivos (variable d1) y negativos, etiquetados con 1 (variable labels) y -1 (variable plabels) respectivamente. De esta forma, cuando el clasificador determine que las muestras pertenecen a la clase que representa, devolverá como máximo una puntuación de -1, en caso contrario devolverá un 1 TODO: no sé porqué se comporta al revés. Este comportamiento se ha aplicado simplemente por comodidad, pero la \acrshort{svm} podría entrenarse para que cause el efecto contrario.

La función comentada se invoca durante la inicialización del sistema y cuando se llama al módulo de actualización, o lo que es lo mismo, cada vez que se necesite crear un nuevo clasificador a registrar en el sistema.

\input{contenido/codes/training.tex}

\section{Seguimiento y reidentificación}
La implementación sigue el flujo expuesto en la sección \ref{sec:tracker}.

Para realizar una asignación óptima del método húngaro, se utilizó la función \textit{linear\_sum\_assignment} otorgada por el módulo \textit{optimize} de la librería SciPy.TODO: la complejidad está en O(n3). El cálculo del \acrshort{iou} es realmente sencillo y no entraña ninguna complejidad computacional. La distancia euclidiana se calcula como se expone en la sección \ref{subsec:reiden}, para el cálculo de la raiz cuadrada se empleó la función \textit{sqrt} de la librería \textit{math}.

\section{Módulo de valoración}

La implementación sigue el funcionamiento descrito en la sección \ref{sec:val}. Para calcular los percentiles y la mediana se utilizan las funciones \textit{percentile} y \textit{median} respectivamente de la librería NumPy.

\section{Módulo de reconocimiento}

Esta función determina si la entidad detectada se corresponde a un individuo previamente reclutado o a una entidad \textbf{desconocida} (sección \ref{sec:reckon}).

El código \ref{coud:weib} (función RDF) muestra la implementación de dicha función. Del conjunto de scores ordenados, se excluye el primer score de la distribución (que corresponde con el más bajo, por lo tanto el mejor) y se compone la distribución de distancias de cada puntuación respecto a la mediana. De los puntos de la distribución, se obtienen los parámetros \textit{shape} y \textit{scale}, que modelan la función de Weibull. Finalmente, se calcula la probabilidad de pertenencia del mejor score a la distribución (función weib) y se toma la decisión en base a un umbral (Tw). Si la probabilidad es inferior al umbral, se reconoce el caso como un extremo y se asigna la identidad correspondiente al sujeto (\textit{drift}), en caso contrario se devuelve como desconocido (\textit{unknown}).

\input{contenido/codes/weib.tex}

\section{Módulo de actualización}

La implementación del módulo sigue el flujo descrito en la sección \ref{sec:reckon}. La creación de las \acrshort{svm} se realiza a partir de la función \textit{def\_svm} vista en la sección \ref{sec:training}.

\section{Módulo de limitación}
Este módulo se activa cuando se crea una nueva \acrshort{svm} en la actualización para un comité existente y este excede el límite prefijado de clasificadores. Se invoca a la función que calcula el criterio de favorabilidad, que a su vez invoca a los criterios de diversidad y coherencia para el comité. Se fusionan los resultados de dichos criterios, almacenados en un array de NumPy de longitud igual al número de clasificadores, multiplicados por las constantes $\alpha$ y $\gamma$ a 1. Finalmente, se ordenan los valores devueltos mediante la función \textit{argsort} de NumPy, por lo que la \acrshort{svm} a eliminar se corresponde con la primera entrada del vector (es decir, el valor de favorabilidad más bajo).

\section{Inicialización de personas registradas}
Como se ha comentado en la sección \ref{sec:initarch}, la base de datos de usuarios se puede inicializar de un modo supervisado o no supervisado. Para que el algoritmo de clasificación y el método de reconocimiento funcionen, es necesario disponer de varias muestras representativas del individuo (a partir de ahora este parámetro se definirá como \textbf{tamaño de plantilla}).

En el modo supervisado, se cuenta con un directorio con las muestras (recortes de caras y/o cuerpos) agrupadas por subdirectorios para cada usuario. Se inicializa la base de datos con los \glspl{embedding} generados por los modelos de reconocimiento para cada muestra, tras obtener los \glspl{embedding} de todos los usuarios, se entrenan las \acrshort{svm} que compondrán los comités iniciales. El conjunto de positivos de dichos clasificadores se compone de las muestras del propio usuario, mientras que el conjunto de negativos se corresponde con una selección aleatoria de las muestras del resto de individuos. La creación de los clasificadores se realiza con la función \textit{def\_svm} vista en la sección \ref{sec:training}.

En el modo no supervisado, se parte puramente de la información de las cámaras en el momento de ejecución del sistema, en el caso de las pruebas realizadas se utilizan los frames de los videos grabados. Se recoge el mismo instante del video (frame) de todas las cámaras operativas y se aplica el respectivo modelo de detección, si el número de individuos detectados supera un valor mínimo prefijado (5 en este caso, ya que es el mínimo necesario de puntos para que Weibull pueda converger), se aplica el módulo de seguimiento y reidentificación para una cantidad de frames prefijada (generalmente un valor superior al \textbf{tamaño de plantilla}), de forma que se agrupan los recortes (o \glspl{bbox}) generados según el individuo. Dichos recortes se filtran basándose en una serie de condiciones, como que el recorte se encuentre parcialmente fuera del rango de visión de la cámara, o que el ancho de la \gls{bbox} sea más largo que el alto. Finalmente, si no se ha logrado recolectar un mínimo de \glspl{bbox} para un mínimo de usuarios, el sistema descarta todas las muestras adquiridas y empieza sin ningún conocimiento.

TODO: poner algún extracto de código?

\section{TODO: Escalabilidad y tolerancia a fallos de las cámaras}
Cuando se fusionan los resultados procesados por los distintos sensores (nodo integración de sensores en la figura \ref{fig:finalsys}), se requiere que todos ellos se encuentren \textbf{sincronizados} dentro de un intervalo temporal (ejemplo: 100 milisegundos), de forma que las predicciones no se realizan a partir de información desactualizada. En \cite{andrew} se utiliza una clase del paquete \textit{message\_filters} de \acrshort{ros} llamado \textit{ApproximateTimeSynchronizer}. Esta clase utiliza un algoritmo para emparejar mensajes a partir de su \gls{timestamp} \cite{ApproximateTime}. El problema de \textit{ApproximateTimeSynchronizer} es que espera recibir datos \textbf{de todas las fuentes en todo momento}, lo que no es una situación realista y que puede provocar una caída del sistema en el momento que uno de los sensores falle. Como solución a este problema, se ha realizado una sustitución por la clase \textit{MessageFiltersCache} de la misma librería \cite{MFC}. En esta nueva implementación, cada nodo posee una caché en la que se almacenan sus mensajes, a una frecuencia establecida se recuperan los datos de todas las cachés, TODO: si en una de las cachés el último dato no se corresponde con el intervalo actual, este no se tiene en cuenta para dicho intervalo. El código \ref{coud:cash} muestra la implementación de dicho mecanismo.

\input{contenido/codes/cash.tex}

\section{Migración a ROS 2}
\label{subsec:ROS2}

Con el motivo del fin de soporte de ROS 1 \cite{ROSEOL}, se ha optado por migrar el sistema para ser ejecutado en ROS 2 con el fin de mantener su continuidad. El proceso de migración se ha llevado a cabo por medio de la guía oficial de \acrshort{ros} \cite{ros2tuto}. Se han migrado los nodos cámara e integrador, la migración del nodo \acrshort{lidar} requeriría actualizar el código a una versión soportada para Ubuntu 22.04 de la librería pcl, entre otros detalles que llevarían a rediseñar casi todo el código. Por último, el sensor \acrshort{lidar} instalado no es compatible con \acrshort{ros} 2, lo que impide la migración a menos que se haga un recambio.