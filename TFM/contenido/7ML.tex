\chapter{Reconocimiento facial adaptativo}
\label{chap:adaptation}

\lettrine{E}{n} este capítulo se ahonda en los fundamentos y detalles de implementación de la funcionalidad \textit{Open-World} y demás componentes para otorgar la adaptación.

\section{Fundamentos}
\label{subsec:erikfounds}

TODO: El método propuesto en \cite{Erik} y que conforma la base del sistema implementado, ha sido probado en un contexto de video vigilancia bajo el \textit{\gls{dataset}} \textbf{FACE COX} \cite{cox}. También se ha utilizado el \textit{\gls{dataset}} \textbf{Youtube Faces} (YTF) \cite{ytf} que, a diferencia del anterior, se encuentra accesible de forma pública. En este proyecto se utiliza un \textit{\gls{dataset}}\dots
El método utiliza \textbf{secuencias de video} como entrada para devolver las predicciones acerca de un IoI o para determinar una identidad desconocida.

La figura \ref{fig:FITS}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FITS.jpg}
    \caption{Ejemplos de distribuciones del \acrshort{evt} y como el umbral (Tw) distingue entre un desconocido (\textit{unknown} y una deriva (\textit{drift})).}
    \label{fig:FITS}
\end{figure}

\subsubsection{Comités de SVM}
TODO: Se basa en el concepto de que múltiples \acrshort{svm} simples (ejemplo: lineales) como conjunto (\textbf{comité}) \textbf{generalizan mejor} que una única \acrshort{svm} compleja (ejemplo: sigmoide) \cite{malisiewicz2011ensemble}. Otras ventajas de los comités son la incorporación de nueva información sin tener que re-entrenar las \acrshort{svm}, lo que recorta una cantidad de tiempo significativa durante la operación del sistema, y la flexibilidad, que permite eliminar parte de la información que no es relevante borrando la \acrshort{svm} redundante. Para cada IoI se asigna un comité de \acrshort{svm}, cada \acrshort{svm} del comité se entrena con n muestras de la propia entidad (1 en la idea original \cite{malisiewicz2011ensemble}, 5 adaptado a este proyecto) y \textbf{m-n} muestras negativas (fotogramas de otras entidades), siendo \textbf{m} el número de IoI registrados en el sistema.

\section{Arquitectura del sistema adaptativo}
\label{sec:adaptarch}

En la figura \ref{fig:FACESYS} se muestra la arquitectura del sistema con adaptación a los cambios. De manera resumida, el sistema se encarga de evaluar si la persona detectada en la secuencia es un desconocido o pertenece a la base de datos. En ambos casos, el sistema se actualiza con la nueva información en forma de un nuevo registro en el sistema si es un desconocido o modificando el registro existente ante los cambios de la entidad (lo que se conoce como \textit{\textbf{concept-drift}}). A continuación se detallan todos sus componentes.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FACESYS.jpg}
    \caption{Diseño del sistema adaptativo}
    \label{fig:FACESYS}
\end{figure}

La mayoría de los componentes se han implementado basándose en \cite{Erik} TODO: como menciono también a César?.

\subsection{Inicialización}

TODO: figura?

En esta primera fase del sistema se crean los registros que representarán a los individuos iniciales. En este proyecto se han probado 2 aproximaciones:
\begin{itemize}
    \item \textbf{Supervisado}: el operador realiza una selección de los frames más representativos para cada individuo.
    \item \textbf{No supervisado}: el sistema recoge los frames cuando aparecen un mínimo de 5 entidades simultaneas en escena (el mínimo necesario de puntos para poder aplicar Weibull). A partir de los frames de las cámaras, que estarán sincronizadas, se obtienen las \glspl{bbox} que encierran los rostros y se procede a la creación de los comités con los recortes de caras generados. \textbf{No se requiere de ninguna intervención del operador}, el sistema realiza la selección en base a unos criterios preestablecidos (ejemplo: la cara debe estar completamente dentro del rango de la cámara). En esta aproximación, es crucial el método de seguimiento (tracking) para recolectar las secuencias de caras.
\end{itemize}

Independientemente de la aproximación escogida, se obtienen las características de cada frame de la secuencia y se crea la \acrshort{svm} inicial con la que se \textbf{inicializa el comité}. Dicha \acrshort{svm} se entrena con las características del usuario, que compondrá el set positivo, y un subconjunto de las características del resto de usuarios, que compondrá el set de negativos (escogidas aleatoriamente). Dichas características son generadas por el modelo ArcFace \cite{deng2019arcface}, es la misma red que se utiliza en \cite{Erik, andrew} y que ha demostrado ser de las mejores en el \acrshort{sota} del reconocimiento facial.

La \acrshort{svm} inicial es la que define la identidad del comité. Si dicha \acrshort{svm} está compuesta por recortes de caras de baja calidad (ejemplo: borrosas o parcialmente ocluidas), entonces el comité \textbf{no estará bien definido} y, por lo tanto, generará \textbf{mayor confusión} a la hora de aplicar Weibull para los reconocimientos.

El resto de módulos del sistema que se exponen a continuación se ejecutan por cada secuencia de caras recolectada en cada secuencia de frames (figura \ref{fig:FACESYS}).

\subsection{\textit{Ensemble Decision Function} (EDF)}

Es el módulo encargado de devolver una representación comparable de cada individuo que será aplicada en la decisión de reconocimiento.

Por cada secuencia de entrada, siendo esta una secuencia de \textit{\glspl{embedding}} extraídas de los recortes faciales (figura \ref{fig:FACESYS}), se calculan las \textbf{puntuaciones (scores) para cada comité}. La puntuación de un comité es a su vez un valor consensuado entre los resultados de las predicciones de las \acrshort{svm} que lo conforman, el criterio de consenso (o de fusión) se basa en un percentil (generalmente la media). Aplicar percentiles es igual a escoger un conjunto amplio o reducido de \acrshort{svm}, ya que pueden existir \acrshort{svm} dañinas para el comité (ejemplo: corresponden a otra persona), los percentiles ayudan a descartar los resultados de dichas \acrshort{svm}. Para cada comité, se ejecutan las siguientes funciones:
\begin{itemize}
    \item \textbf{FDF} (Frame Decision Function): se calculan los scores de cada \acrshort{svm} contra \textbf{un frame} de la secuencia y se fusionan las salidas (o puntuaciones) en una única puntuación del comité para dicho frame. Antes de la fusión, se aplica la normalización Euclidiana (figura \ref{eq:l2norm}) a cada puntuación con el fin de hacerlas comparables.
    \item \textbf{SDF} (Sequence Decision Function): se encarga de fusionar todas las puntuaciones de la anterior función para obtener un único resultado que representa a la \textbf{secuencia}.
\end{itemize}

\[ s_{i} = \frac{x_{i}}{\left\| x_{i}\right\|_{2}} \]
\captionof{figure}{Normalización L2, siendo $x_{i}$ un \textit{\gls{embedding}} o la salida de una \acrshort{svm}, se obtiene el vector normalizado $s_{i}$.}
\label{eq:l2norm}

\subsection{\textit{Recognition Decision Function} (RDF)}
Esta función determina si la entidad detectada se corresponde a un individuo previamente reclutado o a una entidad \textbf{desconocida}.

(TODO: va en fundamentos) Las \acrshort{svm} sólo pueden discernir dentro del conjunto de datos con las que fueron entrenadas (\textit{Closed-Set}), por lo que un dato desconocido se clasificaría erróneamente como una de las clases del entrenamiento \cite{rudd2017extreme}. Varias investigaciones \cite{rudd2017extreme, scorenorm} TODO: (y en \cite{Erik}) utilizan el \textbf{\textit{\acrfull{evt}}} o teorema de Fisher–Tippett–Gnedenko para identificar clases no reclutadas. El \textit{Extreme Value Theory} determina que el conjunto de máximos o mínimos de una muestra sigue una distribución de \textbf{Weibull}. El \acrshort{evt} otorga un conocimiento robusto, ya que convierte scores concretos de un algoritmo (en este caso las \acrshort{svm}) en probabilidades que siguen una teoría estadística. Esto permite la \textbf{fusión de datos de diferentes fuentes} como nuevas redes de reconocimiento o nuevas cámaras diferentes a las Kinect en el sistema.

La distribución de Weibull se modela a partir de las puntuaciones devueltas por cada comité (salida de la función EDF) \textbf{excepto la mejor puntuación} de todos los \textit{ensembles} (que se corresponde con la más baja). Debido a que la entidad en cuestión solo puede coincidir con un comité, se comprueba si el mejor resultado (o lo que se presupone la entidad de la secuencia) \textbf{es un extremo} respecto de la distribución de puntuaciones no coincidentes (resto de \textit{ensembles}), en caso afirmativo, se asigna la etiqueta del usuario del comité con la mejor puntuación, en caso contrario, el individuo se considera \textbf{desconocido} (no coincide con ningún comité). Para determinar si la puntuación es un extremo, se calcula la probabilidad (\gls{pdf}) del mejor score a partir de la función \gls{pdf} con los parámetros obtenidos de la distribución de Weibull modelada. Si el \gls{pdf} se encuentra por debajo de un umbral (Tw), la puntuación se considera que está \textbf{al extremo de la distribución} \cite{scorenorm}.

TODO: El algoritmo compone una función de Weibull ajustando los parámetros de la misma para que converga con la cola de la distribución. Dicha distribución está formada por las distancias de cada puntuación con la mediana, excluyendo la puntuación más baja (siendo teóricamente la puntuación que coincide para la entidad) y las puntuaciones por encima de la mediana. Finalmente, se determina la probabilidad de pertenencia de la puntuación más baja de la distribución, si la probabilidad es lo suficientemente baja como para concluir que no pertenece a la distribución, entonces el reconocimiento es correcto y se asigna la entidad. En caso contrario, se concluye que la entidad es desconocida. Se establece un threshold (Tw, como se muestra en el algoritmo \ref{coud:weib}).

\input{contenido/codes/weib}

(TODO: explicación?) El Extreme Value Theory  determina que el valor \textbf{máximo} de una muestra sólo puede converger en una de las siguientes tres distribuciones: Fréchet, Gumbel o Weibull. Cada una de estas distribuciones poseen propiedades únicas (ejemplo: Fréchet es una distribución cuya cola decrece en menor medida que la de Gumbel) que las hacen adecuadas para determinados campos de estudio (TODO: ejemplo: Fréchet para predicción de inundaciones). TODO: En el campo del reconocimiento de personas, sería interesante hallar el mínimo por el que se puede determinar si cierto individuo pertenece o no a la distribución. Para este proyecto, el mínimo es la \textbf{mínima distancia entre el punto y el hiperplano creado por la \acrshort{svm}}, como se aplican varias \acrshort{svm}, el valor final será una fusión de distancias del conjunto de \acrshort{svm}. Como la muestra sólo puede pertenecer a una entidad, entonces se deberían de obtener resultados no coincidentes con el resto de individuos registrados. La distribución de los valores mínimos, en este caso los resultados no coincidentes, sigue una de las 3 distribuciones ya comentadas (TODO: es la de Weibull porque el comportamiento de la cola es acotado, es decir, hay un cierto valor x que devuelve 0).

\subsection{Update Module}
Es el módulo que implementa la actualización de los comités tras el reconocimiento realizado en la anterior función. Dado un valor c, siendo este el resultado de la función RDF, pueden darse los siguientes dos escenarios:
\begin{itemize}
    \item \textbf{Entidad conocida (c<Tw)}: se crea una nueva \acrshort{svm} que
          será incluida en el comité ganador (el que tiene la puntuación más baja).
          La \acrshort{svm} se entrena con los \textit{\glspl{embedding}} de la secuencia de entrada como
          conjunto de positivos. Como conjunto de negativos, se realiza un muestreo aleatorio de \textit{\glspl{embedding}} \textbf{del resto de comités}.
    \item \textbf{Entidad desconocida (c>Tw)}: se crea una \acrshort{svm} en un nuevo comité representando a la entidad.
          El conjunto de positivos es el mismo que en el caso anterior. En el caso de los negativos,
          las muestras de cualquier comité son válidas.
\end{itemize}

Una condición necesaria para que este módulo se ejecute es que la
secuencia de entrada para el individuo \textbf{contenga un mínimo de frames para su inicialización},
dicho mínimo es fijado por el operador de antemano. Otra precondición,
que aplica a las entidades conocidas, es comprobar si las caras (o muestras) a añadir son lo suficientemente representativas.
Las puntuaciones cerca del cero indican que las muestras se encuentran en el borde de lo que es nuevo y lo que la \acrshort{svm}
ya conoce. A partir de un valor de umbral (\textit{update\_th}) se decide si dichas muestras añaden información nueva al comité.

\textbf{El tamaño del conjunto de positivos y de negativos es prefijado por el operador.}

\subsection{Limitation Module}
\label{seq:limmod}

El limitation module es una función que se encuentra inherente al módulo de actualización. Si un comité excede un número prefijado de \acrshort{svm} almacenadas, se toma una decisión para eliminar una de las \acrshort{svm} según los siguientes criterios:
\subsubsection{Diversidad}
Este criterio mide el valor de aportación de una \acrshort{svm} respecto al resto del comité. Se coge un conjunto aleatorio de n \textit{\glspl{embedding}} (siendo n=50) de entre todos los comités y se generan los scores utilizando las m \acrshort{svm} del comité, lo que resulta en n*m scores. TODO: \textbf{Basándose en el signo de los scores}, se acumula el producto de los signos entre scores, de forma que un valor discordante afecta en mayor medida a la propia \acrshort{svm} y en menor medida al resto de \acrshort{svm}. Un valor alto indica bajo nivel de diversidad, por ende un valor \textbf{pobre de aportación al comité}. La figura \ref{fig:diversity} muestra la fórmula de diversidad, que se calcula como en \cite{Erik}.

\begin{figure}
    \centering
    \includegraphics[width=0.75\linewidth]{imagenes/Diversity.png}
    \caption{Fórmula de diversidad, extraída de \cite{Erik}}
    \label{fig:diversity}
\end{figure}

\subsubsection{Coherencia}
Este criterio viene a determinar la precisión de una \acrshort{svm} en el reconocimiento cuando no se dispone de un \textit{\gls{dataset}} para su evaluación (ejemplo: entorno operacional). El valor de coherencia determina cuantas veces una \acrshort{svm} devuelve el mismo signo que el resultado consensuado del comité, si los signos coinciden, se suma 1 al valor de coherencia, en caso contrario, se resta -1 a dicho valor. Un valor alto indica buena precisión. En la creación de una \acrshort{svm}, este valor se inicializa a 0.

\subsubsection{Favorabilidad}
Finalmente, los dos criterios se fusionan en un valor llamado \textbf{índice de favorabilidad}, la \acrshort{svm} con el menor valor de dicho índice \textbf{se elimina del comité}. El signo del valor de diversidad \textbf{se invierte} a la hora de la fusión.

\subsection{Creación de nuevos comités (\textit{Open-World})}
Cuando se reconoce a un usuario como desconocido (supuestamente un individuo no antes reclutado), se registra su identidad en forma de un nuevo comité con una \acrshort{svm} inicial. De esta forma, el sistema adquiere la capacidad de expandir su conocimiento a partir de personas nunca antes vistas. Dicha \acrshort{svm} inicial tiene de muestras positivas las de la propia secuencia actual y de muestras negativas las del resto de individuos ya conocidos.

\section{Coherencia entre múltiples cámaras}
Contar con más de una cámara permite realizar un mayor número de predicciones (amplía los grados de visión), cada una de ellas \textbf{más robustas} que con una sola cámara. Asumiendo ningún grado de solapamiento entre cámaras, puede afirmarse que un mismo individuo \textbf{no puede aparecer en el rango de más de una cámara} en un mismo instante de tiempo, es decir, existe una \textbf{coherencia espacio-temporal}. En base a esta afirmación, pueden detectarse errores de una misma predicción en múltiples cámaras e incluso adoptar ciertas técnicas para solucionarlas.

Cuando una incoherencia se detecta, o una o ninguna de las cámaras que han devuelto la predicción se corresponde realmente con la entidad, por lo que se procede a aplicar el siguiente método para averiguarlo:
\begin{itemize}
    \item De la lista de caras extraída de cada cámara, se escoge el frame más representativo, es decir, el de menor score.
    \item Del frame obtenido de cada cámara, se aplica la \textbf{distancia coseno} respecto a los frames de referencia de la entidad repetida y se fusionan todas las distancias en una mediana.
    \item Por cada valor de distancia, se comprueba si está por debajo de un umbral prefijado, en caso de que solo una cámara dé afirmativo, se asigna la entidad a dicha cámara, en caso negativo, se procede con el siguiente paso.
    \item Cada cámara posee un \textit{\gls{buffer}} que contiene las predicciones realizadas en la anterior secuencia. Se comprueba si la entidad actual se encuentra en dicho \textit{\gls{buffer}}, si solo una de las cámaras devuelve positivo, entonces se asigna la entidad a dicha cámara, en caso contrario, el método termina sin haber llegado a un acuerdo y se reconoce la entidad como desconocida para todas las cámaras.
\end{itemize}

La figura TODO muestra un caso real de aplicación,\dots

TODO: no es mas conveniente ejecutarlo antes del update module?

\section{otra cosa}
En resumen, todo el pipeline comentado \textbf{realiza x*j*y*z iteraciones}, siendo x el nº de personas, j el nº de frames por persona, y el nº de comités (o entidades registradas) y z el nº de \acrshort{svm} por comité \textbf{para cada secuencia de entrada}.

TODO: YuNet en OpenCV \textbf{no admite batching} (o quizá YuNet en si), varias opciones:
\begin{itemize}
    \item (Más simple) secuencial: por cada frame que se recibe, ya se procesa por YuNet y se envia la lista cuando se llame a on\_frame (sabemos que la inferencia va a tardar menos de 100 ms).
\end{itemize}
