\chapter{Sistema final}
\label{chap:finalsys}
\lettrine{E}{n} este capítulo se expone la arquitectura que se va a ejecutar en las pruebas.

\section{Arquitectura del sistema}
\label{sec:sysarch}

TODO: Los modelos vistos en el capítulo \ref{chap:cnn} forman parte de un sistema que combina los resultados generados con información de diferentes sensores, de forma que se obtienen reconocimientos robustos y persistentes en el tiempo \cite{andrew}. La figura \ref{fig:ANDRES} muestra la arquitectura del software, se recibe la información de una o múltiples cámaras, las \acrshort{cnn} vistas procesan la información \acrshort{rgb} de cada cámara (nodo cámara). Los resultados obtenidos de esta fase se contrastan con las detecciones realizadas por un modelo que procesa una \gls{pcl} otorgada por un sensor \gls{lidar} (nodo \gls{lidar}). Finalmente, se devuelve la predicción de la identidad otorgada por la información de las cámaras y se mantiene dicha predicción con la información del sensor \gls{lidar} cuando la identidad sobrepasa los límites de visión de las cámaras (nodo integrador). La información de distancia de las cámaras se transforma al mismo marco de coordenadas del sensor \gls{lidar}, de modo que las coordenadas de un individuo devueltas por ambos sensores se vuelven comparables.

Toda la arquitectura vista se ejecuta en el \textit{framework} \acrshort{ros} \cite{ROS}. \acrshort{ros} se encarga de crear los procesos para cada nodo, comprobar su estado, regular la frecuencia a la que trabajan, crear la red en la que dichos procesos intercambian mensajes, entre otros muchos detalles que resultan transparentes para el programador.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/SYSARCH.png}
    \caption{Arquitectura general del sistema (figura extraída de \cite{andrew})}
    \label{fig:ANDRES}
\end{figure}

\section{Escalabilidad y tolerancia a fallos de las cámaras}
Cuando se fusionan los resultados procesados por los distintos sensores, se requiere que todos ellos se encuentren \textbf{sincronizados} dentro de un intervalo temporal (ejemplo: 100 milisegundos), de forma que las predicciones no se empañan de información desactualizada. En \cite{andrew} se utiliza una librería (TODO: clase) de \acrshort{ros}, llamada \textit{ApproximateTimeSynchronizer}, esta librería utiliza un algoritmo para emparejar mensajes a partir del \gls{timestamp} \cite{ApproximateTime}. El problema de esta librería es que no es flexible, ya que espera recibir datos de todas las fuentes en todo momento, lo que no es un suceso realista y que puede provocar una caída del sistema en el momento que una cámara falle. Como solución a este problema, se ha empleado la clase \textit{MessageFiltersCache} de la misma librería a modo de sustitución (TODO: ref). En esta nueva implementación, cada nodo posee una caché en la que se almacenan los mensajes, a una frecuencia establecida se recuperan los datos de todas las cachés, TODO: si en una de las cachés el último dato no se corresponde con el intervalo actual, este se descarta.

\section{Migración a ROS 2}
\label{subsec:ROS2}

Con el motivo del fin de soporte de ROS 1 \cite{ROSEOL}, se ha optado por migrar el sistema para ser ejecutado en ROS 2 con el fin de mantener su continuidad. Se han migrado los nodos cámara e integrador, la migración del nodo \gls{lidar} requeriría actualizar el código a una versión soportada para Ubuntu 22.04 de la librería pcl, entre otros detalles que llevarían a rediseñar casi todo el código. TODO: Se probaron diferentes alternativas como RoboStack
