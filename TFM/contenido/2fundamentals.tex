\chapter{Fundamentos teóricos y tecnológicos}
\lettrine{E}{n} este capítulo se detallan las métricas de evaluación y herramientas hardware y software utilizadas, así como los conceptos necesarios para comprender el resto de la memoria.

\section{Métricas de evaluación}
\label{sec:metriks}

Para evaluar la clasificación de los modelos de visión artificial utilizados, se emplearon los siguientes componentes cuyo significado se expone a continuación:
\begin{itemize}
    \item \textit{\textbf{True Positive (TP)}}: predicción positiva correcta. Para los modelos de detección, sería detectar correctamente a una persona. Para los modelos de reconocimiento, asignar la etiqueta correcta a la persona detectada.
    \item \textit{\textbf{True Negative (TN)}}: predicción negativa correcta. Para los modelos de detección, sería no detectar correctamente a una persona, lo que carece de sentido a la hora de evaluar un buen detector. TODO (es mejor quitar esta métrica, no la uso en el sistema): Para los modelos de reconocimiento, sería predecir que la persona no pertenece a ninguna de las registradas, de aquí surge el concepto de \textbf{desconocido}.
    \item \textit{\textbf{False Positive (FP)}}: predicción positiva errónea. Para los modelos de detección, sería detectar una persona donde no la hay. Para los modelos de reconocimiento, sería otorgar una etiqueta incorrecta a la persona detectada.
    \item \textit{\textbf{False Negative (FN)}}: predicción negativa errónea. Para los modelos de detección, sería no detectar a la persona presente. Para los modelos de reconocimiento, sería asignar la entidad de desconocido a una persona ya registrada en el sistema.
\end{itemize}

Estos componentes se aplicarán a los datasets de prueba formados a partir de los videos grabados. En un entorno real de operación no sería posible aplicar dichas métricas por falta de un \textit{\gls{gt}}. %\textit{ground truth}.

\section{Evaluación de modelos}
\label{sec:modeleval}

Las pruebas empleadas para evaluar los modelos de detección y reconocimiento son las mismas que en \cite{andrew}. Teniendo en cuenta que ahora se considera el desconocido como entidad posible, en las pruebas de reconocimiento se añaden las métricas de \textit{recall} y \textit{F1\_score} al tener falsos negativos (FN) y positivos (FP).

\subsection{Modelos de detección}
\label{subsec:det}

Se aplican las siguientes métricas:
\begin{itemize}
    \item \textbf{\textit{Precision}}: \textbf{cuando el modelo detecta un objeto}, cuantas veces la detección corresponde con una persona presente.
          \begin{equation}
              Precision = \frac{TP}{TP + FP}
          \end{equation}
    \item \textbf{\textit{Recall}}: \textbf{cuando realmente hay una persona}, cuantas veces el modelo detecta a esa persona.
          \begin{equation}
              Recall = \frac{TP}{TP + FN}
          \end{equation}
    \item \textbf{\textit{F1\_score}}: dicha métrica se calcula como una media armónica entre el \textit{recall} (proporción de objetos detectados) y el \textit{precision} (proporción de detecciones correctas) \cite{andrew}.
          \begin{equation}
              F1\_score = 2* \frac{Precision * Recall}{Precision + Recall}
          \end{equation}

\end{itemize}

\subsection{Modelos de reconocimiento}
\label{subsec:recon}

Las métricas de evaluación son las mismas que en los modelos de detección, salvo las diferencias en el significado que se exponen a continuación:
\begin{itemize}
    \item \textbf{\textit{Precision}}: refleja la proporción de aciertos cuando el modelo TODO: no asigna a una persona como desconocida.
          \begin{equation}
              Precision = \frac{TP + TN}{TP + TN + FP}
          \end{equation}
    \item \textbf{\textit{Recall}}: refleja la proporción de veces que el sistema TODO: decide no asignar la entidad desconocida.
          \begin{equation}
              Recall = \frac{TP + TN}{TP + TN + FN}
          \end{equation}
    \item \textbf{\textit{F1\_score}}: lo mismo que en los modelos de detección.
\end{itemize}

Cuando el sistema tiene dudas acerca de la entidad de una persona, es preferible que se asigne dicha entidad como \textbf{desconocida} antes que otorgar una predicción \textbf{incorrecta}. Por este motivo, no se tiene en cuenta los falsos negativos a la hora de calcular la precisión, ni los falsos positivos cuando se calcula el \textit{recall}.

\section{Evaluación de la adaptación}
Como se ahondará en el capítulo \ref{chap:adaptation}, uno de los factores más importantes a analizar es la capacidad del sistema de retener la información con la que se inicializó. Existe un riesgo de que el sistema elimine toda la información con la que fue entrenado (lo que se conoce como \textit{catastrophic forgetting})

TODO: César emplea una métrica para analizar la homogeneidad de los comités, analizar el catastrophic forgeting (comprobar si el sistema no ha eliminado su memoria inicial).

\section{Hardware}
\subsection{Summit\_XL}
\subsection{Cámaras RGBD}
TODO: habremos usado las 4 kinects?
\subsection{NVIDIA Jetson}
Es una familia de \textbf{\glspl{embsystem}} pensados para aplicaciones de \gls{ia}. Dichos dispositivos incluyen un kit de desarrollo llamado \textbf{JetPack}, diseñado para exprimir la potencia de la NVIDIA Jetson en aplicaciones como la robótica, \gls{ia} generativa y visión artificial \cite{jason}.

Actualmente existe una amplia variedad en la potencia y precio de estos dispositivos \cite{jason}. Para este proyecto se han empleado cuatro modelos diferentes que se exponen a continuación (se encuentran ordenados de menores a mayores prestaciones).

\subsection{Jetson Xavier NX}

Specs \cite{jxavier}

\gls{cpu}: 6-core NVIDIA Carmel Armv8.2 64-bit CPU 1.9 GHz

\gls{gpu}: 384-core NVIDIA Volta™ architecture GPU with 48 Tensor Cores 1.1 GHz

Memoria: 8GB 128-bit LPDDR4x 59.7GB/s

Red: Gigabit Ethernet

Consumo: entre 10 W y 20 W

AI Performance: 21 TOPS (TODO: en qué precisión? INT8?)

Desde 399\$ \cite{price}.


\subsection{Jetson Orin Nano}

Specs \cite{jorin}

\gls{cpu}: 6-core Arm® Cortex®-A78AE v8.2 64-bit CPU 1.5MB L2 + 4MB L3 1.7 GHz

\gls{gpu}: 1024-core NVIDIA Ampere architecture GPU with 32 Tensor Cores 1020 MHz

Memoria: 8 GB LPDDR5 128 bits 102 GB/s

Red: Gigabit Ethernet

Consumo: 7W - 15W - 25W

AI Performance: 67 TOPS INT8

Es la más barata desde 249\$ \cite{price}.

\subsection{Jetson AGX Orin}

Specs \cite{jorin}:

\gls{cpu}: 12-core Arm Cortex-A78AE v8.2 64-bit 3MB L2 + 6MB L3 CPU 2.2 GHz

\gls{gpu}: 2048-core NVIDIA Ampere architecture GPU with 64 Tensor Cores 1.3 GHz

Memoria: 64GB 256-bit LPDDR5 204.8GB/s

Red: 10 Gigabit Ethernet

AI Performance: 275 TOPS

Consumo: entre 15 W y 60 W

La placa AGX Orin aumenta considerablemente las prestaciones de memoria principal y núcleos de CPU respecto la familia NX o Nano. En las placas AGX podría ser viable entrenar modelos \gls{cnn}.

1999\$ \cite{price}.

\subsection{Jetson AGX Thor}

Specs \cite{jthor}:

\gls{cpu}: 14-core Arm Neoverse-V3AE 64-bit CPU 1 MB L2 cache per core 16 MB shared system L3 cache 2.6 GHz

\gls{gpu}: 2560-core NVIDIA Blackwell architecture GPU with 96 fifth-gen Tensor Cores Multi-Instance GPU (MIG) with 10 TPCs 1.57 GHz

Memoria: 128 GB 256-bit LPDDR5X 273 GB/s

Red: 1 puerto RJ45 de 5 Gigabit Ethernet y 1 puerto QSFP28 de hasta 4 canales x 25 Gigabit Ethernet (TODO: lo mismo que 100 Gigabit Ethernet?)

AI Performance: 2070 TFLOPS (FP4—Sparse)

Consumo: entre 40 W y 130 W

Desde 3499\$ \cite{price}


\subsection{Equipos x86}
Para las pruebas se emplearon dos equipos con las siguientes características:
\begin{itemize}
    \item \textbf{Equipo 1 (portátil personal)}: cuenta con una CPU \textbf{Intel i7 i7-12650H}, una GPU \textbf{NVIDIA GeForce RTX 3050} con \textbf{4 GB de RAM}. Tiene una memoria principal de \textbf{16 GB} y el sistema operativo Linux Mint 21.3 (equivalente a un Ubuntu 22.04).
    \item \textbf{Equipo 2 (PC del laboratorio del CITIC)}: cuenta con una CPU \textbf{Intel i7 i7-12700}, una GPU \textbf{NVIDIA GeForce GTX 1650} con \textbf{4 GB de RAM}. Tiene una memoria principal de \textbf{32 GB} y el sistema operativo Ubuntu 24.04.
\end{itemize}

\section{Software}
\label{sec:sw}

\subsection{ROS}
Robot Operating System (ROS) es un middleware (TODO: glosario?) de \textbf{código abierto} que incorpora las herramientas necesarias para la interacción y desarrollo de software en robots. Cuenta con una amplia biblioteca de distribuciones y librerías. TODO
\subsection{TensorRT}
Es un software de \textbf{código abierto} desarrollado por NVIDIA para la optimización de inferencias de modelos de IA en aceleradoras de NVIDIA. Permite ejecutar modelos entrenados en frameworks (TODO: glosario?, esta palabra también se usa más arriba) como Pytorch y Tensorflow, aunque se aconseja exportarlos al formato ONNX previamente, para aprovechar al completo las funcionalidades de este software. Se ha empleado TensorRT para optimizar la mayoría de modelos CNN tanto en equipos ARM (Jetson) como x86 (Intel).
\subsection{ONNX}
\subsection{OpenVino}
Es un software de \textbf{código abierto} desarrollado por Intel para la optimización de inferencias en CPUs (ARM,x86) y en aceleradoras de Intel (GPUs,NPUs). Permite la conversión directa de modelos entrenados en frameworks como Tensorflow y Pytorch. Se ha empleado para reducir la latencia de modelos a la hora de ejecutarlos en CPUs.
\subsection{NumPy}
Librería de Python de \textbf{código abierto} usada en este proyecto para representar imágenes y la información generada por los modelos en forma de vectores y matrices multidimensionales. Estos elementos pueden manipularse por medio de una amplia cantidad de funciones matemáticas que dicha librería ofrece.

\subsection{Scipy}
Libreria de Python de \textbf{código abierto} que implementa numerosos algoritmos relacionados con la computación científica. En este proyecto se ha usado para aplicar el método húngaro, hallar los parámetros que modelan una distribución de Weibull, calcular distancias coseno, entre muchas otras funcionalidades que dicho software ofrece.

\subsection{OpenCV}
La librería de \textbf{código abierto} por excelencia para visión por computadora de código abierto. Otorga herramientas para la obtención y procesado de las imágenes, además de un módulo de visión artificial (dnn), que incluye modelos ya entrenados de visión artificial. Dicha librería tiene implementación en CUDA (si se compila el código fuente), lo que permite ejecutar operaciones y kernels de modelos en aceleradoras de NVIDIA (ejemplo: NVIDIA Jetson).
\subsection{Docker}
Es un software de virtualización de \textbf{código abierto}. Permite realizar despliegues automatizados mediante ficheros de configuración, el software se ejecuta en un entorno aislado del sistema operativo llamado \textbf{contenedor}, dichos contenedores proporcionan seguridad y portabilidad. Esta herramienta ha sido de gran utilidad para desplegar el software del proyecto en los diferentes dispositivos.

\section{Sistema final}
TODO: El sistema final es una fusión de los modelos de la sección \ref{sec:modeleval} (en la sección \ref{sec:sysarch} se detalla su arquitectura), además de un modelo de seguimiento de personas a partir de las nubes de puntos otorgadas por un sensor \textbf{LiDAR} instalado en el robot. En el inicio de este proyecto, el sistema estaba sustentado en ROS 1 Noetic (ver sección \ref{sec:sw}), compatible con el ROS 1 Melodic instalado en el Summit\_XL. Como se comentará en la sección \ref{subsec:ROS2}, se ha realizado una migración del sistema a ROS 2. El objetivo era migrar la versión de ROS del robot en consonancia, sin embargo, debido a que la migración no es trivial y el LiDAR instalado no era compatible con ROS 2, se han migrado todos los componentes excepto el seguimiento con el LiDAR.

Las métricas para evaluar el sistema final son las mismas que en \cite{andrew}:
\begin{itemize}
    \item \textit{\textbf{Accuracy\_id}}: es la métrica \textit{precision} de la sección \ref{subsec:recon}.
    \item \textbf{Desconocidos (\textit{unks})}: esta métrica indica a qué porcentaje de detecciones no se les ha podido asignar una identidad. El objetivo es poder comparar si las variaciones en la métrica \textit{Accuracy\_id} se producen a cambio de dejar de identificar a más gente.
    \item \textit{\textbf{Precision\_det}} : se refiere a la métrica \textit{precision} definida en la sección \ref{subsec:det}.
    \item \textit{\textbf{Recall\_det}} : es la métrica \textit{recall} definida en la sección \ref{subsec:det}.
\end{itemize}

\section{Conceptos}
\subsection{Computación en el borde (Edge Computing)}
TODO: lo explico en la motivación. En proyectos en los que se demanda el procesamiento de datos en tiempo real, es imprescindible obtener los resultados de forma inmediata para la correcta operabilidad del sistema. El edge computing mantiene el procesamiento de los datos lo más cerca posible de la fuente que los suministra, un ejemplo sería tener una cámara conectada localmente a un equipo, de manera que se reduce la latencia de transmisión por la red y todo el ancho de banda que implicaría transmitir una imagen, entre otras muchas ventajas.

\subsection{Reconocimiento \textit{Open-World}}
Atendiendo a la definición de \cite{rudd2017extreme}, un sistema de reconocimiento open world debe de ser capaz de realizar las siguientes 4 tareas:
\begin{itemize}
    \item Detectar desconocidos: identificar cuando una muestra de entrada no pertenece al conjunto de datos del entrenamiento. TODO: Un ejemplo sería definir una \textbf{función de Weibull} adaptada a los datos del entrenamiento.
    \item Escoger los puntos que puedan aportar información del desconocido al modelo
    \item Etiquetar dichos puntos (con un número o un pseudónimo).
    \item Actualizar el modelo: TODO: \textbf{re-entrenar los clasificadores}.
\end{itemize}
\subsection{Redes neuronales convolucionales (CNN)}

\subsection{Reconocimiento facial}
\subsubsection{Representación de características (Feature embedding)}
Se refiere a la representación de los vectores de características (información generada por los modelos) a un espacio vectorial \textbf{más pequeño}, de forma que la relación entre los vectores dentro del espacio \textbf{no se rompa} \cite{embeddings}.

La tesis de De-SVM utiliza ArcFace sin la capa de clasificación (sección 3.4.2) \cite{Erik}.

\subsection{Aprendizaje incremental semi-supervisado}
En el campo de la visión artificial, existe una gran cantidad de parámetros que afectan al contexto de adquisición de los datos para el entrenamiento de modelos deep learning (CNN). Por desgracia, dichos modelos son susceptibles a estos cambios en el contexto. Por ejemplo, el modelo ArcFace \cite{deng2019arcface} utiliza datasets con miles de recortes de caras centradas para su entrenamiento. Sin embargo el modelo, en el contexto de este proyecto, se tiene que enfrentar a condiciones de imagen diferentes, así como tener que reconocer personas a diferentes distancias y poses. Por este motivo, es necesaria la perspectiva de la \textbf{adaptación} para generalizar el uso de CNNs a cualquier contexto.

El aprendizaje incremental \textbf{no supervisado} usa sus propias predicciones a partir de datos entrantes (datos no etiquetados) para refinar los datos ya registrados. De esta forma, el modelo se \textbf{auto-entrena}, mejorando así su capacidad de reconocimiento y eliminando la necesidad de reentrenar el modelo. Debido a que puede ser necesaria la intervención humana para etiquetar ciertas muestras, el enfoque de dicho aprendizaje se vuelve \textbf{semi-supervisado}.

Es muy importante que las imágenes recolectadas de las identidades \textbf{sean de calidad}, si no la estrategia de auto-entrenamiento \textbf{no será eficaz}.

\subsection{Support Vector Machine (SVM)}

Es un algoritmo de \textbf{clasificación} que dibuja un hiperplano entre categorías de datos, buscando siempre el mayor margen (distancia entre el punto que define la frontera de la categoría, denominado support vector, y el hiperplano), de modo que agrega cierta tolerancia al posible ruido producido. Es un \textbf{algoritmo de aprendizaje supervisado} (requiere de un conjunto inicial de datos para su entrenamiento) y conforma la unidad más básica de clasificación dentro del sistema de este proyecto \cite{SVM}.

\section{Otras herramientas}
\subsection{VS Code}
\subsection{Git}
\subsection{Trello}
\subsection{Draw.io}