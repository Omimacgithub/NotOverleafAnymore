\chapter{Conclusiones y trabajo futuro}
\label{chap:conclusiones}

\lettrine{Ú}{ltimo} capítulo en el que exponen las conclusiones de los resultados y los hitos alcanzados, así como los errores cometidos y las lecciones aprendidas. También se comentan algunas vías en las que se puede extender el trabajo de este proyecto.

\section{Conclusiones}

Se ha analizado el rendimiento de 4 redes neuronales de visión artificial en 6 dispositivos diferentes tanto en arquitecturas de procesador (x86 y \acrshort{arm}) como en arquitecturas de \acrshort{gpu}. Los resultados arrojan las grandes virtudes de la Jetson AGX Thor y de las \acrshort{gpu}s integradas, que liberan la dependencia de componentes como \acrshort{PCIe} en cuanto a las transferencias de datos y llamadas de operaciones entre \acrshort{cpu} y \acrshort{gpu}, que suponen el principal cuello de botella de los dispositivos Intel para cargas de trabajo intensivas en memoria. También se resaltan las capacidades de los dispositivos de bajo consumo (Jetson Xavier NX y Jetson Orin Nano) para lidiar con la ejecución de modelos en tiempo real una vez se exprimen sus \acrshort{gpu}s.

La potencia de las \acrshort{gpu}s han permitido escalar el sistema para detectar y reconocer personas con hasta 10 cámaras en tiempo real. Sin embargo, para la Jetson Orin Nano no se ha logrado la ejecución de 20 redes neuronales (5 cámaras por 4 redes cada una) procesando los datos de 5 cámaras simultáneamente en tiempo real. En cambio, los buenos resultados obtenidos en las pruebas con 2 cámaras demuestran su utilidad para la ejecución del sistema en tiempo real con únicamente 25 W de consumo, lo que permite al robot mantener una larga autonomía de la batería. La Jetson AGX Orin, idéntica en arquitectura a la Nano, también puede ser una excelente elección para incorporar al robot, ya que ofrece mayor potencia a un consumo eficiente de entre 30-60 W (depende del modo de energía escogido), aunque por la gran diferencia de precio (249\$ y 1999\$ Orin Nano y AGX Orin respectivamente) no resulta conveniente. El sistema originalmente no permitía escalar correctamente el número de las cámaras, debido a su intolerancia a la caída de los sensores y a que no gestionaba correctamente las detecciones provenientes de cámaras con rangos de visión parcialmente solapados, los cambios realizados en el código han sido satisfactorios a la hora de alcanzar este objetivo.

La integración del sistema en contenedores de Docker ha sido fundamental para el éxito de los análisis, ya que de otro modo no sería posible integrar el sistema en todos los dispositivos, teniendo en cuenta que 2 de ellos (AGX Orin y AGX Thor) pasaron a estar disponibles desde finales de septiembre.

Por motivos relacionados con el fin de soporte de \acrshort{ros} 1 y de poder aplicar las últimas librerías disponibles para los distintos dispositivos, se ha tenido que realizar la migración del sistema a \acrshort{ros} 2. Gracias a esta migración, el sistema puede integrarse a los nuevos robots del mercado (siempre que incorporen \acrshort{ros}) sin ningún cambio adicional en el código.

Se ha logrado incorporar un algoritmo de aprendizaje incremental para detectar y reconocer desconocidos, que son posteriormente integrados al sistema, de forma que se mantiene un registro de las personas de una instalación (en este caso el \acrshort{citic}) sin ninguna intervención humana. A pesar de los buenos resultados en la detección de desconocidos (\textit{Open-Set}) y actualización ante los cambios de las entidades existentes, los pobres resultados en la inclusión de nuevas clases (\textit{Open-World}) demuestran la incapacidad del sistema de evolucionar con el tiempo. Este problema parte de la cuestión de qué métodos se deben de adoptar para agrupar los comités duplicados. Los comités duplicados se entrenan con las muestras del propio individuo tanto en el conjunto de positivos como en el de negativos (ya que dicho individuo ya se encuentra registrado en el sistema), lo que anula el poder discriminativo de las \acrshort{svm}, traduciéndose en mayor cantidad de falsos negativos (detecciones de desconocidos), lo que prolifera aún más la creación de estos comités. Este problema no se trata en \cite{Erik,CESAR}, puesto que las condiciones controladas de los \glspl{dataset} probados mitigan la aparición de este problema, a diferencia de un entorno de operación real, con muestras enturbiadas por un ruido (ejemplo: borrosidad de la imagen) que impide extraer las características discriminativas que permiten a las \acrshort{svm} distinguir a la persona del resto del mundo.

%Por otro lado se ha observado que el sistema en el modo \textit{Open-World} es \textbf{muy sensible} a la hora de ajustar el parámetro del umbral de Weibull. Ajustando el umbral a un valor bajo, el número de comités nuevos por entidad se dispara, ya que añade incertidumbre al sistema rápidamente (puesto que no se generan casos extremos si se activa más de un comité). Un valor alto del umbral mitiga este problema, a costa de comprometer la precisión. Se podría estudiar la implementación de un nuevo criterio para agrupar los comités y así solventar esta problemática.

Para aprovechar la coherencia-espacio temporal y mejorar la capacidad de adaptación, se ha optado por abandonar el esquema de detección frame a frame de \cite{andrew} para procesar secuencias de frames (vídeos). Debido al contexto de las pruebas, que implican a múltiples individuos que se entrecruzan, se ha implementado un método para el seguimiento y reidentificación de personas. Las múltiples pruebas realizadas reflejan la efectividad del método propuesto, sobretodo en los resultados \textit{Open-Set}. Sin embargo, dicho método puede fallar cuando el robot gira en su propio eje.

%de forma que el sistema sea capaz de recolectar varias muestras y seleccionar las que mejor identifiquen al individuo y aporten a la capacidad de generalización de los comités

Con el fin de automatizar todo el proceso del sistema y poderlo desplegar rápidamente en cualquier contexto, se ha explorado un método de inicialización completamente controlado por dicho sistema (no supervisado) y se ha comparado con otro método que parte de un conjunto reducido de datos etiquetados (semisupervisado). Los resultados logran mantener la consistencia del sistema en \textit{Open-Set}, a diferencia de \textit{Open-World}, en el que dicho sistema llega a colapsar, lo que demuestra una necesidad de manejar el ruido de las muestras obtenidas durante la operación, que pueden agravar el problema de los comités duplicados.

Gracias a la realización de este proyecto, el estudiante ha adquirido conocimiento en campos como el aprendizaje máquina o la ejecución eficiente de redes neuronales convolucionales en \acrshort{gpu}s, a los que no se había enfrentado nunca antes.

\section{Trabajo Futuro}

Los nuevos componentes de la arquitectura extendida (sección \ref{sec:finalsys}) se han probado bajo un modelo de reconocimiento facial, debido a no disponer del tiempo suficiente para integrarlos en el sistema completo. La integración de dichos componentes en el sistema implicaría muchos cambios en el código, aunque no debería de afectar significativamente a la lógica del sistema base ni a la interacción con \acrshort{ros}.

El método de reconocimiento adaptativo se ha probado únicamente con características faciales, igual que en el sistema diseñado en \cite{Erik, CESAR}. Se cree que dicho método puede integrarse en el sistema mediante un enfoque multimodal, es decir, para operar con características faciales y corporales.
%Como ya se ha visto, el reconocimiento adaptativo mejora conforme se añaden nuevos usuarios al sistema. Para lograr alcanzar el techo de rendimiento del sistema, sería necesario crear un \gls{dataset} más grande, con decenas de personas, en vez de las 6 del \gls{dataset} probado.

Más allá del uso de TensorRT para optimizar y acelerar las inferencias, aún existe espacio para aprovechar al máximo las prestaciones de la \acrshort{gpu}. Podrían aplicarse métodos como la \gls{quant} de los modelos a INT8, lo que reduce la memoria del modelo y de las entradas/salidas producidas, o el uso de los \textbf{Deep Learning Accelerators (DLA)} \cite{DLA}, que son componentes hardware integrados en las NVIDIA Jetson, que permiten delegar la ejecución de ciertas capas de modelos en dichos componentes, lo que podría liberar a la \acrshort{gpu} de parte de la computación de las redes neuronales.

El método de reidentificación de entidades mediante la distancia Euclidiana reporta problemas cuando las cámaras cambian de posición (ejemplo: el robot se desplaza), ya que se guardan las coordenadas \acrshort{2d} de una persona que pasan a ocupar el lugar de otro individuo. La imagen de distancia de las cámaras Kinect puede otorgar una posición en el espacio \acrshort{3d} de forma que la posición de la persona desaparecida se mantiene.

Los resultados del sistema \textit{Open-World} indican que deben de plantearse nuevos métodos para mejorar su rendimiento. Se cree que la principal solución puede ser la integración de un método para agrupar y/o eliminar los comités duplicados que dificulten el funcionamiento del reconocimiento de personas. También podría realizarse un esfuerzo en crear un \gls{dataset} con más personas para mejorar el propio sistema de reconocimiento, en \cite{Erik} se demuestra que el rendimiento mejora al incluir más personas en el sistema, ya que más puntos definen la distribución de Weibull.

A pesar de que se ha implementado y analizado las capacidades de un sistema \textit{Open-World}, este no se ha expuesto a pruebas con una proporción significativa de desconocidos respecto a la cantidad de conocidos del \gls{dataset} (lo que se define en \cite{scheirer2012toward,Erik} como \textit{\textbf{openness}}). No se han realizado dichas pruebas, ya que se centraron los esfuerzos en intentar mejorar los resultados en las pruebas sin desconocidos. No obstante, es un buen siguiente paso (en \cite{Erik} el sistema responde de forma consistente hasta el 60\% de \textit{openness}).

A pesar de que los modelos del sistema se ejecutan en paralelo entre nodos cámara, dentro de dichos nodos la invocación es secuencial (se invoca primero a YuNet, posteriormente a YOLO, etc), por lo que se podría realizar un esfuerzo para paralelizar las llamadas a dichos modelos. En el caso de paralelizar YOLO con YuNet, la versión de OpenCV de este último no otorga muchas opciones, en cambio, si se podrían paralelizar ArcFace y OSNet para ejecutarse en diferentes \glspl{stream} de \gls{CUDA}, lo que beneficiaría especialmente a los dispositivos Jetson. Aprovechando la arquitectura de \acrshort{ros}, se optó por dividir el nodo cámara entre la parte de detección (YuNet y YOLO) y la de reconocimiento (ArcFace y OSNet), de forma que una vez se finalizan las detecciones, el nodo de detección envía el mensaje al nodo de reconocimiento y pasa a procesar la siguiente imagen recibida por la cámara. Sin embargo, no se han realizado pruebas de esta aproximación, ya requiere de una mayor reserva de memoria de la \acrshort{gpu}, debido a que se crean el doble de contextos de \gls{CUDA} respecto al modo unificado.

%En el anexo \ref{chap:coherence} se comenta la implementación de un módulo para la resolución de conflictos cuando dos cámaras \textbf{sin solapamiento} predicen al mismo individuo. Debido a la nula mejora en el rendimiento por los motivos comentados, sería necesario solventar los problemas del método de clasificación implementado, o incluso eliminarlo y replantear un método nuevo.