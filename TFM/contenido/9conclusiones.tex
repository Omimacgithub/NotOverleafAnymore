\chapter{Conclusiones y trabajo futuro}
\label{chap:conclusiones}

\lettrine{Ú}{ltimo} capítulo en el que exponen las conclusiones de los resultados y los hitos alcanzados, así como las lecciones aprendidas. También se comentan algunas líneas en las que se puede extender el trabajo de este proyecto.

\section{Conclusiones}

En este proyecto se ha conseguido el primer objetivo planteado: el desarrollo de un sistema de detección y reconocimiento de caras sobre secuencias de imágenes de múltiples cámaras en un robot móvil con capacidad para adaptarse a su entorno.
Para ello se ha propuesto la integración y mejora de dos sistemas previos. Por un lado, se han mejorado las capacidades del reconocimiento de personas mediante la integración del método de aprendizaje incremental planteado en \cite{Erik}, que permite al sistema reconocer e incorporar a nuevos individuos de manera completamente autónoma.
Por otro lado, se ha extendido el sistema propuesto en \cite{andrew} para trabajar con secuencias de vídeo, de forma que se aprovecha la coherencia-espacio temporal y se mejora el aprendizaje incremental, ya que permite la recolección eficiente de muestras para seleccionar las que más aporten al aprendizaje.

A mayores, se han desarrollado mejoras específicas para conseguir una operación autónoma del sistema en tiempo real.
En primer lugar, se ha implementado un método para el seguimiento y reidentificación de personas a modo de obtener las secuencias de cada individuo.
En segundo lugar, el sistema original no permitía escalar el número de las cámaras, debido a su intolerancia a la caída de los sensores y a que no gestionaba correctamente las detecciones de cámaras con visiones parcialmente solapadas, por lo que hemos propuesto mejoras en el proceso de integración de la información que han hecho al sistema mucho más robusto. %  Los cambios realizados en  han sido satisfactorios a la hora de alcanzar este objetivo.
En tercer lugar, con el fin de soporte de ROS1 y para poder seguir usando las mejoras y las nuevas librerías  se ha realizado la migración del sistema a ROS2. De este modo, el sistema se puede mantener fácilmente actualizado y permite integrarse en nuevos robots o con nuevos sensores.
En cuarto lugar, y con el fin de facilitar y automatizar el despliegue y operación de nuestro sistema en cualquier contexto, se ha propuesto un nuevo método de inicialización no supervisado,  en el cual es el propio sistema el que, durante su operación, establece cuándo y cómo inicializar sus componentes (básicamente cuando detecta simultáneamente a un número significativo de individuos). En el método original un operador experto es el encargado de seleccionar y etiquetar un conjunto reducido de datos o muestras para realizar la inicialización.
En quinto lugar, se ha dockerizado todo el sistema, lo que ha facilitado y acelerado enormemente su adaptación y despliegue en nuevos dispositivos.

El segundo gran objetivo de este proyecto ha consistido en evaluar el rendimiento de todo el sistema y de sus componentes principales. Las pruebas se han articulado en tres grandes evaluaciones, todas ellas realizadas con los datos obtenidos de la interacción del robot móvil con varias personas en el laboratorio del CITIC. Durante dicho experimento, seis personas se mueven constantemente durante unos 105 segundos y se entrecruzan entre sí mientras el robot gira y se desplaza. La grabación de los datos de todos los sensores en un fichero rosbag ha posibilitado realizar las evaluaciones en condiciones totalmente controladas.

%
En la primera evaluación se ha analizado pormenorizadamente el rendimiento de las cuatro redes neuronales de visión artificial de nuestro sistema en seis dispositivos con diferentes arquitecturas de procesador (x86 y \acrshort{arm}) y de \acrshort{gpu}. Los resultados reflejan las grandes virtudes de la Jetson AGX Thor y de las \acrshort{gpu}s integradas, que liberan la dependencia de componentes como \acrshort{PCIe} en cuanto a las transferencias de datos y llamadas de operaciones entre \acrshort{cpu} y \acrshort{gpu}, que suponen el principal cuello de botella de los dispositivos Intel para cargas de trabajo intensivas en memoria. También se resaltan las capacidades de los dispositivos de bajo consumo (Jetson Xavier NX, Orin Nano y AGX Orin) para lidiar con la ejecución de modelos en tiempo real una vez se exprimen sus \acrshort{gpu}s.

En la segunda evaluación se ha comprobado hasta qué punto el sistema es escalable, es decir, se puede aumentar el número de cámaras. Para mantener las mismas condiciones experimentales, se decidió ``multiplicar'' el número de tópicos disponibles para simular más cámaras, ya que el objetivo fundamental era comprobar el rendimiento del sistema en su conjunto a nivel computacional. Debido al gran volumen de datos que se manejan en estas pruebas ha sido necesario definir un nuevo mecanismo para reproducir el fichero rosbag y enviar los tópicos por la red Ethernet de forma eficiente.

La potencia de las \acrshort{gpu}s ha permitido escalar el sistema para detectar y reconocer personas con hasta diez cámaras, un número más que suficiente para cubrir un espacio de 360º, todo ello en tiempo real. Sin embargo, para la Jetson Orin Nano no se ha logrado la ejecución de veinte redes neuronales (cinco cámaras por las cuatro redes de nuestro sistema) procesando los datos simultáneamente. En cambio, los buenos resultados obtenidos en las pruebas con dos cámaras demuestran su utilidad para la ejecución del sistema en tiempo real con únicamente 25 W de consumo, lo que permite al robot mantener una larga autonomía de la batería. La Jetson AGX Orin, idéntica en arquitectura a la Nano, también puede ser una excelente elección para incorporar al robot, ya que ofrece mayor potencia a un consumo eficiente de entre 30-60 W (depende del modo de energía escogido).
%
La integración del sistema en contenedores de Docker ha sido fundamental para el éxito de este análisis, ya que de otro modo no sería posible integrar el sistema en todos los dispositivos, teniendo en cuenta que dos de ellos (Jetson AGX Orin y Jetson AGX Thor) pasaron a estar disponibles en noviembre.

%Los resultados obtenidos demuestran que la Jetson AGX Thor puede procesar en tiempo real toda la información de hasta 10 cámaras y que podemos asumir que podría detectar y reconocer a 26 personas de forma simultánea. Por otro lado, la Jetson Orin Nano puede procesar dos cámaras, pero con un consumo energértico y a un coste realmente muy bajo, ideal para un robot móvil. La principal limitación de la Orin Nano son su 8 GB de memoria. A pesar del gran número de mejoras realizadas en el código, no ha sido posible aumentar más sus prestaciones. 


La tercera y última evaluación se ha centrado en analizar las capacidades del sistema para detectar individuos desconocidos y adaptarse. Se han comprobado múltiples combinaciones de parámetros y se han mostrado y analizado los resultados más reseñables.
A pesar de los buenos resultados en la detección de desconocidos (\textit{Open-Set}) y actualización ante los cambios de las entidades registradas, los pobres resultados en la inclusión de nuevas clases (\textit{Open-World}) demuestran la incapacidad actual del sistema de evolucionar adecuadamente con el tiempo. Este problema parte de la cuestión de qué métodos se deben de adoptar para agrupar los comités duplicados. Este problema no se trata en \cite{Erik,CESAR}, puesto que las condiciones controladas de los \glspl{dataset} probados mitigan la aparición de este problema. Como nuestra evaluación se ha realizado en condiciones normales de operación, el ruido de las muestras (por ejemplo, imágenes borrosas o en movimiento) complican que el sistema determine y extraiga las características discriminativas que permiten a las \acrshort{svm} distinguir a un individuo del resto.

En esta evaluación también se ha comparado el rendimiento del sistema con nuestro modelo de inicialización. En general, las muestras seleccionadas para entrenar las primeras SVMs son muy similares entre sí y con poca diversidad, por lo que no generalizan bien (es decir, no detectan al mismo individuo en situaciones diferentes). En el caso de \emph{Open-Set} el rendimiento final es bastante aceptable y justifica su uso.
Sin embargo, en el caso de \emph{Open-World}, la falta de diversidad acrecienta las dudas del sistema, lo que implica una mayor tasa de detección de desconocidos, lo que a su vez genera más comités y provoca un colapso del sistema.

%Por otro lado se ha observado que el sistema en el modo \textit{Open-World} es \textbf{muy sensible} a la hora de ajustar el parámetro del umbral de Weibull. Ajustando el umbral a un valor bajo, el número de comités nuevos por entidad se dispara, ya que añade incertidumbre al sistema rápidamente (puesto que no se generan casos extremos si se activa más de un comité). Un valor alto del umbral mitiga este problema, a costa de comprometer la precisión. Se podría estudiar la implementación de un nuevo criterio para agrupar los comités y así solventar esta problemática.

%de forma que el sistema sea capaz de recolectar varias muestras y seleccionar las que mejor identifiquen al individuo y aporten a la capacidad de generalización de los comités

%Los resultados logran mantener la consistencia del sistema en \textit{Open-Set}, a diferencia de \textit{Open-World}, en el que dicho sistema llega a colapsar, lo que demuestra una necesidad de manejar el ruido de las muestras obtenidas durante la operación, que pueden agravar el problema de los comités duplicados.

Gracias a la realización de este proyecto, el estudiante ha adquirido conocimiento en campos como el aprendizaje máquina o la ejecución eficiente de redes neuronales convolucionales en \acrshort{gpu}s, a los que no se había enfrentado nunca antes.

\section{Trabajo Futuro}

A raíz del trabajo realizado se abren múltiples líneas de desarrollo posibles para mejorar los resultados obtenidos. A continuación se exponen las que se consideran más relevantes.

Los nuevos componentes de la arquitectura extendida (sección \ref{sec:finalsys}) se desarrollaron y probaron de forma independiente. Queda pendiente su integración en el sistema. % y, por tanto, con el \emph{framework} \acrshort{ros}.

El nodo integración de sensores es un punto único de fallo del sistema. Sería necesario aplicar métodos de tolerancia a fallos, como una configuración activo/pasivo, que consiste en lanzar otro nodo que se mantenga en espera hasta que el nodo activo caiga, o una configuración activo/activo, de forma que ambos nodos se distribuyen la carga.

%El método de reconocimiento adaptativo se ha probado únicamente con características faciales, igual que en el sistema diseñado en \cite{Erik, CESAR}. Se cree que dicho método puede integrarse en el sistema mediante un enfoque multimodal, es decir, para operar con características faciales y corporales.
%Como ya se ha visto, el reconocimiento adaptativo mejora conforme se añaden nuevos usuarios al sistema. Para lograr alcanzar el techo de rendimiento del sistema, sería necesario crear un \gls{dataset} más grande, con decenas de personas, en vez de las 6 del \gls{dataset} probado.

Más allá del uso de TensorRT para optimizar y acelerar las inferencias, aún existe espacio para aprovechar al máximo las prestaciones de la \acrshort{gpu}. Podrían aplicarse métodos como la \gls{quant} de los modelos a INT8, lo que reduce la memoria del modelo y otorga mayor velocidad (a costa de una ligera pérdida en la precisión), o el uso de los Deep Learning Accelerators (DLA) \cite{DLA}, que son componentes hardware integrados en las NVIDIA Jetson, que permiten delegar la ejecución de ciertas capas de modelos, lo que podría liberar a la \acrshort{gpu} de parte de la computación.

El método de reidentificación de entidades mediante la distancia Euclidiana reporta problemas cuando las cámaras cambian de posición (ejemplo: el robot se desplaza), ya que se guardan las coordenadas \acrshort{2d} de la persona que pasan a ocupar el lugar de otra. La imagen de distancias de las cámaras Kinect otorga una posición \acrshort{3d} útil para localizar al individuo ante movimientos del robot.

Los resultados del sistema \textit{Open-World} indican que deben de plantearse nuevos métodos para mejorar su rendimiento. Se cree que la principal solución puede ser la integración de un método para agrupar y/o eliminar los comités duplicados que dificulten el reconocimiento de personas. También podría crearse un \gls{dataset} con más personas para mejorar el propio sistema de reconocimiento, en \cite{Erik} se demuestra que el rendimiento mejora al incluir más personas en el sistema, ya que más puntos definen la distribución de Weibull. Por otra parte, se logra disponer de más muestras negativas para las \acrshort{svm}. %Se podría implementar un método que escoja los negativos más difíciles de distinguir respecto a los positivos, de forma que las \acrshort{svm} dea las que se les podría aplicar un método de selección avanzado para obtener (lo que se conoce como \textit{hard negative mining} \cite{malisiewicz2011ensemble}).

A pesar de que se ha implementado y analizado las capacidades de un sistema \textit{Open-World}, este no se ha expuesto a pruebas con una proporción significativa de desconocidos respecto a la cantidad de conocidos del \gls{dataset} (lo que se define en \cite{scheirer2012toward,Erik} como \textit{openness}). En \cite{Erik} el sistema responde de forma consistente hasta el 60\% de \textit{openness} (50 personas registradas frente a un total de 1000 individuos).

A pesar de que los modelos del sistema se ejecutan en paralelo entre nodos cámara, dentro de dichos nodos la invocación es secuencial (se invoca primero a YuNet, posteriormente a YOLO, etc). La paralelización de la inferencia de los modelos en un mismo contexto de \gls{CUDA} podría aprovechar mejor el uso de la \acrshort{gpu} y obtener un mejor rendimiento. Debido a que la versión de YuNet del proyecto utiliza OpenCV, que no permite gestionar manualmente \gls{CUDA}, no existen muchas opciones para paralelizar su ejecución con YOLO salvo utilizar TensorRT para su ejecución (requiere de implementar los pipelines de pre y postprocesado). En cambio, si se podrían paralelizar ArcFace y OSNet para ejecutarse en diferentes \glspl{stream} de \gls{CUDA}, lo que beneficiaría especialmente a los dispositivos Jetson.
%Aprovechando la arquitectura de \acrshort{ros}, se optó por dividir el nodo cámara entre la parte de detección (YuNet y YOLO) y la de reconocimiento (ArcFace y OSNet), de forma que una vez se finalizan las detecciones, el nodo de detección envía el mensaje al nodo de reconocimiento y pasa a procesar la siguiente imagen recibida por la cámara. Sin embargo, no se han realizado pruebas de esta aproximación, ya requiere de una mayor reserva de memoria de la \acrshort{gpu}, debido a que se crean el doble de contextos de \gls{CUDA} respecto al modo unificado.

%En el anexo \ref{chap:coherence} se comenta la implementación de un módulo para la resolución de conflictos cuando dos cámaras \textbf{sin solapamiento} predicen al mismo individuo. Debido a la nula mejora en el rendimiento por los motivos comentados, sería necesario solventar los problemas del método de clasificación implementado, o incluso eliminarlo y replantear un método nuevo.