\chapter{Pruebas de escalabilidad del sistema}
\label{chap:syscal}

\lettrine{E}{n} este capítulo se realiza una evaluación del rendimiento del sistema al elevar el número de cámaras implicadas.

\section{Realización de las pruebas}

Para obtener resultados de precisión del sistema, se dispone de un \gls{dataset} que representa el \gls{gt} del nodo integración de sensores (ver sección \ref{sec:basearch}). La prueba de la que se ha extraído el \gls{dataset} corresponde con la misma del \gls{dataset} de las cámaras. En el apéndice \ref{sec:datsys} se comenta su composición.

Es importante remarcar que todas las pruebas de esta sección se realizan en \textbf{tiempo real}. Según el proyecto, la frecuencia del tiempo real puede variar, en este caso, se espera que el sistema trabaje a \textbf{10 Hz} (o 10 \acrshort{fps}), que es la frecuencia a la que ambos sensores \acrshort{lidar} y Kinect devuelven datos.

Se inicializa el sistema con el nodo integración de sensores, el nodo \acrshort{lidar} y el número de nodos cámara deseado (ver sección \ref{sec:basearch}). Se reproduce el fichero \gls{rosbag} una vez inicializado el sistema, que lo nutrirá con la información generada por los sensores en \textbf{tiempo real}. Cada predicción generada por el nodo integrador se almacena en memoria y se vuelca en un fichero \acrshort{json} una vez el sistema se detiene (por ejemplo, con un Ctrl+C). Los datos guardados en el fichero \acrshort{json} se procesan contra el \textit{\gls{dataset}} y se devuelven los resultados finales en forma de las siguientes métricas:

%En cada iteración del procesado, se ejecutan \textbf{4 redes neuronales (\acrshort{cnn})}. 2 de ellas, YOLOv8n y YuNet, para la detección de cuerpos y de caras respectivamente. Las otras 2, OSNet\_x1 y ArcFace, para el reconocimiento de cuerpos y caras respectivamente. A pesar de lo que la figura \ref{fig:finalsys} muestra, las redes de detección YOLOv8n y YuNet \textbf{no se ejecutan en paralelo}, lo mismo sucede con las redes ArcFace y OSNet\_x1. Se ha considerado ejecutar en paralelo estas redes. Sin embargo, las limitaciones de memoria principal de la Jetson restringen tomar esta aproximación.

\begin{itemize}
    \item \textit{\textbf{Det precision} (det\_p)}: es la proporción de personas detectadas en la posición correcta (campo \textit{position} del \gls{dataset}) respecto al total de personas detectadas.
    \item \textit{\textbf{Det recall} (det\_r)}: representa la proporción de personas detectadas en la posición correcta respecto al total de personas en el \gls{dataset}.
    \item \textit{\textbf{Ident F1 score} (idf1)}: corresponde con el \textit{F1\_score} global de los modelos de reconocimiento (ver apéndice \ref{subsec:recon} para más información).
    \item \textit{\textbf{Ident precision} (idp)}: corresponde con la precisión global de los modelos de reconocimiento.
\end{itemize}

La prueba del sistema da una detección como positiva si la posición predicha es igual a la del \gls{dataset} dentro de una holgura de \textbf{40 centímetros}.

Siendo \textit{det\_tp} una posición predicha correctamente, \textit{det\_fp} una posición predicha incorrectamente, \textit{n\_gt} el número total de detecciones del \gls{dataset}, \textit{id\_tp} una predicción correcta de la identidad y \textit{id\_fp} una predicción incorrecta de la identidad, se definen las siguientes métricas:
\begin{itemize}
    \item $det\_p = \frac{det\_tp}{(det\_tp + det\_fp)}$
    \item $det\_r = \frac{det\_tp}{n\_gt}$
    \item $idf1 = \frac{2 * id\_tp}{2 * (id\_tp + id\_fp + (n\_gt - det\_tp))}$
    \item $idp = \frac{id\_tp}{(id\_tp + id\_fp)}$
\end{itemize}

Los modelos de todas las pruebas realizadas en este capítulo se han ejecutado en el \gls{rt} de \textbf{TensorRT} (salvo YuNet, que utiliza CUDA por medio de OpenCV).

Para cada prueba, también se mostrará la proporción de los recursos utilizados del dispositivo durante la ejecución del sistema (las pruebas se han realizado \textbf{sin el entorno gráfico}). Se empleará la mediana de todas las lecturas de recursos en una ejecución completa del sistema, ya que es robusta frente a los picos de uso de recursos. En dispositivos Jetson, el comando \textbf{tegrastats} devuelve toda la información necesaria, en cambio, para el resto de dispositivos se obtienen de la siguiente forma:
\begin{itemize}
    \item Carga de la \acrshort{cpu}: media de las mediciones devueltas por el comando \textbf{sar -u}.
    \item Ocupación de la memoria de la \acrshort{cpu}: media de las mediciones devueltas por el comando \textbf{sar -r}.
    \item Carga de la \acrshort{gpu}: media de las mediciones devueltas por el comando \textbf{nvidia-smi}.
    \item Ocupación de la memoria de la \acrshort{gpu}: media de las mediciones devueltas por el comando \textbf{nvidia-smi}.
    \item Ancho de banda de la transferencia de datos por la red: media de las mediciones devueltas por el comando \textbf{ifstat}.
\end{itemize}

\section{Entorno de las pruebas}

Debido a que el \gls{rosbag} utilizado es un archivo pesado (41 \acrshort{gb}), en ciertas situaciones ha sido necesario reproducir dicho fichero desde una \textbf{fuente externa} al no disponer de almacenamiento local suficiente.

\begin{equation}
    (|imagen\_RGB| + |imagen\_profundidad|)*ncams + |nube\_de\_puntos\_LiDAR|
\end{equation}
\label{eq:transmision}

La comunicación con la fuente externa se realiza a través de una red \acrshort{lan} \textbf{Gigabit Ethernet}, que posee un ancho de banda limitado para la transmisión de imágenes \acrshort{rgbd} (máximo teórico de 125 \acrshort{mb}/s). La fórmula \ref{eq:transmision} muestra el tamaño de los datos que debe transmitir la fuente externa cada 100 ms (que es la frecuencia a la que trabaja el sistema). Siendo $|imagen\_RGB| = 40 \acrshort{mb}/s$, $|imagen\_profundidad| = 20 \acrshort{mb}/s$ y $|nube\_de\_puntos\_LiDAR| = 5 \acrshort{mb}/s$ (los datos se han tomado del comando \textbf{rostopic bw}), el ancho de banda necesario es de \textbf{125 \acrshort{mb}/s} para dos cámaras (\textit{ncams}=2), lo que ya \textbf{equivale} al ancho de banda máximo teórico.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/SYSTESTING.jpg}
    \caption{Reproducción y transmisión del \gls{rosbag} por la red}
    \label{fig:systesting}
\end{figure}

La figura \ref{fig:systesting} ilustra el proceso de transmisión de los datos por la red \acrshort{lan}. Para reducir el ancho de banda necesario para la transmisión, se ha optado por desplegar nodos encargados de comprimir la imagen \acrshort{rgb} desde el equipo en el que se reproduce el \gls{rosbag} (\textit{remote side} en la figura \ref{fig:systesting}). La compresión se realiza por medio del paquete \textit{image\_transport} de \acrshort{ros}, que logra reducir hasta 10 veces el tamaño de la imagen \acrshort{rgb} (resultando en 4 \acrshort{mb}/s). Los nodos cámara (\textit{host side} en la figura \ref{fig:systesting}) se suscriben al tópico generado por el nodo que descomprime la imagen (\textit{image\_transport} \textit{decompress} en el \textit{host side}).

En el caso de la imagen de distancias, en sí no es un objeto pesado, por lo que no necesita compresión. Sin embargo, la frecuencia elevada de transmisión (30 Hz), hace que se requiera de un mayor ancho de banda. Como el resto de los sensores funcionan a 10 Hz, la tasa de la imagen de distancias puede reducirse a dicha frecuencia, de forma que el sistema no percibe el cambio y se logra reducir el ancho de banda. Con reducir la tasa de envío del nodo de \acrshort{ros} encargado de publicar la imagen sería suficiente, pero debido a que en el \gls{rosbag} dicho nodo se grabó a 30 Hz, se ha optado por ejecutar el paquete \textit{topic\_tools} de \acrshort{ros}, que permite publicar una réplica de un tópico a una menor frecuencia.

Debido a que el \gls{rosbag} solo contiene los datos de 2 cámaras, para realizar la prueba de escalabilidad con un mayor número de cámaras, ha sido necesario \textbf{replicar} los tópicos de las imágenes mediante el paquete de \acrshort{ros} \textit{topic\_tools} (figura \ref{fig:systesting}), de forma que los nuevos nodos se pueden suscribir a dichos tópicos.

\section{Resultados}
\label{sec:scaleresults}

A continuación se exponen los resultados de las pruebas de escalabilidad ejecutadas en la familia Intel (equipos de sobremesa) y en 2 dispositivos de la familia Jetson (Jetson Orin Nano y Jetson AGX Thor). Los resultados marcados con guion indican ausencia del dato por imposibilidad de realizar la prueba.

\subsection{Familia Intel}

\input{contenido/tables/tests/scaleperf.tex}

La tabla \ref{tab:scaleperf} muestra los resultados de la familia Intel en función del número de cámaras del sistema en \textbf{\acrshort{ros} 1}. La columna \textit{Reference} muestra los resultados obtenidos en el dispositivo de pruebas utilizado en \cite{andrew}, en el que solo se registraron datos del sistema funcionando con un máximo de 2 cámaras.

La principal mejora respecto al equipo de referencia se ve en el \textit{det\_r}, que demuestra que el sistema tiene una mayor capacidad de procesamiento, en cierta medida influida por la potencia de los procesadores Intel Core i7 respecto a Core i5 (este último viniendo del equipo de referencia).

Por otro lado, se aprecia una bajada en el \textit{det\_p} de los 2 dispositivos de sobremesa respecto al de referencia,

% ESTO NO ES CIERTO, al reducir el intervalo a 200 ms baja el recall (a 47, que es MENOS que la referencia) pero no sube la precisión, esto puede deberse a que se acepta la llegada de los mensajes de las cámaras con un máximo de \textbf{500 milisegundos} de retardo respecto a los \textbf{200 milisegundos} configurados en la prueba de referencia, lo que hace que se devuelvan predicciones con posiciones más atrasadas y, por lo tanto, que superen la holgura de 40 centímetros para asumirlas correctas. En cuanto a la métrica \textit{idp} todos los sistemas se encuentran relativamente a la par.

%a que el nodo integrador debe de fusionar los datos procedentes de todos los sensores, al aumentar su número también se aumenta la cantidad de procesamiento. Por lo tanto, más tiempo se demorará en devolver una predicción, que se emparejará con el frame del \gls{dataset} con el mismo \gls{timestamp}, que corresponde a un instante real \textbf{anterior}.

En la métrica \textit{det\_r} se aprecia una bajada, no muy clara en el portátil, al aumentar la cantidad de cámaras. Dicha bajada implica que el sistema empieza a perder mensajes de los nodos, aunque \textbf{no es crítica} y permite atender a la mayoría de las peticiones.

%PRECISION DE FAMILIA INTEL: la caida en la precision no se debe al slope ni al tamaño de la cola. El problema debe de estar en el nodo LiDAR.

%PRECISIÓN AL AUMENTAR EL Nº DE CÁMARAS: creo q el nodo integrador incluye detecciones repetidas (con las mismas posiciones exactas) cuando no se conoce la identidad (la etiqueta como unk), ya que con entidades desconocidas no se guardan duplicados. Esto produce una proliferación de det_fps, ya que al haber puntos repetidos, hay más detecciones pero menos matches, por lo tanto aumentan los unmatches y así los det_fps.

La precisión en los reconocimientos (métrica \textit{idp}) no experimenta caídas notorias (excepto por la situación de las 5 cámaras en el portátil, que sorprendente se recupera al subir a las 10 cámaras) al aumentar la cantidad de cámaras, lo que demuestra que los modelos de reconocimiento siguen funcionando correctamente ante un enorme estrés del sistema. El \textit{idf1} depende en cierta medida del \textit{det\_r}, por lo que es de esperar que dicho valor descienda junto al \textit{det\_r}, que en cierto modo es compensado por el \textit{idp}.

La métrica \textit{det\_p} sufre la mayor caída a medida que se escala en el número de cámaras... Por otra parte, los resultados del \textit{det\_p} se muestran similares entre el PC del laboratorio y el portátil, lo que demuestra la baja latencia de la red Ethernet utilizada para las pruebas del portátil.

\input{contenido/tables/tests/scaleresources.tex}

La tabla \ref{tab:scaleresources} muestra el uso de recursos durante la prueba para los equipos de sobremesa. Se puede apreciar que, hasta las 10 cámaras, el sistema se desempeña de forma fluida, con máximos de poco más de la mitad de recursos utilizados.

(TODO: El portátil ha registrado su mayor recall en 10 cámaras, entonces se puede decir que la GPU está al límite???) Los recursos de la \acrshort{gpu} se llevan al límite con 10 cámaras. La gráfica del portátil (Ampere) frente a la del PC del laboratorio (Turing) es capaz de gestionar mejor la memoria (debido a TODO: \dots). Por otro lado, un mayor número de \glspl{sm} en la \acrshort{gpu} Ampere (20, respecto a los 14 de la Turing) le permite lidiar mejor con la carga respecto a la \acrshort{gpu} del PC del laboratorio.

El uso elevado de recursos explica, junto a otros factores, la bajada en el \textit{det\_r} cuando se ejecutan 10 nodos cámara simultáneamente, más el nodo \acrshort{lidar} y el integrador.

En el caso del portátil, gracias a las herramientas de \acrshort{ros} y a la arquitectura de transmisión de los datos, se ha conseguido reducir significativamente el ancho de banda de transmisión de imágenes \acrshort{rgbd}, permitiendo el tráfico de estos datos en tiempo real.

\subsection{Familia Jetson}

\input{contenido/tables/tests/scaleros2.tex}

\input{contenido/tables/tests/scaleresourcesros2.tex}

En la tabla \ref{tab:scaleros2} se muestra el rendimiento del sistema en \textbf{\acrshort{ros} 2} para los equipos Jetson Orin Nano y Jetson AGX Thor. En estos dispositivos no es posible instalar \acrshort{ros} Noetic, al menos para poder contar con las últimas versiones de las librerías. Por los motivos comentados en la sección \ref{subsec:ROS2}, el sistema en \acrshort{ros} 2 no puede ejecutar el nodo \acrshort{lidar}, por lo que los resultados mostrados solo tienen en cuenta los nodos cámara junto al integrador.

El \textit{det\_r} se muestra claramente inferior respecto a los resultados de la familia Intel, ya que el \acrshort{lidar} otorgaba cobertura completa a la reducida visión de las cámaras. La Jetson AGX Thor logra superar el valor del equipo de referencia en esta métrica, mientras que la Jetson Orin Nano se queda a 3 puntos de superarlo. Los resultados de precisión (\textit{det\_p} e \textit{idp}) se mantienen entre todos los dispositivos. Estos datos demuestran el excelente rendimiento de las \acrshort{gpu}s de las Jetson, capaces de compensar las limitaciones de una \acrshort{cpu} de \acrshort{arm} respecto a un Intel Core i5 (procesador del equipo de referencia). También es importante recordar que el cálculo del \textit{det\_r} se ha modificado respecto a \cite{andrew}, por lo que se muestra un \textit{recall} ligeramente inflado en la referencia.

Se experimenta una ligera caída en el \textit{det\_p} al aumentar a 5 cámaras en la Jetson AGX Thor, ya que se generan más resultados, por lo que aumenta la probabilidad de fusionar información de distintos instantes temporales en el nodo integrador. El \textit{det\_r} se mantiene constante, lo que significa que el dispositivo tolera sin problema la carga introducida (el bajo uso de recursos en la tabla \ref{tab:scaleresourcesros2} lo abala). Sin embargo, en la Jetson Orin Nano el \textit{det\_r} cae drásticamente debido a la saturación de los recursos (acorde a la tabla \ref{tab:scaleresourcesros2}), tanto de memoria, lo que impide la realización de las inferencias, como de procesamiento, lo que implica en un retardo de las respuestas y, por consiguiente, a que se consideren resultados desactualizados que conducen a una pérdida en la precisión.

% RECALL: En la Thor con 2 y 5 cámaras el n_gt se mantiene encima de los 6000 mientras q con 10 cams baja a 4300. Creo q el recall debe ser: det_fp/6259 y 6259 es el número de detecciones totales del ground truth, sin recortar nada.

%Decir que las pruebas del PC lab:
%  - Utilizan un slope de 0.5
%  - El nodo integrador no detecta duplicados a partir de la misma posición
%  - El tamaño de cola es de 100 (como todas las pruebas excepto las de la Orin Nano), por lo que no tiene problema de pérdida de mensajes

La Jetson AGX Thor sufre una caída en el \textit{det\_p}, pero sobretodo en el \textit{det\_r} al procesar 10 cámaras. Esto se debe a la elevada utilización de la \acrshort{gpu} (como se muestra en la tabla \ref{tab:scaleresourcesros2}), que provoca una reducción en el número de detecciones totales, además de su precisión. Este hecho lo demuestra la ejecución del modelo YuNet en la \acrshort{cpu}, que ha logrado aumentar el \textit{det\_p} en 4 puntos respecto a ejecutarlo en \acrshort{gpu}. Se ha escogido YuNet, debido a que la reducción en la latencia mediante CUDA no es tan efectiva como en TensorRT y a que la gestión de la memoria realizada por OpenCV es mucho menos eficiente (en la tabla \ref{tab:scaleresourcesros2} se puede ver como el uso de memoria con 10 cámaras y YuNet en \acrshort{cpu} es \textbf{menor} que con 5 cámaras y YuNet en \acrshort{gpu}).

\section{Discusión}

En varios equipos, se ha logrado escalar el sistema hasta un número de cámaras más que suficiente para el caso de uso de este proyecto (10 cámaras sobran para cubrir un espacio de 360º), al menos para ser procesado por un solo dispositivo. La \textbf{Jetson Orin Nano} ha superado los resultados de \textbf{\textit{det\_r}} y el \textbf{\textit{idp}} para 2 cámaras respecto al equipo de referencia y ha conseguido mantener resultados aceptables hasta las 5 cámaras. Esto es especialmente interesante, debido a que este equipo es de muy bajo consumo y peso, lo que permite su fácil integración en un robot móvil.

El uso de la \acrshort{gpu} ha sido un factor clave en los resultados obtenidos, ya que, al ejecutar todo el procesamiento en la \acrshort{cpu}, no solo se saturan sus propios recursos, sino que la latencia de las inferencias aumenta y, por tanto, se devuelven predicciones en instantes de tiempo posteriores, cuya diferencia se va acumulando.

Es importante destacar que las pruebas se realizaron con \textbf{6 personas registradas en la base de datos}. Aumentar este número tendría consecuencias en los modelos de reconocimiento, ya que iteran toda la base de datos para calcular las distancias del vector con cada individuo, para devolver la mejor coincidencia. Según el dispositivo, esta operación tarda menos o alrededor de 1 milisegundo, lo que podría aumentar en varios milisegundos si se añaden por ejemplo 100 personas.

Los 8 \acrshort{gb}s de memoria de la Jetson Orin Nano se vuelven insuficientes, debido a todos los recursos necesarios a reservar, que pesan en torno a cientos de \acrshort{mb}s, que se multiplican por 4 modelos y a su vez por 5 cámaras. Para reducir el impacto de este problema, se han aplicado ciertas optimizaciones de los códigos de Python, que han permitido ahorrar hasta \textbf{400 \acrshort{mb}s} en la inicialización del sistema, y que se citan en el apéndice \ref{chap:optimus}. De todos modos, es necesario recortar también el elevado coste de procesamiento que impide al \textit{det\_r} despegar.

TODO: Acorde al uso de recursos, no da la impresión de que ninguno de los dispositivos pueda ejecutar más de 10 cámaras sin una caída en el rendimiento.

Aunque la ejecución de YuNet en la \acrshort{gpu} sea beneficioso, en una situación de estrés en la \acrshort{gpu} impide ...

%el uso ineficiente de la memoria de OpenCV con CUDA respecto a TensorRT impide 