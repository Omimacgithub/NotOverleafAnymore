\chapter{Arquitectura del sistema propuesto}
\label{chap:sysarch}
\lettrine{E}{n} este capítulo se expone una idea general de la arquitectura planteada y se comentan sus componentes en detalle.

\section{Arquitectura general}

En esta sección se explica el sistema de partida y todas las mejoras que componen el nuevo sistema extendido.

\subsection{Arquitectura del sistema base}
\label{sec:basearch}

Se parte de un sistema que detecta y reconoce personas a través de 2 cámaras \acrshort{rgbd} combinado con un sensor \acrshort{lidar}, que permite rastrear las detecciones fuera del ángulo de visión de las cámaras (cada una con un rango de visión horizontal de 57º), de forma que se mantienen detecciones robustas y persistentes en el tiempo \cite{andrew}.

\begin{figure}[hp!]
    \centering
    \includegraphics[width=0.6\linewidth]{imagenes/SYSARCH.png}
    \caption{Arquitectura del sistema de partida. Figura extraída de \cite{andrew}}
    \label{fig:sysarch}
\end{figure}

En la figura \ref{fig:sysarch} se muestra la arquitectura planteada en \cite{andrew}. Se ejecutan 1 o varios nodos que procesan las imágenes de las cámaras (nodo cámara), cada nodo cámara recibe los datos \textbf{de una sola cámara}, que devuelve un mensaje con la detección y el reconocimiento del individuo, junto con su posición \acrshort{3d} a partir de la imagen de distancias de la cámara. La posición \acrshort{3d} se contrasta con las detecciones realizadas por un modelo que procesa una \gls{pcl} otorgada por un sensor \acrshort{lidar} (nodo \acrshort{lidar}). Finalmente, las salidas de todos los nodos se fusionan para reforzar las predicciones (nodo integración de sensores).

\begin{figure}[hp!]
    \centering
    \includegraphics[width=0.8\linewidth]{imagenes/CAMNOD.jpg}
    \caption{Nodo cámara. Figura extraída de \cite{andrew}}
    \label{fig:camnod}
\end{figure}

En la figura \ref{fig:camnod} se muestra el flujo del nodo cámara. Dicho nodo procesa la información de las cámaras frame a frame, los modelos de detección (expuestos en la sección \ref{sec:models}) devuelven \glspl{bbox} de los rostros y cuerpos detectados, que se comparan para asegurar que cada recorte facial se encuentra contenido en cada recorte corporal. Posteriormente, se procede al reconocimiento facial y corporal (expuestos en la sección \ref{sec:models}) para devolver la etiqueta del individuo dentro de los registrados inicialmente en el sistema, ya que el diseño inicial no cuenta con la capacidad de reconocer desconocidos (\textit{Closed-Set}). Tras obtener el \gls{embedding} generado por el modelo para cada usuario, se calcula la \textbf{distancia} de dicho vector con todos los vectores (sujetos) guardados en la base de datos, este cálculo se realiza mediante el algoritmo de \textbf{distancia de cosenos}, que otorga el grado de similitud entre dos vectores \cite{andrew}. Como resultado, se obtiene una lista ordenada de los sujetos según el grado de similitud. La predicción final puede tomarse como la primera entrada de dicha lista, o pueden aplicarse métodos como la distancia relativa y/o la identidad probable (definidos en \cite{andrew}) sobre el conjunto de usuarios, con el fin de devolver predicciones más precisas (dichos métodos se ejecutan en el nodo integración de sensores). Estos dos posibles comportamientos pueden escogerse con un valor del parámetro \textit{top\_k} de 1 o mayor que 1 respectivamente.

\subsection{Arquitectura extendida}
\label{sec:finalsys}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FINALSYS.jpg}
    \caption{Arquitectura general del sistema, los módulos en negrita se corresponden con los nuevos componentes desarrollados.}
    \label{fig:finalsys}
\end{figure}

En la figura \ref{fig:finalsys} se muestra la arquitectura extendida, los nuevos componentes desarrollados se encuentran marcados en negrita, mientras que el resto de la arquitectura sigue la estructura ya comentada.

El nodo cámara pasa de operar frame a frame a procesar una \textbf{secuencia de frames}, con el fin de explotar la coherencia espacio-temporal. Se agrupan los recortes (o \glspl{bbox}) según el sujeto aplicando un método de seguimiento (\textit{tracking}) y se almacenan en la \textbf{lista de entidades} para un intervalo de la secuencia, junto con los vectores de características (o \glspl{embedding}) generados a partir de las \glspl{bbox} por los respectivos modelos de reconocimiento. Dichos \glspl{embedding} se sirven como entrada para el módulo de \textbf{reconocimiento adaptativo}, que toma la decisión de reconocimiento y actualiza las \textbf{personas registradas}, que es una base de datos compuesta por todos los nodos cámara, cada uno con una copia actualizada con los últimos cambios.

El módulo de reconocimiento adaptativo es el encargado de otorgar el reconocimiento \textbf{\textit{Open-Set} y/o \textit{Open-World}}. Dicho módulo evalúa si la persona detectada en la secuencia es un desconocido o pertenece a las personas registradas. En ambos casos, el sistema se actualiza con la nueva información en forma de un nuevo registro en el sistema si es un desconocido o modificando el registro existente ante los cambios de la entidad (lo que se conoce como \textit{\textbf{concept-drift}}).

Finalmente, las predicciones de cada nodo se contrastan dentro del nodo integración de sensores, que devuelve el reconocimiento final, coherente con la información otorgada por los nodos (ejemplo: dos cámaras que no están solapadas no pueden reconocer a una misma persona en el mismo instante temporal).

Toda la arquitectura vista se ejecuta en el \textit{framework} \acrshort{ros} \cite{ROS}. \acrshort{ros} se encarga de crear los procesos para cada nodo, comprobar su estado, regular la frecuencia a la que trabajan, crear la red en la que dichos procesos intercambian mensajes, entre otros muchos detalles que resultan transparentes para el programador.

\section{Procesamiento de secuencias de frames}
\label{sec:video}
El sistema de partida trabaja a nivel de frame \cite{andrew}, es decir, devuelve predicciones de los individuos presentes en una sola imagen. Esta aproximación permite trabajar a altas frecuencias (ejemplo: devolver un reconocimiento cada 100 ms), sin embargo, las predicciones dependen enteramente de la calidad del frame (ejemplo: nivel de borrosidad). En este proyecto se ha optado por trabajar con \textbf{secuencias (o intervalos) de frames}, de esta forma, se devuelve un reconocimiento más robusto basado en la coherencia espacio-temporal.

De cada frame de la secuencia, se extrae la información de los individuos presentes a partir de un modelo de detección de caras (YuNet) y/o de cuerpos (YOLO) y se agrupan por cada individuo a lo largo del intervalo aplicando el método de seguimiento y reidentificación a partir del frame actual y el anterior. El resultado final es una lista (lista de entidades en la figura \ref{fig:finalsys}) que contiene los \glspl{embedding} generados por los modelos de reconocimiento agrupados por el usuario en cada frame. El tamaño del intervalo en número de frames es ajustable según las necesidades del operador (ejemplo: intervalo de 10 frames, que equivale a 1 segundo si las cámaras funcionan a 10 Hz).

\subsection{Seguimiento de entidades}
\label{sec:tracker}

En casos como los del \textit{\gls{dataset}} FACE COX \cite{cox}, donde en los videos siempre aparece una sola persona, la agrupación de las entidades es trivial. Sin embargo, en un video donde aparecen múltiples individuos que se entrecruzan, es necesario adoptar un método para seguir el rastro de cada persona entre frames.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/Seq.jpg}
    \caption{Funcionamiento del método húngaro para el seguimiento de personas, como salida se obtiene una lista de recortes agrupados por entidad}
    \label{fig:seq}
\end{figure}

El \textbf{método húngaro} es un algoritmo que resuelve el problema de la asignación óptima. Dada una matriz de costes en el que cada fila establece una correlación con cada columna, dicho algoritmo buscará la \textbf{asignación óptima}, es decir, de menor coste entre elementos, en este caso, dos frames adyacentes \cite{Hungarian}.

La figura \ref{fig:seq} muestra un ejemplo de funcionamiento del método, que consiste en lo siguiente: se aplica el modelo de detección pertinente y se generan las \glspl{bbox} del \textbf{frame anterior y el actual}. Posteriormente, se genera la matriz de costes, donde las \glspl{bbox} del frame anterior se encuentran en las filas y las \glspl{bbox} del frame actual en las columnas. Para cada par de \glspl{bbox} de la matriz, se calcula el \textbf{\acrfull{iou}} \cite{iou}. Finalmente, el método húngaro devuelve los pares de menor coste, que en este caso representan las \glspl{bbox} con mayor solape y similitud (es necesario invertir el valor del \acrshort{iou} restándole 1). Tras repetir el método en todos los frames de la secuencia, se obtiene la información agrupada de cada persona según el rastro generado por el algoritmo.

La métrica \acrshort{iou} devuelve el porcentaje de solapamiento y similitud entre \glspl{bbox} (como se muestra en la figura \ref{fig:iou}), de forma que recortes de diferente tamaño (cuando más cerca esté el sujeto de la cámara, más grande será el recorte) den un valor bajo al solaparse (ejemplo: personas que coinciden en la imagen en diferentes distancias). Dadas dos \glspl{bbox} A y B, el \acrshort{iou} se calcula como sigue en la ecuación \ref{eq:iou}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/iou.png}
    \caption{Intersection over Union, imagen extraída de \cite{iou}}
    \label{fig:iou}
\end{figure}

\begin{equation}
    IoU = \frac{A \cap B}{A \cup B}\label{eq:iou}
\end{equation}

\subsection{Reidentificación de entidades}
\label{subsec:reiden}
Es posible que durante la detección, las \glspl{bbox} de una misma persona en frames consecutivos no se solapen debido a la velocidad de movimiento de la propia persona o a un movimiento de la cámara, lo que imposibilita la aplicación del método húngaro. Otro problema es el no seguimiento de la persona cuando esta se encuentra totalmente ocluida (ejemplo: se cruza un individuo justo delante) y reaparece o si simplemente la persona gira su cara fuera de la visión de la cámara y vuelve a detectarse después, en estos casos se crearía una nueva entidad para el mismo individuo, lo que no es un comportamiento deseable.

El \textbf{filtro de Kalman} predice la próxima posición del individuo a partir de la probabilidad Gausiana, de tal forma que puede mantenerse el rastro cuando la persona desaparece por unos frames. A pesar de ser una técnica efectiva, el filtro necesita de un mínimo de frames para converger cuando una nueva persona aparece \cite{MangoYOLO}, lo que no es beneficioso para intervalos de secuencia cortos. Finalmente se ha optado por un método más sencillo basado en la \textbf{distancia euclidiana}.

Dicho método consiste en los siguiente: en el caso de que haya un movimiento veloz del individuo o de la cámara, se calcula la distancia entre el \textbf{centro} de la \gls{bbox} actual con la \glspl{bbox} posterior que no tiene solape, si la distancia calculada es \textbf{inferior a un umbral}, \textbf{se valida la asociación}. En el caso de perder el rastro del individuo, se guarda la posición de la última aparición del mismo y se calcula la distancia con las \glspl{bbox} sin asociación en futuros frames, si la distancia no es inferior al umbral en un máximo de frames (prefijado por el operador), \textbf{se abandona el rastreo}, en caso contrario se restablece. El valor del umbral se fija de antemano \textbf{y se ajusta automáticamente en función de la resolución} de la cámara utilizando un escalado a partir de la diagonal (se calcula la diagonal de la resolución prefijada y la nueva resolución y se divide la diagonal de la resolución nueva entre la prefijada, el resultado se multiplica por el valor de umbral).

\begin{equation}
    \Delta r_{euclid} = \sqrt{\Delta x^{2} + \Delta y^{2}} \label{eq:eucl}
\end{equation}

Siendo $\Delta x$ y $\Delta y$ la diferencia entre las coordenadas \acrshort{2d} de los centros de dos \glspl{bbox}, la distancia euclidiana se calcula como se muestra en la figura \ref{eq:eucl}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FOLREID.jpg}
    \caption{Diagrama de flujo del seguimiento y reidentificación}
    \label{fig:reident}
\end{figure}

La figura \ref{fig:reident} muestra el diagrama de flujo del módulo de seguimiento y reidentificación. El seguimiento de las entidades a lo largo de los frames se guarda en la \textbf{lista de entidades} vista en la figura \ref{fig:finalsys}, en cada iteración se revisan todas las entidades de la lista, TODO: seguir explicando

\begin{figure}[hp!]
    \centering
    \begin{subfigure}[c]{0.2\textwidth}
        \includegraphics[width=\textwidth]{imagenes/eucl0.png}
    \end{subfigure}
    \begin{subfigure}[c]{0.2\textwidth}
        \includegraphics[width=\textwidth]{imagenes/eucl1.png}
    \end{subfigure}
    \begin{subfigure}[c]{0.2\textwidth}
        \includegraphics[width=\textwidth]{imagenes/eucl2.png}
    \end{subfigure}
    \caption{Reidentificación mediante la distancia euclidiana}
    \label{fig:eucls}
\end{figure}

En la figura \ref{fig:eucls} se expone un ejemplo real, en el primer frame, se muestran dos entidades etiquetadas con un identificador (0 y 1) y como se aplica la distancia euclidiana para la entidad 0, cuyas \glspl{bbox} no se solapan, también se muestra como la entidad 1 está a punto de ser ocluida, al no haber \glspl{bbox} en frames posteriores asociables a la entidad 1, la posición del sujeto se guarda. En el segundo frame (figura \ref{fig:eucls}), la entidad 1 se encuentra totalmente ocluida por la entidad 0, como en el instante posterior a dicho frame existe una \gls{bbox} sin ninguna asociación, se calcula la distancia euclidiana entre dicha \gls{bbox} respecto a la última detectada de la entidad 1. En el último frame (figura \ref{fig:eucls}) se muestra la entidad 1 reasignada.

\section{Reconocimiento adaptativo}

\begin{figure}[tb]
    \centering
    \includegraphics[width=1\linewidth]{imagenes/ADAPTSYS.jpg}
    \caption{Diseño del módulo adaptativo}
    \label{fig:ADAPTSYS}
\end{figure}

Módulo encargado de devolver las predicciones y actualizar el conocimiento existente a partir de la lista de entidades generada en la anterior sección.

En la figura \ref{fig:ADAPTSYS} se muestra la arquitectura de este módulo, cuyos componentes se han diseñado partiendo de \cite{Erik, CESAR} como referencia. Tras agrupar las \glspl{bbox} por individuos y calcular sus vectores (\textit{\glspl{embedding}}), estos se comparan contra las personas registradas para averiguar si dichos sujetos pertenecen o no al sistema. La base de datos está compuesta por \textbf{comités (o colecciones) de \acrshort{svm} lineales} para cada individuo. Las \acrshort{svm} de los comités procesan los \textit{\glspl{embedding}}, devolviendo una serie de \textbf{puntuaciones}, que representan la distancia del punto respecto al plano lineal que distingue entre la clase del propio individuo y el resto del universo. Finalmente, se toma la decisión de reconocimiento a partir de dichas puntuaciones y se actualiza la base de datos con los nuevos \glspl{embedding}.

TODO: en trabajo relacionado? Se ha demostrado que múltiples \acrshort{svm} simples (ejemplo: lineales) como conjunto \textbf{generalizan mejor} que una única \acrshort{svm} compleja (ejemplo: sigmoide) \cite{malisiewicz2011ensemble}. Los comités de \acrshort{svm} también favorecen la adaptación a los cambios, ya que permiten agregar conocimiento acerca de una entidad entrenando una nueva \acrshort{svm} lineal o eliminar dicho conocimiento descartando la \acrshort{svm} correspondiente. De esta forma, se obtiene una representación de un individuo a partir de un conjunto de clasificadores ligeros, sin necesidad de reentrenar un clasificadores complejo desde cero \cite{malisiewicz2011ensemble}.

El módulo de reconocimiento adaptativo se compone de los siguientes componentes, presentes en la figura \ref{fig:ADAPTSYS}:
\begin{itemize}
    \item \textbf{Módulo de valoración}: cada comité asigna una puntuación al intervalo de \glspl{bbox} de un individuo.
    \item \textbf{Módulo de reconocimiento}: devuelve una decisión de reconocimiento basándose en las puntuaciones de cada comité.
    \item \textbf{Módulo de actualización}: se encarga de crear un nuevo comité si se detecta un usuario nuevo (\textit{unknown}) o de crear un nuevo clasificador para registrar los cambios del usuario existente (\textit{drift}).
    \item \textbf{Módulo de limitación}: reemplaza la \acrshort{svm} que menos aporta a un comité en el caso de que este exceda el límite establecido.
\end{itemize}

\subsection{Módulo de valoración}
\label{sec:val}

Es el módulo encargado de devolver una representación comparable de cada individuo que será aplicada en la decisión de reconocimiento.

Por cada secuencia de entrada, siendo esta una secuencia de \textit{\gls{embedding}} (figura \ref{fig:ADAPTSYS}), se calculan las \textbf{puntuaciones (scores) para cada comité}. La puntuación de un comité es a su vez un valor consensuado entre los resultados de las predicciones de las \acrshort{svm} que lo conforman, el criterio de consenso (o de fusión) se basa en un percentil (generalmente la media). Aplicar percentiles es igual a escoger un conjunto amplio o reducido de \acrshort{svm}, ya que pueden existir \acrshort{svm} dañinas para el comité (ejemplo: corresponden a otra persona), los percentiles ayudan a descartar los resultados de dichas \acrshort{svm}.

\begin{equation}
    s_{i} = \frac{x_{i}}{\left\| x_{i}\right\|_{2}} \label{eq:l2norm}
\end{equation}

Para cada comité, se ejecutan las siguientes funciones:
\begin{itemize}
    \item \textbf{FDF} (Frame Decision Function): se calculan los scores de cada \acrshort{svm} contra \textbf{un frame} de la secuencia y se fusionan las salidas (o puntuaciones) en una única puntuación, que representa la puntuación del comité para dicho frame. Antes de la fusión, se aplica la normalización Euclidiana a cada puntuación con el fin de hacerlas comparables. Siendo $x_{i}$ un \textit{\gls{embedding}} o la salida de una \acrshort{svm}, se obtiene el vector normalizado $s_{i}$ como sigue en la ecuación \ref{eq:l2norm}.
    \item \textbf{SDF} (Sequence Decision Function): se encarga de fusionar todas las puntuaciones de la anterior función para obtener un único resultado que representa a la \textbf{secuencia}.
\end{itemize}

\subsection{Módulo de reconocimiento}
\label{sec:reckon}

Este módulo determina si la entidad detectada se corresponde a un individuo previamente reclutado o a una entidad \textbf{desconocida}.

Para tomar la decisión de si un sujeto es o no un desconocido, se ha implementado un algoritmo basado en el teorema estadístico \acrfull{evt} o teorema de Fisher–Tippett–Gnedenko, que permite \textbf{detectar extremos} en distribuciones estadísticas. Dicho teorema dicta que la distribución de los valores máximos o mínimos sigue una de las siguientes 3 distribuciones: Gumbel, Frechet, Weibull \cite{rudd2017extreme, scorenorm, Erik}. Gumbel y Frechet son distribuciones \textbf{no acotadas}, mientras que Weibull es una distribución acotada. Para sistemas de reconocimiento que calculan las distancias o similitudes entre puntuaciones (ejemplo: valores devueltos por una \acrshort{svm} para una clase), la distribución de puntos para cada clase sigue una distribución de Weibull, ya que los valores se encuentran acotados \cite{scorenorm}.

Siendo \textit{f(x)} la distribución de puntuaciones de los comités \textbf{que no corresponden con el sujeto}, se analiza si la puntuación del comité que se corresponde supuestamente con el sujeto es un \textbf{extremo} de la distribución \textit{f(x)}, en dicho caso, la entidad se reconoce claramente diferenciada con el resto, en caso contrario, se denota como \textbf{desconocido}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FITS.jpg}
    \caption{Ejemplos de distribuciones de Weibull y como el umbral (Tw) distingue entre un desconocido (\textit{unknown} y una deriva (\textit{drift})).}
    \label{fig:FITS}
\end{figure}

Se calcula la probabilidad de pertenencia a la distribución de la puntuación en cuestión, es decir, la salida de la función \acrfull{pdf} de Weibull. Si la probabilidad se encuentra por debajo de un \textbf{umbral} (Tw en la figura \ref{fig:ADAPTSYS}), entonces se trata de un \textbf{extremo} \cite{Erik, scorenorm}. En la situación de la derecha de la figura \ref{fig:FITS} se muestra un caso en el que la puntuación ganadora es un extremo, al contrario de la gráfica de la izquierda.

Las puntuaciones de todos los comités se ordenan por su valor (función sort de la figura \ref{fig:ADAPTSYS}), siendo la mejor puntuación la primera de la lista, es decir, la más baja (en la sección \ref{sec:init} se explica el porqué) y el resto de puntuaciones las no coincidentes.

El algoritmo expuesto otorga un conocimiento robusto, ya que convierte puntuaciones (o scores) concretos de una \acrshort{svm} en probabilidades que siguen una teoría estadística. Esto permite la \textbf{fusión de datos de diferentes fuentes} como nuevas \acrshort{cnn} de reconocimiento o nuevas cámaras diferentes a las Kinect en el sistema \cite{scorenorm}.

\subsection{Módulo de actualización}
Es el módulo que implementa la actualización de los comités tras el reconocimiento realizado en la anterior función.

Según la entidad predicha, se toma una cierta decisión de actualización. Si el sujeto es \textbf{desconocido}, se crea un nuevo comité con una \acrshort{svm} que se añade al registro. La \acrshort{svm} se entrena con las muestras (\textit{\glspl{embedding}} de caras o cuerpos) obtenidas del propio sujeto como conjunto de positivos, mientras que el conjunto de negativos se compone de muestras aleatorias extraídas directamente de la base de datos. Si el sujeto es \textbf{conocido}, se agrega una nueva \acrshort{svm} al comité, entrenada con las muestras del propio individuo como positivos y como negativos un muestreo aleatorio de todas las entidades \textbf{excepto el propio sujeto}.

Una condición necesaria para que este módulo se ejecute es que la secuencia de entrada para el individuo \textbf{contenga un mínimo de \textit{\glspl{embedding}} para su inicialización}, dicho mínimo es fijado por el operador de antemano. Otra precondición, que aplica a las entidades conocidas, es comprobar si las muestras a añadir son lo suficientemente representativas. Las puntuaciones cerca del cero indican que las muestras se encuentran en el borde de lo que es nuevo y lo que la \acrshort{svm} ya conoce. Si la mediana de las puntuaciones de los \glspl{embedding} para un comité se encuentra por debajo de un umbral (\textit{update\_th}), se procede a seleccionar las muestras más cercanas al 0 (función sample selection en la figura \ref{fig:ADAPTSYS}), que compondrán el conjunto de positivos del clasificador.

\textbf{El tamaño del conjunto de positivos y de negativos es prefijado por el operador}, en la sección \ref{seq:paramtunning} se evalúa su impacto en el rendimiento.

\subsection{Módulo de limitación}
\label{seq:limmod}

Dicho módulo se encuentra inherente al de actualización. Si un comité excede un número prefijado de \acrshort{svm} almacenadas, se toma una decisión para eliminar una de las \acrshort{svm} según los siguientes criterios.

\subsubsection{Diversidad}

\begin{align}
    D(h_{i}^{k})= \sum_{j=0;j\neq i}^{N-1} d(h_{i}^{k}, h_{j}^{k}) \label{eq:diversity} \\
    d(h_{i}^{k}, h_{j}^{k}) = -\frac{1}{Q}\sum_{q=0}^{Q-1} sgn(h_{i}^{k}(x_{q})) \cdot sgn(h_{j}^{k}(x_{q}))
\end{align}

Este criterio devuelve un valor que representa el grado de diferenciación de un clasificador respecto a su comité. Se escoge un conjunto aleatorio de \textit{\glspl{embedding}} de entre todos los comités y se calcula el score de cada clasificador del comité. Posteriormente, se acumula el producto de los signos entre scores y se multiplica por -1, de esta forma, el clasificador más discordante (es decir, el único que devuelve un resultado contrario respecto a una amplia mayoría) obtendrá un mayor valor de este criterio y viceversa. El valor de diversidad de cada clasificador se calcula como en \cite{Erik}. Dado un conjunto de \glspl{embedding} \{$x_{0}$, $x_{1}$, ..., $x_{Q-1}$\} y un comité $e^{k}$ con N clasificadores \{$h^{k}_{0}$, $h^{k}_{1}$, ..., $h^{k}_{N-1}$\}, $D(h^{k}_{i})$ se calcula como sigue en la figura \ref{eq:diversity}, donde \textit{sgn} es la función \textit{sign}, que devuelve 1 o -1 dependiendo del signo del número real.

\subsubsection{Coherencia}

\begin{align}
    C_{k,i} = 1[sgn(e^{k}) == sgn(\bar{y})] - 1 [sgn(e^{k}) \neq sgn(\bar{y})] \label{eq:coherence} \\
    \bar{y} = \frac{1}{Q} \sum_{q=1}^{Q-1} h_{n}^{k} (x_{q})
\end{align}

Este criterio viene a determinar la precisión de una \acrshort{svm} en el reconocimiento respecto a las salidas de su comité. El valor de coherencia determina cuantas veces una \acrshort{svm} devuelve el mismo signo que el resultado consensuado del comité para un conjunto de \textit{\glspl{embedding}}. Si los signos coinciden, se suma 1 al valor de coherencia, en caso contrario, se resta 1 a dicho valor, de forma que un valor alto se corresponde con una buena precisión. En el momento de creación de una \acrshort{svm}, este valor se inicializa a 0. Dado un comité ganador $e^{k}$ de N clasificadores \{$h^{k}_{0}$, $h^{k}_{1}$, ..., $h^{k}_{N-1}$\} y un conjunto de \textit{\glspl{embedding}} \{$x_{0}$, $x_{1}$, ..., $x_{Q-1}$\}, $C_{k,i}$ se calcula como sigue en \cite{CESAR} (figura \ref{eq:coherence}), donde $1[\cdot]$ representa a un condicional que devuelve 1 si la condición se cumple o 0 en caso contrario.

\subsubsection{Favorabilidad}

\begin{equation}
    F(h_{i}^{k}) = \alpha C_{k,i} + \gamma D(h_{i}^{k}) \label{eq:fav}
\end{equation}


Finalmente, los dos criterios anteriores se fusionan en un valor llamado \textbf{índice de favorabilidad}, la \acrshort{svm} con el menor valor de dicho índice \textbf{se elimina del comité}. La fórmula para calcular dicho índice es la misma que en \cite{CESAR}. Dado el valor de coherencia $C_{k,i}$ del clasificador $h^{i}$ del comité ganador $e^{k}$ y el valor de diversidad $D(h^{m})$, la favorabilidad se calcula como sigue en la figura \ref{eq:fav}, donde son $\alpha$ y $\gamma$ constantes que ajustan el peso de la coherencia y la diversidad respectivamente.

\section{Personas registradas}
\label{sec:initarch}

La fase de inicialización es fundamental, debido a que la \acrshort{svm} inicial es la que define la identidad del comité. Si dicha \acrshort{svm} está compuesta por muestras de baja calidad (ejemplo: caras borrosas o parcialmente ocluidas), entonces el comité \textbf{no se identificará correctamente consigo mismo} y, por lo tanto, generará \textbf{mayor confusión} a la hora de aplicar Weibull, es decir, \textbf{se generarán más desconocidos}.

En esta primera fase del sistema se crean los registros que representarán a los individuos iniciales. En este proyecto se han probado 2 aproximaciones, una \textbf{supervisada}, es decir, con intervención del operador, y la otra \textbf{no supervisada}, en la que el sistema se inicializa de manera completamente autónoma.
\subsection{Supervisado}
El operador realiza una selección de los frames más representativos para cada individuo. El sistema crea la base de datos de personas registradas a partir de las características extraídas de dichos frames.

\subsection{No supervisado}
El sistema se encarga de recoger los frames en el instante en el que aparezcan un mínimo de entidades simultáneas en escena. A partir de los frames de las cámaras, que estarán sincronizadas, se obtienen las \glspl{bbox} y se agrupan por individuo mediante el método de tracking. En este modo \textbf{no se requiere de ninguna intervención del operador}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/Init.jpg}
    \caption{Inicialización no supervisada del sistema}
    \label{fig:init}
\end{figure}

El funcionamiento se muestra en la figura \ref{fig:init}. Dado un número de cámaras \textbf{sincronizadas}, se busca un instante (o frame) en el que mínimo se detecten \textbf{5 personas} (equivalente al mínimo de puntos necesario para formar una distribución de Weibull consistente \cite{Erik}) de forma simultánea entre todas las cámaras. En caso de no encontrar suficientes \glspl{bbox} para definir al individuo (ejemplo: desaparece de la visión de la cámara demasiado rápido), el sistema \textbf{no se puede inicializar satisfactoriamente}. En caso contrario, se obtienen las características (o \textit{\glspl{embedding}/features}) y se almacenan para emplearse en el entrenamiento de las \acrshort{svm}. Finalmente, se crean los comités que conforman las \textbf{personas registradas}.

Las \glspl{bbox} se someten a un método de filtrado, que puede descartarlas si no cumplen con las siguientes condiciones:

\begin{itemize}
    \item La cara se encuentra enteramente dentro del plano
    \item La \gls{bbox} es más alta que ancha.
\end{itemize}

\subsection{Composición}

Para satisfacer los requerimientos del diseño expuesto, cada entrada en el registro de usuarios se compone de los siguientes objetos:

\begin{itemize}
    \item \textbf{person\_id:} etiqueta asignada al usuario (ejemplo: andres).
    \item \textbf{ensemble:} lista con las \acrshort{svm} del usuario, inicialmente 1.
    \item \textbf{descriptors:} lista de los vectores de características (\glspl{embedding}) del usuario de cada \acrshort{svm}. Dichos vectores se aplican como conjunto de positivos para el propio usuario y como parte del conjunto de negativos para el resto de usuarios.
    \item \textbf{coherence:} lista de valores de coherencia obtenidos de cada clasificador, inicializado a 0.
\end{itemize}

\subsection{Propagación de los cambios}

Como ya se ha comentado anteriormente, este registro es compartido por una o más cámaras que conforman el sistema. Debido a que el sistema es distribuido (computación en nodos de cálculo distintos) y los nodos están implementados en Python, es necesario explorar otras vías diferentes a la memoria compartida entre procesos. Para este proyecto, se han propuesto 2 alternativas:

\begin{itemize}
    \item \textbf{Base de datos centralizada:} todos los nodos acceden a una base de datos de baja latencia (ejemplo: base de datos puramente en memoria RAM), de la que reciben el registro de personas actualizado. Dicha base de datos se encontraría junto al nodo integración de sensores, que realizaría las peticiones de escritura. Finalmente, la base de datos propaga las modificaciones a todos los nodos conectados.
    \item \textbf{Difusión de los cambios:} aprovechando la red creada por \acrshort{ros}, el nodo integración de sensores recibe los mensajes acerca de las entidades reconocidas por los nodos cámara. El nodo integrador difunde un mensaje con los cambios a un tópico en el que todos los nodos estarán suscritos, de forma que mantienen su propia copia actualizada.
\end{itemize}