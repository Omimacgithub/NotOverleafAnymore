\chapter{Arquitectura del sistema propuesto}
\label{chap:sysarch}
\lettrine{E}{n} este capítulo se comenta brevemente la arquitectura de partida y se expone el diseño de los nuevos componentes.

\section{Arquitectura general}
\label{sec:partarch}

Se parte de un sistema compuesto por 2 cámaras \acrshort{rgbd} y un sensor \acrshort{lidar}, que detecta y reconoce personas a partir de nodos que aplican los respectivos modelos de redes neuronales (o \acrshort{cnn}). El sistema posee la capacidad de fusionar la información de todos los nodos, de forma que se obtiene un único reconocimiento robusto para cada individuo, junto a su posición concreta en el espacio \acrshort{3d}.

Toda la arquitectura se ejecuta en el \textit{framework} \acrshort{ros} \cite{ROS} (sección \ref{sec:ros}). \acrshort{ros} se encarga de crear los procesos para cada nodo, comprobar su estado, regular la frecuencia a la que trabajan, crear la red en la que dichos procesos intercambian mensajes, entre otros muchos detalles que resultan transparentes para el programador.

\begin{figure}[hp!]
    \centering
    \includegraphics[width=0.6\linewidth]{imagenes/SYSARCH.png}
    \caption{Arquitectura del sistema de partida. Figura extraída de \cite{andrew}}
    \label{fig:sysarch}
\end{figure}

En la figura \ref{fig:sysarch} se muestra la arquitectura planteada en \cite{andrew}, compuesta por un nodo que procesa los datos del \acrshort{lidar}, 1 o varios nodos que procesan los datos de las cámaras (2 en el caso del robot) y un nodo que devuelve una lista final de todos los individuos reconocidos y su posición a partir de la información de todos los nodos anteriores en un frame.

Cada cámara otorga una imagen \acrshort{rgb}, que es procesada por los modelos de detección y reconocimiento, y otra de distancias, que permite realizar una conversión a coordenadas \acrshort{3d}. Cada nodo cámara recibe los datos \textbf{de una sola cámara}.

El sensor \acrshort{lidar} otorga una \gls{pcl} del entorno, que sirve como entrada del nodo \acrshort{lidar}, que ejecuta un modelo de detección de objetos en \gls{pcl} y etiqueta los puntos devueltos.

Finalmente, mediante los datos de todos los nodos, el uso de la coherencia espacio-temporal y la aplicación de métodos como la distancia relativa y/o la identidad probable (definidos en \cite{andrew}), se obtiene la lista final de identidades. La posición \acrshort{3d} de cada individuo se obtiene mediante el contraste de las posiciones devueltas del nodo cámara y el \acrshort{lidar} para dicho individuo.

TODO: trabajo relacionado? La integración de sensores propuesta en \cite{andrew} ha demostrado mejorar los resultados, debido a su capacidad de rastrear individuos por medio del \acrshort{lidar} fuera del ángulo de visión de las cámaras (cada una con un rango de visión horizontal de 57º), lo que otorga detecciones robustas y persistentes en el tiempo \cite{andrew}.

\subsection{Nodo cámara}
\label{sec:basearch}


\begin{figure}[hp!]
    \centering
    \includegraphics[width=0.8\linewidth]{imagenes/CAMNOD.jpg}
    \caption{Nodo cámara. Figura extraída de \cite{andrew}}
    \label{fig:camnod}
\end{figure}

En la figura \ref{fig:camnod} se muestra el flujo del nodo cámara.

El nodo cámara recibe la información de un frame \acrshort{rgb} de una de las cámaras, que es procesado por 2 modelos de detección, uno destinado a rostros (YuNet en la figura \ref{fig:camnod}) y el otro a cuerpos (YOLO en la figura \ref{fig:camnod}). Se obtienen las \glspl{bbox} de los rostros y cuerpos detectados, que se comparan para asegurar que cada recorte facial se encuentra contenido en cada recorte corporal.

Tras comprobar que cada cara detectada se corresponde con un cuerpo, se procede al reconocimiento facial (ArcFace en la figura \ref{fig:camnod}) y corporal (OSNet en la figura \ref{fig:camnod}), que devuelven un vector con las características representativas para un individuo (o \gls{embedding}).

Una vez obtenidos los \glspl{embedding} de cada usuario, se calcula la \textbf{distancia} de dicho vector con todos los vectores (sujetos) guardados en la base de datos, este cálculo se realiza mediante el algoritmo de \textbf{distancia de cosenos}, que otorga el grado de similitud entre dos vectores \cite{andrew}. Como resultado, se obtiene una lista ordenada de los sujetos según el grado de similitud.

La identidad del individuo puede tomarse como la primera entrada de la lista de sujetos (es decir, la identidad más parecida), o puede procesarse la lista por medio de los métodos de distancia relativa y/o identidad probable en el nodo integración de sensores. Estos dos posibles comportamientos pueden escogerse con un valor del parámetro \textit{top\_k} de 1 o mayor que 1 respectivamente.

\section{Arquitectura extendida}
\label{sec:finalsys}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FINALSYS.jpg}
    \caption{Arquitectura del sistema extendido, los módulos en negrita se corresponden con los nuevos componentes desarrollados.}
    \label{fig:finalsys}
\end{figure}

En la figura \ref{fig:finalsys} se muestra la arquitectura extendida, los nuevos componentes desarrollados se encuentran marcados en negrita, mientras que el resto de la arquitectura sigue la estructura ya comentada.

En concreto, se han propuesto los siguientes componentes:

\begin{itemize}
    \item \textbf{Procesamiento de video:} implementa toda la lógica necesaria para agrupar las \glspl{bbox} por individuos en más de un frame (video o secuencia). Todas las \glspl{bbox} se transforman en \glspl{embedding}, que se guardan en una lista para ser procesados por el módulo de \textbf{reconocimiento adaptativo}.
    \item \textbf{Reconocimiento adaptativo:} implementa la capacidad de detección e inclusión de desconocidos en el sistema (modo \textbf{\textit{Open-Set} y \textit{Open-World}}). Evalúa, mediante el uso de la teoría estadística, si una \textbf{puntuación} particular para un individuo no comparte similitudes con el resto de individuos registrados. En caso afirmativo, se trata de un conocido, en caso contrario, de un desconocido. En ambos casos, el sistema actualiza su conocimiento acerca del individuo por medio de la base de datos de \textbf{personas registradas}. Dichas puntuaciones son los resultados de los \textbf{comités de \acrshort{svm}}, que clasifican las secuencias de \glspl{embedding}.
    \item \textbf{Personas registradas:} representa al conocimiento existente acerca de los individuos, que es compartido por \textbf{todo el sistema}, es decir, por todos los nodos cámara. Este módulo también abarca la inicialización de dicho registro al arrancar el sistema, los distintos métodos para su compartición entre nodos, así como su composición.
\end{itemize}

El nodo \acrshort{lidar} no se incluye en el sistema extendido, debido a que TODO.

El nodo cámara pasa de operar frame a frame a procesar una \textbf{secuencia de frames}, con el fin de explotar la coherencia espacio-temporal (módulo de procesamiento de secuencias de frames). Se obtiene la \textbf{lista de entidades} con la lista de \glspl{embedding} para cada individuo y se ejecuta el módulo de reconocimiento adaptativo.

El módulo de reconocimiento adaptativo devuelve la decisión de reconocimiento y actualiza las \textbf{personas registradas}. Los nuevos cambios de los individuos son actualizados y compartidos entre todos los nodos. El método de clasificación pasa de utilizar la \textbf{distancia coseno} a emplear los \textbf{comités de \acrshort{svm}}, que devuelven una serie de \textbf{puntuaciones} que se estudian bajo el teorema estadístico \textbf{\acrfull{evt}}, útil para detectar casos extremos en la distribución de dichas puntuaciones. Este último método permite implementar el reconocimiento \textbf{\textit{Open-Set} y/o \textit{Open-World}}.

Finalmente, las predicciones de cada nodo cámara se contrastan dentro del nodo integración de sensores, que devuelve la lista de identidades final junto a la posición \acrshort{3d}.

%coherente con la información otorgada por los nodos (ejemplo: dos cámaras que no están solapadas no pueden reconocer a una misma persona en el mismo instante temporal).

A continuación, se exponen en detalle los componentes recién comentados.

\section{Procesamiento de video}
\label{sec:video}
El sistema de partida trabaja a nivel de frame \cite{andrew}, es decir, devuelve predicciones de los individuos presentes en una sola imagen. Esta aproximación permite trabajar a altas frecuencias (ejemplo: devolver un reconocimiento cada 100 ms), sin embargo, las predicciones dependen enteramente de la calidad del frame (ejemplo: nivel de borrosidad). En este proyecto se ha optado por trabajar con \textbf{secuencias de frames} (o videos), de esta forma, se devuelve un reconocimiento más robusto basado en múltiples muestras.

En cada frame, se extraen las \glspl{bbox} de los individuos presentes a partir de los modelos de detección de caras y cuerpos. Posteriormente, se relacionan dichos datos entre el \textbf{frame actual y el anterior}, hasta establecer la secuencia completa. El tamaño de la secuencia es ajustable según las necesidades del operador (ejemplo: secuencia de 10 frames, que equivale a 1 segundo si las cámaras funcionan a 10 Hz).

El resultado final es una lista (lista de entidades en la figura \ref{fig:finalsys}), que contiene a su vez una lista de \glspl{bbox} transformadas en \glspl{embedding} (aplicando los modelos de reconocimiento) para cada individuo.

\subsection{Seguimiento de entidades}
\label{sec:tracker}

En casos como los del \textit{\gls{dataset}} FACE COX \cite{cox}, donde en los videos siempre aparece una sola persona, la agrupación de las entidades es trivial. Sin embargo, en un video donde aparecen múltiples individuos que se entrecruzan, es necesario adoptar un método para \textbf{seguir} el rastro de cada persona entre frames.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/Seq.jpg}
    \caption{Funcionamiento del método húngaro para el seguimiento de personas, como salida se obtiene una lista de recortes agrupados por entidad}
    \label{fig:seq}
\end{figure}

El \textbf{método húngaro} es un algoritmo que resuelve el problema de la asignación óptima. Dada una matriz de costes en el que cada fila establece una correlación con cada columna, dicho algoritmo buscará la \textbf{asignación óptima}, es decir, de menor coste entre elementos, en este caso, dos frames adyacentes \cite{Hungarian}.

Se genera la matriz de costes, donde las \glspl{bbox} (o recortes) del frame anterior se encuentran en las filas y las \glspl{bbox} del frame actual en las columnas. Para cada par de \glspl{bbox} de la matriz, se calcula el \textbf{\acrfull{iou}} \cite{iou}. Finalmente, el método húngaro devuelve los pares de menor coste, es decir, de mayor valor de \acrshort{iou} (el resultado se invierte restándole un 1).

Tras repetir el proceso en toda la secuencia, se obtiene la lista de recortes de cada persona según el rastro generado por el algoritmo. La figura \ref{fig:seq} muestra el funcionamiento ya comentado.

La métrica \acrshort{iou} devuelve el porcentaje de solapamiento y similitud entre \glspl{bbox} (como se muestra en la figura \ref{fig:iou}), de forma que recortes de diferente tamaño (cuando más cerca esté el sujeto de la cámara, más grande será el recorte) den un valor bajo al solaparse (ejemplo: personas que coinciden en la imagen en diferentes distancias). Dadas dos \glspl{bbox} A y B, el \acrshort{iou} se calcula como sigue en la ecuación \ref{eq:iou}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/iou.png}
    \caption{Intersection over Union, imagen extraída de \cite{iou}}
    \label{fig:iou}
\end{figure}

\begin{equation}
    IoU = \frac{A \cap B}{A \cup B}\label{eq:iou}
\end{equation}

\subsection{Reidentificación de entidades}
\label{subsec:reiden}
Es posible que durante la detección, las \glspl{bbox} de una misma persona en frames consecutivos no se solapen debido a la velocidad de movimiento de la propia persona o a un movimiento de la cámara, lo que causa una incorrecta aplicación del método húngaro. En este caso, se asigna el mayor coste (valor de 1) a la relación (es decir, un valor de \acrshort{iou} de 0), lo que genera el riesgo de asociar 2 \glspl{bbox} de individuos diferentes.

%También existe la posibilidad de que el método húngaro realice una mala asignación cuando 2 \glspl{bbox} no coinciden, en este caso tendrían el coste máximo (valor de 1), pero igualmente se relacionarían al no existir otras relaciones de menor coste.

Otro problema es el no seguimiento de la persona cuando esta se encuentra totalmente ocluida (ejemplo: se cruza un individuo justo delante) y reaparece o si simplemente la persona gira su cabeza, dejando la cara fuera de la visión de la cámara, y la vuelve a girar. En estos casos, se crearía una nueva entidad para el mismo individuo, lo que no es un comportamiento deseable.

Debido a dichos problemas, es necesario aplicar un método que pueda \textbf{reidentificar} a los individuos cuyo rastro se ha perdido temporalmente.

El \textbf{filtro de Kalman} predice la próxima posición del individuo a partir de la probabilidad Gausiana, de tal forma que puede mantenerse el rastro cuando la persona desaparece por unos frames. A pesar de ser una técnica efectiva, el filtro necesita de un mínimo de frames para converger cuando una nueva persona aparece \cite{MangoYOLO}, lo que no es beneficioso para tamaños pequeños de secuencia. Finalmente, se ha optado por un método más sencillo basado en la \textbf{distancia euclidiana}.

En el caso de que haya un movimiento veloz del individuo o de la cámara o que se haya realizado una asignación con el mayor coste, se calcula la distancia entre el \textbf{centro} de la \gls{bbox} actual con la \gls{bbox} posterior que no tiene solape, si la distancia calculada es \textbf{inferior a un umbral}, \textbf{se valida la asociación}, en caso contrario, la \gls{bbox} del individuo se mantiene, por si se vuelve a localizar en futuros frames.

En el caso de perder la localización del individuo, se mantiene la \gls{bbox} de la última aparición del mismo y se calcula la distancia con las \glspl{bbox} sin asociación en futuros frames. Si la distancia es \textbf{superior} al umbral en un máximo de frames (prefijado por el operador), \textbf{se abandona el rastreo}, en caso contrario se restablece.

El valor del umbral se fija de antemano \textbf{y se ajusta automáticamente en función de la resolución} de la cámara utilizando un escalado a partir de la diagonal (se calcula la diagonal de la resolución prefijada y la nueva resolución y se divide la diagonal de la resolución nueva entre la prefijada, el resultado se multiplica por el valor de umbral).

Siendo $\Delta x$ y $\Delta y$ la diferencia entre las coordenadas \acrshort{2d} de los centros de dos \glspl{bbox}, la distancia euclidiana se calcula como se muestra en la ecuación \ref{eq:eucl}.

\begin{equation}
    \Delta r_{euclid} = \sqrt{\Delta x^{2} + \Delta y^{2}} \label{eq:eucl}
\end{equation}

\begin{figure}[hp!]
    \centering
    \begin{subfigure}[c]{0.2\textwidth}
        \includegraphics[width=\textwidth]{imagenes/eucl0.png}
    \end{subfigure}
    \begin{subfigure}[c]{0.2\textwidth}
        \includegraphics[width=\textwidth]{imagenes/eucl1.png}
    \end{subfigure}
    \begin{subfigure}[c]{0.2\textwidth}
        \includegraphics[width=\textwidth]{imagenes/eucl2.png}
    \end{subfigure}
    \caption{Reidentificación mediante la distancia euclidiana}
    \label{fig:eucls}
\end{figure}

En la figura \ref{fig:eucls} se expone un ejemplo real, en el primer frame, se muestran dos entidades etiquetadas con un identificador (0 y 1) y como se aplica la distancia euclidiana para la entidad 0, cuyas \glspl{bbox} no se solapan, también se muestra como la entidad 1 está a punto de ser ocluida, al no haber \glspl{bbox} en frames posteriores asociables a la entidad 1, la posición del sujeto se guarda. En el segundo frame (figura \ref{fig:eucls}), la entidad 1 se encuentra totalmente ocluida por la entidad 0, como en el instante posterior a dicho frame existe una \gls{bbox} sin ninguna asociación, se calcula la distancia euclidiana entre dicha \gls{bbox} respecto a la última detectada de la entidad 1. En el último frame (figura \ref{fig:eucls}) se muestra la entidad 1 reasignada.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FOLREID.jpg}
    \caption{Diagrama de flujo del procesamiento de video}
    \label{fig:reident}
\end{figure}

La figura \ref{fig:reident} muestra el diagrama de flujo que conforma todo el módulo de procesamiento de video.

Se aplica el método húngaro para asociar detecciones entre el frame anterior y el actual. Se itera la lista de entidades con los individuos detectados hasta el momento, si algún individuo posee la asignación de mayor coste o no se ha establecido, se aplica el método de reidentificación durante un máximo de frames, controlado por la variable intentos\_loc. Por cada intento fallido de localización, se decrementa dicha variable, así hasta llegar al 0, que es el punto en el que se descarta la localización. En el resto de casos, la asignación del frame anterior con el actual se realiza y se restablece de nuevo la variable de intentos (en el caso de reidentificación).

Al final de cada iteración del módulo, se añaden las nuevas detecciones a la lista de entidades. Los nuevos casos se corresponden con asignaciones de \gls{bbox} que no se corresponden con ninguna entidad antes registrada.

\section{Reconocimiento adaptativo}

\begin{figure}[tb]
    \centering
    \includegraphics[width=1\linewidth]{imagenes/ADAPTSYS.jpg}
    \caption{Diseño del módulo adaptativo}
    \label{fig:ADAPTSYS}
\end{figure}

El módulo de reconocimiento adaptativo se encarga de devolver las predicciones y actualizar el conocimiento existente a partir de la lista de entidades generada (ver sección \ref{sec:video}).

En la figura \ref{fig:ADAPTSYS} se muestra la arquitectura de este módulo, cuyos componentes se han diseñado partiendo de \cite{Erik, CESAR} como referencia.

El módulo de reconocimiento adaptativo se compone de los siguientes componentes:
\begin{itemize}
    \item \textbf{Módulo de valoración}: cada comité asigna una puntuación a la secuencia de \glspl{embedding} (o vectores) de un individuo.
    \item \textbf{Módulo de reconocimiento}: devuelve una decisión de reconocimiento basándose en las puntuaciones de cada comité.
    \item \textbf{Módulo de actualización}: se encarga de crear un nuevo comité si se detecta un usuario nuevo (\textit{unknown}) o de crear una nueva \acrshort{svm} para registrar los cambios del usuario existente (\textit{drift}).
    \item \textbf{Módulo de limitación}: reemplaza la \acrshort{svm} que menos aporta a un comité, en el caso de que este exceda el límite establecido.
\end{itemize}

TODO: debe de ir en otro lugar? La base de datos de personas registradas está compuesta por \textbf{comités (o colecciones) de \acrshort{svm} lineales} para cada individuo.

El módulo de reconocimiento adaptativo recibe la secuencia de vectores de un individuo, que son procesados por el \textbf{módulo de valoración}, que devuelve las puntuaciones de cada comité, dichas puntuaciones se ordenan de menor a mayor, de forma que la mejor puntuación se corresponde (supuestamente) con el comité del individuo. Las puntuaciones son recibidas por el \textbf{módulo de reconocimiento}, que determina, mediante el \acrfull{evt}, si el comité corresponde realmente al individuo (conocido) o no (desconocido). El \textbf{módulo de actualización} recibe la decisión y agrega una nueva \acrshort{svm}, entrenada con la secuencia de vectores como positivos y con muestras guardadas del resto de individuos como negativos, en caso de determinar que el individuo es conocido, en caso contrario, se crea el nuevo comité con una \acrshort{svm} entrenada del mismo modo. Finalmente, si el comité se excede en el límite fijado de \acrshort{svm}s, el \textbf{módulo de limitación} determina la \acrshort{svm} que menos aporta a dicho comité. En la figura \ref{fig:ADAPTSYS} se muestran el flujo comentado con todos los módulos.

\subsection{Módulo de valoración}
\label{sec:val}

Es el módulo encargado de devolver una puntuación comparable de cada individuo que será aplicada en la decisión de reconocimiento.

Por cada secuencia de entrada, siendo esta una secuencia de \textit{\gls{embedding}} (figura \ref{fig:ADAPTSYS}), se calculan las \textbf{puntuaciones (scores) para cada comité}. La puntuación de un comité es a su vez un valor consensuado entre los resultados de las predicciones de las \acrshort{svm} que lo conforman, el criterio de consenso (o de fusión) se basa en un percentil (generalmente la media). Aplicar percentiles es igual a escoger un conjunto amplio o reducido de \acrshort{svm}, ya que pueden existir \acrshort{svm} dañinas para el comité (ejemplo: corresponden a otra persona), los percentiles ayudan a descartar los resultados de dichas \acrshort{svm}.

Para cada comité, se ejecutan las siguientes funciones:
\begin{itemize}
    \item \textbf{FDF} (Frame Decision Function): se calculan los scores de cada \acrshort{svm} contra \textbf{un frame} de la secuencia y se fusionan las salidas (o puntuaciones) en una única puntuación, que representa la puntuación del comité para dicho frame. Antes de la fusión, se aplica la normalización Euclidiana a cada puntuación con el fin de hacerlas comparables. Siendo $x_{i}$ un \textit{\gls{embedding}} o la salida de una \acrshort{svm}, se obtiene el vector normalizado $s_{i}$ como sigue en la ecuación \ref{eq:l2norm}.
    \item \textbf{SDF} (Sequence Decision Function): se encarga de fusionar todas las puntuaciones de la anterior función para obtener un único resultado que representa a la \textbf{secuencia}.
\end{itemize}

\begin{equation}
    s_{i} = \frac{x_{i}}{\left\| x_{i}\right\|_{2}} \label{eq:l2norm}
\end{equation}

\subsection{Módulo de reconocimiento}
\label{sec:reckon}

Este módulo determina si la entidad detectada se corresponde a un individuo previamente reclutado o a una entidad \textbf{desconocida}.

Para tomar la decisión de si un sujeto es o no un desconocido, se ha implementado un algoritmo basado en el teorema estadístico \acrfull{evt} o teorema de Fisher–Tippett–Gnedenko, que permite \textbf{detectar extremos} en distribuciones estadísticas. Dicho teorema dicta que la distribución de los valores máximos o mínimos sigue una de las siguientes 3 distribuciones: Gumbel, Frechet, Weibull \cite{rudd2017extreme, scorenorm, Erik}. Gumbel y Frechet son distribuciones \textbf{no acotadas}, mientras que Weibull es una distribución acotada. Para sistemas de reconocimiento que calculan las distancias o similitudes entre puntuaciones (ejemplo: valores devueltos por una \acrshort{svm} para una clase), la distribución de puntos para cada clase sigue una distribución de Weibull, ya que los valores se encuentran acotados \cite{scorenorm}.

Siendo \textit{f(x)} la distribución de puntuaciones de los comités \textbf{que no corresponden con el sujeto}, se analiza si la puntuación del comité que se corresponde supuestamente con el sujeto es un \textbf{extremo} de la distribución \textit{f(x)}, en dicho caso, la entidad se reconoce claramente diferenciada con el resto, en caso contrario, se denota como \textbf{desconocido}.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/FITS.jpg}
    \caption{Ejemplos de distribuciones de Weibull y como el umbral (Tw) distingue entre un desconocido (\textit{unknown} y una deriva (\textit{drift})).}
    \label{fig:FITS}
\end{figure}

Se calcula la probabilidad de pertenencia a la distribución de la puntuación en cuestión, es decir, la salida de la función \acrfull{pdf} de Weibull. Si la probabilidad se encuentra por debajo de un \textbf{umbral} (Tw en la figura \ref{fig:ADAPTSYS}), entonces se trata de un \textbf{extremo} \cite{Erik, scorenorm}. En la situación de la derecha de la figura \ref{fig:FITS} se muestra un caso en el que la puntuación ganadora es un extremo, al contrario de la gráfica de la izquierda.

Las puntuaciones de todos los comités se ordenan por su valor (función sort de la figura \ref{fig:ADAPTSYS}), siendo la mejor puntuación la primera de la lista, es decir, la más baja (en la sección \ref{sec:init} se explica el porqué) y el resto de puntuaciones las no coincidentes.

El algoritmo expuesto otorga un conocimiento robusto, ya que convierte puntuaciones (o scores) concretos de una \acrshort{svm} en probabilidades que siguen una teoría estadística. Esto permite la \textbf{fusión de datos de diferentes fuentes} como nuevas \acrshort{cnn} de reconocimiento o nuevas cámaras diferentes a las Kinect en el sistema \cite{scorenorm}.

\subsection{Módulo de actualización}
Es el módulo que implementa la actualización de los comités tras el reconocimiento realizado en la anterior función.

Según la entidad predicha, se toma una cierta decisión de actualización. Si el sujeto es \textbf{desconocido}, se crea un nuevo comité con una \acrshort{svm} que se añade al registro. La \acrshort{svm} se entrena con las muestras (\textit{\glspl{embedding}} de caras o cuerpos) obtenidas del propio sujeto como conjunto de positivos, mientras que el conjunto de negativos se compone de muestras aleatorias extraídas directamente de la base de datos. Si el sujeto es \textbf{conocido}, se agrega una nueva \acrshort{svm} al comité, entrenada con las muestras del propio individuo como positivos y como negativos un muestreo aleatorio de todas las entidades \textbf{excepto el propio sujeto}.

Una condición necesaria para que este módulo se ejecute es que la secuencia de entrada \textbf{contenga un mínimo de \textit{\glspl{embedding}} para la inicialización de la \acrshort{svm}}, dicho mínimo es fijado por el operador de antemano.

Otra precondición, que aplica a las entidades conocidas, es comprobar si las muestras a añadir son lo suficientemente representativas. Las puntuaciones cerca del cero indican que las muestras se encuentran en el borde de lo que es nuevo y de lo que la \acrshort{svm} ya conoce. Si la mediana de las puntuaciones de los \glspl{embedding} para un comité se encuentra por debajo de un umbral (\textit{update\_th}), se procede a seleccionar las muestras más cercanas al 0 (función \textit{sample\_selection} en la figura \ref{fig:ADAPTSYS}), que compondrán el conjunto de positivos de la \acrshort{svm}.

\textbf{El tamaño del conjunto de positivos y de negativos es prefijado por el operador}, en la sección \ref{seq:paramtunning} se evalúa su impacto en el rendimiento.

\subsection{Módulo de limitación}
\label{seq:limmod}

Dicho módulo se encuentra inherente al de actualización. Si un comité excede un número prefijado de \acrshort{svm} almacenadas, se toma una decisión para eliminar una de las \acrshort{svm} según los siguientes criterios.

\subsubsection{Diversidad}

Este criterio devuelve un valor que representa el grado de diferenciación de una \acrshort{svm} respecto a su comité.

Se escoge un conjunto aleatorio de \textit{\glspl{embedding}} de entre todos los comités y se calcula la puntuación de cada \acrshort{svm} del comité. Posteriormente, se acumula el producto de los signos entre scores y se multiplica por -1, de esta forma, el \acrshort{svm} más discordante (es decir, el único que devuelve un resultado contrario respecto a una amplia mayoría) obtendrá un mayor valor de este criterio y viceversa. El valor de diversidad de cada \acrshort{svm} se calcula como en \cite{Erik}. Dado un conjunto de \glspl{embedding} \{$x_{0}$, $x_{1}$, ..., $x_{Q-1}$\} y un comité $e^{k}$ con N \acrshort{svm}s \{$h^{k}_{0}$, $h^{k}_{1}$, ..., $h^{k}_{N-1}$\}, $D(h^{k}_{i})$ se calcula como sigue en la ecuación \ref{eq:diversity}, donde \textit{sgn} es la función \textit{sign}, que devuelve 1 o -1 dependiendo del signo del número real.

\begin{align}
    D(h_{i}^{k})= \sum_{j=0;j\neq i}^{N-1} d(h_{i}^{k}, h_{j}^{k}) \label{eq:diversity} \\
    d(h_{i}^{k}, h_{j}^{k}) = -\frac{1}{Q}\sum_{q=0}^{Q-1} sgn(h_{i}^{k}(x_{q})) \cdot sgn(h_{j}^{k}(x_{q}))
\end{align}

\subsubsection{Coherencia}

Este criterio viene a determinar la precisión de una \acrshort{svm} en el reconocimiento respecto a las salidas de su comité.

El valor de coherencia determina cuantas veces una \acrshort{svm} devuelve el mismo signo que el resultado consensuado del comité para un conjunto de \textit{\glspl{embedding}}. Si los signos coinciden, se suma 1 al valor de coherencia, en caso contrario, se resta 1 a dicho valor, de forma que un valor alto se corresponde con una buena precisión. En el momento de creación de una \acrshort{svm}, este valor se inicializa a 0. Dado un comité ganador $e^{k}$ de N \acrshort{svm}s \{$h^{k}_{0}$, $h^{k}_{1}$, ..., $h^{k}_{N-1}$\} y un conjunto de \textit{\glspl{embedding}} \{$x_{0}$, $x_{1}$, ..., $x_{Q-1}$\}, $C_{k,i}$ se calcula como sigue en \cite{CESAR} (ecuación \ref{eq:coherence}), donde $1[\cdot]$ representa a un condicional que devuelve 1 si la condición se cumple o 0 en caso contrario.

\begin{align}
    C_{k,i} = 1[sgn(e^{k}) == sgn(\bar{y})] - 1 [sgn(e^{k}) \neq sgn(\bar{y})] \label{eq:coherence} \\
    \bar{y} = \frac{1}{Q} \sum_{q=1}^{Q-1} h_{n}^{k} (x_{q})
\end{align}

\subsubsection{Favorabilidad}

Finalmente, los dos criterios anteriores se fusionan en un valor llamado \textbf{índice de favorabilidad}

La fórmula para calcular dicho índice es la misma que en \cite{CESAR}. Dado el valor de coherencia $C_{k,i}$ de la \acrshort{svm} $h^{i}$ del comité ganador $e^{k}$ y el valor de diversidad $D(h^{m})$, la favorabilidad se calcula como sigue en la figura \ref{eq:fav}, donde son $\alpha$ y $\gamma$ constantes que ajustan el peso de la coherencia y la diversidad respectivamente.

\begin{equation}
    F(h_{i}^{k}) = \alpha C_{k,i} + \gamma D(h_{i}^{k}) \label{eq:fav}
\end{equation}

Como en los dos criterios anteriores, cuanto mayor sea el valor devuelto, mejor se valora la \acrshort{svm}. De este modo, la \acrshort{svm} con el menor valor de dicho índice \textbf{se elimina del comité}.

\section{Personas registradas}
\label{sec:initarch}

Conforma la base de datos de todos los individuos registrados en el sistema. Cada entrada en este registro se compone de los siguientes objetos:

\begin{itemize}
    \item \textbf{person\_id:} etiqueta asignada al usuario (ejemplo: andres).
    \item \textbf{ensemble:} lista con las \acrshort{svm} del usuario, inicialmente 1.
    \item \textbf{descriptors:} lista de los vectores de características (\glspl{embedding}) del usuario de cada \acrshort{svm}. Dichos vectores se aplican como conjunto de positivos para el propio usuario y como parte del conjunto de negativos para el resto de usuarios.
    \item \textbf{coherence:} lista de valores de coherencia obtenidos de cada \acrshort{svm}, inicializado a 0.
\end{itemize}

La base de datos de personas registradas se conforma mediante un proceso de \textbf{inicialización}, que crea las entradas de cada individuo dentro de la lista inicial de individuos. Posteriormente, dicho registro se actualiza a partir de los módulos de actualización y limitación dentro del módulo de reconocimiento adaptativo. El registro se comparte a nivel de sistema por todos los nodos.

\subsection{Inicialización}

%fundamental, debido a que la \acrshort{svm} inicial es la que define la identidad del comité. Si dicha \acrshort{svm} está compuesta por muestras de baja calidad (ejemplo: caras borrosas o parcialmente ocluidas), entonces el comité \textbf{no se identificará correctamente consigo mismo} y, por lo tanto, generará \textbf{mayor confusión} a la hora de aplicar Weibull, es decir, \textbf{se generarán más desconocidos}.

En esta primera fase del sistema, se crean los registros que representarán a los individuos iniciales.

Como se ha demostrado en \cite{Erik}, el proceso de inicialización es \textbf{crítico} y depende de la calidad de las muestras escogidas. Las muestras borrosas o parcialmente ocluidas agregan confusión a las \acrshort{svm}, que devuelven puntuaciones similares al no distinguir correctamente las características del individuo.

En este proyecto se han probado 2 aproximaciones, una \textbf{supervisada}, es decir, con intervención del operador, y la otra \textbf{no supervisada}, en la que el sistema se inicializa de manera completamente autónoma. En ambos modos, se requieren de mínimo \textbf{5 muestras} del individuo, acorde a las pruebas de \cite{Erik}.

\subsubsection{Supervisado}
El operador realiza una selección de los frames más representativos para cada individuo, de los que se obtienen las características (\glspl{embedding}) a partir de los modelos de reconocimiento.

\subsubsection{No supervisado}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{imagenes/Init.jpg}
    \caption{Inicialización no supervisada del sistema}
    \label{fig:init}
\end{figure}

El sistema se encarga de recoger los frames en el instante en el que aparece un mínimo de entidades simultáneas en escena. A partir de los frames de las cámaras, que estarán sincronizadas, se obtienen las \glspl{bbox} por medio de los modelos de detección y se agrupan por individuo mediante el módulo de procesamiento de video. En este modo \textbf{no se requiere de ninguna intervención del operador}. El funcionamiento se muestra en la figura \ref{fig:init}.

Dado un número de cámaras \textbf{sincronizadas}, se busca un instante (o frame) en el que mínimo se detecten \textbf{5 personas} (equivalente al mínimo de puntos necesario para formar una distribución de Weibull consistente \cite{Erik}) de forma simultánea entre todas las cámaras. En dicho instante, se aplica el método de procesamiento de video para organizar las \glspl{bbox} por individuo, si no se obtienen suficientes \glspl{bbox} del sujeto, el sistema \textbf{repite el proceso de búsqueda} en otro instante. En caso contrario, se obtienen las características (o \textit{\glspl{embedding}/features}) y se almacenan para la creación de las \acrshort{svm}.

Las \glspl{bbox} se someten a un método de \textbf{filtrado}, que puede descartarlas si no cumplen con las siguientes condiciones:

\begin{itemize}
    \item La cara se encuentra enteramente dentro del plano
    \item La \gls{bbox} es más alta que ancha.
\end{itemize}

En ambos modos de inicialización, se crean los comités de cada usuario con una \acrshort{svm} inicial. Dicha \acrshort{svm} se entrena a partir de las propias muestras del individuo (conjunto de positivos) y una selección aleatoria del resto de muestras (conjunto de negativos). Finalmente, los comités se añaden a la base de datos de \textbf{personas registradas}.

\subsection{Registro compartido}

En el sistema de partida (ver sección \ref{sec:partarch}), el registro inicial de individuos no se modifica (modo \textit{Closed-Set}), por lo tanto, no existe la necesidad de mantener una fuente centralizada de los datos. En su lugar, cada nodo inicializa su propia copia. Para implementar el modo \textit{Open-Set} y/o \textit{Open-World}, es necesario mantener los datos actualizados en todos los nodos mediante métodos de compartición.

Debido a que el sistema es distribuido (computación en nodos de cálculo distintos) y los nodos están implementados en Python, es necesario explorar otras vías diferentes a la memoria compartida entre procesos. Para este proyecto, se han propuesto 2 alternativas:

\begin{itemize}
    \item \textbf{Base de datos centralizada:} todos los nodos acceden a una base de datos de baja latencia (ejemplo: base de datos puramente en memoria RAM), de la que reciben el registro de personas actualizado. Dicha base de datos se encontraría en la misma máquina que el nodo integración de sensores, que realizaría las peticiones de escritura. Finalmente, la base de datos propaga las modificaciones a todos los nodos conectados.
    \item \textbf{Red \acrshort{ros}:} el nodo integración de sensores recibe los mensajes de los nodos cámara y, aprovechando la red creada por \acrshort{ros}, se difunde un mensaje con los nuevos cambios a un tópico en el que todos los nodos cámara estarán suscritos, de forma que mantienen su propia copia actualizada.
\end{itemize}